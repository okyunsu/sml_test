#!/usr/bin/env python3
"""
RTX 2080 GPU ìƒíƒœ í™•ì¸ ë° ìµœì í™” ì„¤ì • í…ŒìŠ¤íŠ¸
"""

import torch
import sys
import os
from app.config.gpu_config import setup_rtx2080_environment, monitor_gpu_memory, RTX2080Config

def check_cuda_installation():
    """CUDA ì„¤ì¹˜ ìƒíƒœ í™•ì¸"""
    print("ğŸ” CUDA ì„¤ì¹˜ ìƒíƒœ í™•ì¸")
    print("-" * 40)
    
    # PyTorch CUDA ì§€ì› í™•ì¸
    print(f"PyTorch ë²„ì „: {torch.__version__}")
    print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDA ë²„ì „: {torch.version.cuda}")
        print(f"cuDNN ë²„ì „: {torch.backends.cudnn.version()}")
        print(f"GPU ê°œìˆ˜: {torch.cuda.device_count()}")
        
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            print(f"GPU {i}: {props.name}")
            print(f"  - ë©”ëª¨ë¦¬: {props.total_memory / (1024**3):.1f}GB")
            print(f"  - CUDA Capability: {props.major}.{props.minor}")
    else:
        print("âŒ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return False
    
    return True

def check_rtx2080_optimization():
    """RTX 2080 ìµœì í™” ì„¤ì • í™•ì¸"""
    print("\nğŸ® RTX 2080 ìµœì í™” ì„¤ì • í™•ì¸")
    print("-" * 40)
    
    # GPU í™˜ê²½ ì„¤ì •
    if not setup_rtx2080_environment():
        return False
    
    # ì„¤ì • ì •ë³´ ì¶œë ¥
    config = RTX2080Config()
    print(f"ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {config.MAX_MEMORY_FRACTION * 100}%")
    print(f"ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ…: {config.GRADIENT_CHECKPOINTING}")
    print(f"FP16 ì‚¬ìš©: {config.TRAINING_CONFIG['fp16']}")
    
    # ë°°ì¹˜ í¬ê¸° ì •ë³´
    print("\nğŸ“Š ê¶Œì¥ ë°°ì¹˜ í¬ê¸°:")
    for model_type, sizes in config.BATCH_SIZES.items():
        print(f"  {model_type}:")
        for task, size in sizes.items():
            print(f"    - {task}: {size}")
    
    return True

def test_gpu_memory():
    """GPU ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ’¾ GPU ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    
    if not torch.cuda.is_available():
        print("âŒ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return False
    
    # ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ
    memory_info = monitor_gpu_memory()
    print("ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ:")
    for key, value in memory_info.items():
        print(f"  {key}: {value}")
    
    # ê°„ë‹¨í•œ í…ì„œ ìƒì„± í…ŒìŠ¤íŠ¸
    try:
        print("\nğŸ§ª í…ì„œ ìƒì„± í…ŒìŠ¤íŠ¸...")
        device = torch.device("cuda:0")
        
        # ì‘ì€ í…ì„œë¶€í„° ì‹œì‘
        test_tensor = torch.randn(1000, 1000, device=device)
        print(f"âœ… 1000x1000 í…ì„œ ìƒì„± ì„±ê³µ")
        
        # ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
        memory_info = monitor_gpu_memory()
        print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_info['usage_percent']}%")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del test_tensor
        torch.cuda.empty_cache()
        print("âœ… ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ í…ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
        return False
    
    return True

def check_dependencies():
    """í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸"""
    print("\nğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜ì¡´ì„± í™•ì¸")
    print("-" * 40)
    
    required_packages = [
        'transformers',
        'datasets',
        'peft',
        'accelerate',
        'bitsandbytes',
        'fastapi',
        'uvicorn'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
            print(f"âœ… {package}")
        except ImportError:
            print(f"âŒ {package} - ì„¤ì¹˜ í•„ìš”")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\nâš ï¸ ëˆ„ë½ëœ íŒ¨í‚¤ì§€: {', '.join(missing_packages)}")
        print("setup_local.batì„ ì‹¤í–‰í•˜ì—¬ ì„¤ì¹˜í•˜ì„¸ìš”.")
        return False
    
    return True

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 50)
    print("ESG Fine-tuning Service GPU í™˜ê²½ í™•ì¸")
    print("=" * 50)
    
    # ê° ë‹¨ê³„ë³„ í™•ì¸
    checks = [
        ("CUDA ì„¤ì¹˜", check_cuda_installation),
        ("ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜ì¡´ì„±", check_dependencies),
        ("RTX 2080 ìµœì í™”", check_rtx2080_optimization),
        ("GPU ë©”ëª¨ë¦¬", test_gpu_memory)
    ]
    
    all_passed = True
    
    for check_name, check_func in checks:
        try:
            if not check_func():
                all_passed = False
                print(f"\nâŒ {check_name} í™•ì¸ ì‹¤íŒ¨")
            else:
                print(f"\nâœ… {check_name} í™•ì¸ ì™„ë£Œ")
        except Exception as e:
            print(f"\nâŒ {check_name} í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            all_passed = False
    
    print("\n" + "=" * 50)
    if all_passed:
        print("ğŸ‰ ëª¨ë“  í™•ì¸ ì™„ë£Œ! ì„œë¹„ìŠ¤ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("run_local.batì„ ì‹¤í–‰í•˜ì—¬ ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")
    else:
        print("âš ï¸ ì¼ë¶€ í™•ì¸ ì‹¤íŒ¨. ë¬¸ì œë¥¼ í•´ê²°í•œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
    print("=" * 50)

if __name__ == "__main__":
    main() 