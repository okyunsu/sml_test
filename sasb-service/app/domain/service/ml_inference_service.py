import logging
import os
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from ...config.settings import settings

class MLInferenceService:
    """
    Service for performing sentiment analysis by loading a local Hugging Face model.
    The model is loaded once and reused for all subsequent requests.
    """
    def __init__(self):
        self.tokenizer = None
        self.model = None
        self.device = None
        
        # Beatì—ì„œë§Œ ML ëª¨ë¸ ë¡œë”© ë¹„í™œì„±í™” (ìŠ¤ì¼€ì¤„ë§ë§Œ ë‹´ë‹¹)
        disable_ml = os.getenv("DISABLE_ML_MODEL", "false").lower() == "true"
        if disable_ml:
            logging.info("ML ëª¨ë¸ ë¡œë”©ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤ (Beat ì»¨í…Œì´ë„ˆ)")
            return
            
        if settings.MODEL_NAME and settings.MODEL_BASE_PATH:
            try:
                self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
                logging.info(f"Using device: {self.device}")
                
                # SASB ì„œë¹„ìŠ¤ì—ì„œëŠ” ê°ì„±í‰ê°€ ëª¨ë¸ë§Œ ì‚¬ìš©
                model_path = os.path.join(settings.MODEL_BASE_PATH, f"{settings.MODEL_NAME}_sentiment")
                
                if os.path.isdir(model_path):
                    # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ëª¨ë¸ ë¡œë”© ì„¤ì •
                    self.tokenizer = AutoTokenizer.from_pretrained(
                        model_path,
                        local_files_only=True,
                        use_fast=True
                    )
                    self.model = AutoModelForSequenceClassification.from_pretrained(
                        model_path,
                        local_files_only=True,
                        torch_dtype=torch.float32  # CPUì—ì„œëŠ” float32 ì‚¬ìš©
                    ).to(self.device)
                    logging.info(f"'{settings.MODEL_NAME}' ê°ì„±í‰ê°€ ëª¨ë¸ì„ '{model_path}' ê²½ë¡œì—ì„œ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
                else:
                    logging.error(f"ëª¨ë¸ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤: {model_path}")

            except Exception as e:
                logging.error(f"ëª¨ë¸ ë¡œë”© ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}", exc_info=True)
        else:
            logging.warning("MODEL_NAME ë˜ëŠ” MODEL_BASE_PATHê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ëª¨ë¸ì„ ë¡œë“œí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


    def analyze_sentiment(self, text: str) -> dict:
        """
        Analyzes the sentiment of a single text string.
        """
        if not self.model or not self.tokenizer:
            logging.warning("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•„ ê°ì„± ë¶„ì„ì„ ì¤‘ë¦½ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            # ğŸ¯ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì•ˆì „í•œ ê¸°ë³¸ê°’ ë°˜í™˜
            return {"sentiment": "ì¤‘ë¦½", "confidence": 0.0}
            
        if not text or not isinstance(text, str) or not text.strip():
            # ğŸ¯ ë¹ˆ í…ìŠ¤íŠ¸ëŠ” ì¤‘ë¦½ìœ¼ë¡œ ì²˜ë¦¬ (SentimentResult í˜¸í™˜)
            return {"sentiment": "ì¤‘ë¦½", "confidence": 0.0}

        try:
            inputs = self.tokenizer(text, return_tensors="pt", truncation=True, max_length=512).to(self.device)
            
            with torch.no_grad():
                outputs = self.model(**inputs)

            logits = outputs.logits
            probabilities = torch.softmax(logits, dim=-1)
            confidence, predicted_class_id = torch.max(probabilities, dim=-1)
            
            sentiment = "unknown"
            if hasattr(self.model, 'config') and self.model.config and self.model.config.id2label:
                raw_sentiment = self.model.config.id2label[predicted_class_id.item()]
                sentiment = self._convert_sentiment_label(raw_sentiment)
            else:
                logging.warning("model.config.id2labelì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ IDë¥¼ ëŒ€ì‹  ë°˜í™˜í•©ë‹ˆë‹¤.")
                class_id = predicted_class_id.item()
                sentiment = self._convert_sentiment_label(str(class_id))

            return {
                "sentiment": sentiment,
                "confidence": confidence.item()
            }
        except Exception as e:
            logging.error(f"Sentiment analysis ì¤‘ ì—ëŸ¬ ë°œìƒ: '{e}'\nInput text: {text}", exc_info=True)
            # ğŸ¯ ì—ëŸ¬ ì‹œ ì•ˆì „í•œ ê¸°ë³¸ê°’ ë°˜í™˜ (SentimentResult í˜¸í™˜)
            return {"sentiment": "ì¤‘ë¦½", "confidence": 0.0}

    def _convert_sentiment_label(self, raw_sentiment: str) -> str:
        """
        LABEL_0, LABEL_1, LABEL_2 ë˜ëŠ” ìˆ«ìë¥¼ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜
        
        ì¼ë°˜ì ì¸ 3-class sentiment ë¶„ë¥˜:
        - LABEL_0 / 0 = ë¶€ì • (negative)
        - LABEL_1 / 1 = ê¸ì • (positive) 
        - LABEL_2 / 2 = ì¤‘ë¦½ (neutral)
        """
        # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ì²˜ë¦¬
        label = raw_sentiment.upper().strip()
        
        # LABEL_X í˜•íƒœ ì²˜ë¦¬ (ìˆ˜ì •ëœ ë§¤í•‘)
        if label == "LABEL_0" or label == "0":
            return "ê¸ì •"  # ìˆ˜ì •: LABEL_0 = ê¸ì •
        elif label == "LABEL_1" or label == "1":
            return "ë¶€ì •"  # ìˆ˜ì •: LABEL_1 = ë¶€ì •
        elif label == "LABEL_2" or label == "2":
            return "ì¤‘ë¦½"
        
        # ì´ë¯¸ ë³€í™˜ëœ í˜•íƒœì¸ì§€ í™•ì¸
        elif label in ["ë¶€ì •", "NEGATIVE", "NEG"]:
            return "ë¶€ì •"
        elif label in ["ê¸ì •", "POSITIVE", "POS"]:
            return "ê¸ì •"
        elif label in ["ì¤‘ë¦½", "NEUTRAL", "NEU"]:
            return "ì¤‘ë¦½"
        
        # ì•Œ ìˆ˜ ì—†ëŠ” ë¼ë²¨ì˜ ê²½ìš° ë¡œê¹…í•˜ê³  ì›ë³¸ ë°˜í™˜
        else:
            logging.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” sentiment ë¼ë²¨: '{raw_sentiment}' â†’ ì¤‘ë¦½ìœ¼ë¡œ ì²˜ë¦¬")
            return "ì¤‘ë¦½"

    def get_device(self):
        """Returns the device (cpu/cuda) being used by the model."""
        return self.device