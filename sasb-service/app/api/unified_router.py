"""SASB ì„œë¹„ìŠ¤ í†µí•© API ë¼ìš°í„° - News Serviceì™€ ìœ ì‚¬í•œ êµ¬ì¡°"""
from typing import Optional, List
from fastapi import APIRouter, HTTPException, Depends, BackgroundTasks, Path, Query
from datetime import datetime
import os
import sys

# âœ… Python Path ì„¤ì • (shared ëª¨ë“ˆ ì ‘ê·¼ìš©)
sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))))

# âœ… ê³µí†µ ê°ì • ë³€í™˜ ëª¨ë“ˆ ì‚¬ìš©
from shared.services.sentiment_helper import SentimentConverter

from app.domain.controller.sasb_controller import SASBController
from app.domain.controller.dashboard_controller import DashboardController
from app.domain.model.sasb_dto import (
    NewsAnalysisRequest, NewsAnalysisResult, AnalyzedNewsArticle
)
from app.core.dependencies import get_dependency, DependencyContainer
from app.config.settings import settings
import logging

logger = logging.getLogger(__name__)

# âœ… ê³µí†µ ëª¨ë“ˆ ì‚¬ìš© (ê¸°ì¡´ í•¨ìˆ˜ ì œê±°)
convert_sentiment_label = SentimentConverter.convert_sentiment_label

def convert_articles_sentiment(articles: List[dict]) -> List[dict]:
    """ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ì˜ sentimentë¥¼ ëª¨ë‘ ë³€í™˜"""
    converted_articles = []
    
    for article in articles:
        # ê¸°ì‚¬ ë³µì‚¬
        converted_article = dict(article)
        
        # sentiment í•„ë“œê°€ ìˆìœ¼ë©´ ë³€í™˜
        if "sentiment" in converted_article and isinstance(converted_article["sentiment"], dict):
            sentiment_data = converted_article["sentiment"]
            if "sentiment" in sentiment_data:
                original_sentiment = sentiment_data["sentiment"]
                converted_sentiment = convert_sentiment_label(original_sentiment)
                
                # ë³€í™˜ëœ sentimentë¡œ ì—…ë°ì´íŠ¸
                sentiment_data["sentiment"] = converted_sentiment
                sentiment_data["original_label"] = original_sentiment  # ì›ë³¸ ë¼ë²¨ ë³´ê´€
                
                logger.debug(f"Sentiment ë³€í™˜: {original_sentiment} â†’ {converted_sentiment}")
        
        converted_articles.append(converted_article)
    
    return converted_articles

# ì˜ì¡´ì„± ì£¼ì… í•¨ìˆ˜ë“¤
def get_sasb_controller(
    container: DependencyContainer = Depends(get_dependency)
) -> SASBController:
    """SASBController ì˜ì¡´ì„± ì£¼ì…"""
    return container.get("sasb_controller")

def get_dashboard_controller(
    container: DependencyContainer = Depends(get_dependency)
) -> DashboardController:
    """DashboardController ì˜ì¡´ì„± ì£¼ì…"""
    return container.get("dashboard_controller")

# ============================================================================
# ğŸ”— í”„ë¡ íŠ¸ì—”ë“œ í•µì‹¬ API (Gateway í˜¸í™˜)
# ============================================================================

# í”„ë¡ íŠ¸ì—”ë“œ ì—°ê²°ìš© í•µì‹¬ ë¼ìš°í„°
frontend_router = APIRouter(prefix="/api/v1", tags=["ğŸ¨ SASB Frontend API"])

@frontend_router.post(
    "/analyze/company-sasb",
    response_model=NewsAnalysisResult,
    summary="íšŒì‚¬ + SASB í‚¤ì›Œë“œ ì¡°í•© ë‰´ìŠ¤ ë¶„ì„",
    description="íŠ¹ì • íšŒì‚¬ì™€ SASB í‚¤ì›Œë“œ ì¡°í•©ìœ¼ë¡œ ë‰´ìŠ¤ ë¶„ì„"
)
async def analyze_company_sasb_news(
    company_name: str = Query(..., description="ë¶„ì„í•  íšŒì‚¬ëª…"),
    sasb_keywords: Optional[List[str]] = Query(None, description="SASB í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)"),
    max_results: int = Query(100, description="ìˆ˜ì§‘í•  ìµœëŒ€ ë‰´ìŠ¤ ê°œìˆ˜"),
    background_tasks: BackgroundTasks = BackgroundTasks(),
    sasb_controller: SASBController = Depends(get_sasb_controller),
    dashboard_controller: DashboardController = Depends(get_dashboard_controller)
):
    """íšŒì‚¬ + SASB í† í”½ ì¡°í•© ë‰´ìŠ¤ ë¶„ì„"""
    try:
        # 1ë‹¨ê³„: ìºì‹œ í™•ì¸
        cache_key = f"company_sasb_analysis:{company_name}"
        cached_result = await dashboard_controller.get_cache_data(cache_key)
        
        if cached_result:
            logger.info(f"ìºì‹œ íˆíŠ¸ - íšŒì‚¬+SASB: {company_name}")
            return NewsAnalysisResult(**cached_result)
        
        # 2ë‹¨ê³„: ì‹¤ì‹œê°„ ë¶„ì„
        logger.info(f"ìºì‹œ ë¯¸ìŠ¤, ì‹¤ì‹œê°„ ë¶„ì„ - íšŒì‚¬+SASB: {company_name}")
        result = await sasb_controller.analyze_company_sasb_news(
            company_name=company_name,
            sasb_keywords=sasb_keywords,
            max_results=max_results
        )
        
        # 3ë‹¨ê³„: ìºì‹œ ì €ì¥ (ë°±ê·¸ë¼ìš´ë“œ)
        background_tasks.add_task(
            dashboard_controller.set_cache_data,
            cache_key, 
            result.dict(),
            expire_minutes=60  # SASB ë¶„ì„ì€ 1ì‹œê°„ ìºì‹œ
        )
        
        return result
        
    except Exception as e:
        logger.error(f"íšŒì‚¬+SASB ë‰´ìŠ¤ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"íšŒì‚¬+SASB ë‰´ìŠ¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")

@frontend_router.post(
    "/analyze/sasb-only",
    response_model=NewsAnalysisResult,
    summary="SASB í† í”½ ì „ìš© ë‰´ìŠ¤ ë¶„ì„",
    description="SASB í‚¤ì›Œë“œë§Œìœ¼ë¡œ ë‰´ìŠ¤ ê²€ìƒ‰ ë° ë¶„ì„ (íšŒì‚¬ëª… ì—†ìŒ)"
)
async def analyze_sasb_only_news(
    sasb_keywords: Optional[List[str]] = Query(None, description="SASB í‚¤ì›Œë“œ ëª©ë¡ (ë¯¸ì§€ì •ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©)"),
    max_results: int = Query(100, description="ìˆ˜ì§‘í•  ìµœëŒ€ ë‰´ìŠ¤ ê°œìˆ˜"),
    background_tasks: BackgroundTasks = BackgroundTasks(),
    sasb_controller: SASBController = Depends(get_sasb_controller),
    dashboard_controller: DashboardController = Depends(get_dashboard_controller)
):
    """SASB í† í”½ ì „ìš© ë‰´ìŠ¤ ë¶„ì„"""
    try:
        # 1ë‹¨ê³„: ìºì‹œ í™•ì¸
        cache_key = f"sasb_only_analysis:{hash(str(sasb_keywords))}"
        cached_result = await dashboard_controller.get_cache_data(cache_key)
        
        if cached_result:
            logger.info(f"ìºì‹œ íˆíŠ¸ - SASB ì „ìš©")
            return NewsAnalysisResult(**cached_result)
        
        # 2ë‹¨ê³„: ì‹¤ì‹œê°„ ë¶„ì„
        logger.info(f"ìºì‹œ ë¯¸ìŠ¤, ì‹¤ì‹œê°„ ë¶„ì„ - SASB ì „ìš©")
        result = await sasb_controller.analyze_sasb_only_news(
            sasb_keywords=sasb_keywords,
            max_results=max_results
        )
        
        # 3ë‹¨ê³„: ìºì‹œ ì €ì¥ (ë°±ê·¸ë¼ìš´ë“œ)
        background_tasks.add_task(
            dashboard_controller.set_cache_data,
            cache_key,
            result.dict(),
            expire_minutes=30  # SASB ì „ìš©ì€ 30ë¶„ ìºì‹œ
        )
        
        return result
        
    except Exception as e:
        logger.error(f"SASB ì „ìš© ë‰´ìŠ¤ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"SASB ì „ìš© ë‰´ìŠ¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")

@frontend_router.get(
    "/health",
    summary="í—¬ìŠ¤ì²´í¬",
    description="SASB ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"
)
async def health_check():
    """í—¬ìŠ¤ì²´í¬"""
    return {
        "status": "healthy",
        "service": "sasb-service",
        "version": "2.0.0",
        "timestamp": datetime.now().isoformat(),
        "features": [
            "ğŸ” íšŒì‚¬ + SASB í‚¤ì›Œë“œ ì¡°í•© ë¶„ì„",
            "ğŸ“Š SASB ì „ìš© í‚¤ì›Œë“œ ë¶„ì„",
            "ğŸ’¾ Redis ìºì‹œ ì‹œìŠ¤í…œ",
            "ğŸ”„ ë°±ê·¸ë¼ìš´ë“œ ìë™ ë¶„ì„"
        ]
    }

# ============================================================================
# ğŸ“Š ëŒ€ì‹œë³´ë“œ ê´€ë¦¬ API
# ============================================================================

dashboard_router = APIRouter(prefix="/api/v1/dashboard", tags=["ğŸ“Š SASB Dashboard"])

@dashboard_router.get(
    "/status",
    summary="ëŒ€ì‹œë³´ë“œ ì „ì²´ ìƒíƒœ",
    description="SASB ì‹œìŠ¤í…œ ì „ì²´ ìƒíƒœ ë° Redis ì—°ê²° í™•ì¸"
)
async def get_dashboard_status(
    dashboard_controller: DashboardController = Depends(get_dashboard_controller)
):
    """ëŒ€ì‹œë³´ë“œ ì „ì²´ ìƒíƒœ"""
    try:
        return await dashboard_controller.get_system_status()
    except Exception as e:
        logger.error(f"ëŒ€ì‹œë³´ë“œ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ëŒ€ì‹œë³´ë“œ ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")

@dashboard_router.get(
    "/companies",
    summary="ëª¨ë‹ˆí„°ë§ íšŒì‚¬ ëª©ë¡",
    description="í˜„ì¬ SASB ëª¨ë‹ˆí„°ë§ ì¤‘ì¸ íšŒì‚¬ ëª©ë¡"
)
async def get_monitored_companies(
    dashboard_controller: DashboardController = Depends(get_dashboard_controller)
):
    """ëª¨ë‹ˆí„°ë§ ì¤‘ì¸ íšŒì‚¬ ëª©ë¡"""
    return {
        "companies": ["ë‘ì‚°í“¨ì–¼ì…€", "LS ELECTRIC"],
        "total_count": 2,
        "last_updated": datetime.now().isoformat()
    }

@dashboard_router.get(
    "/sasb-news",
    response_model=NewsAnalysisResult,
    summary="SASB ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ",
    description="SASB í‚¤ì›Œë“œë¡œ ë¶„ì„ëœ ìµœì‹  ë‰´ìŠ¤ ê²°ê³¼ ì¡°íšŒ (Worker ê²°ê³¼ ìš°ì„ , ì²˜ìŒ ëŒ€ì‹œë³´ë“œìš©)"
)
async def get_sasb_news_analysis(
    max_results: int = Query(100, description="ë°˜í™˜í•  ìµœëŒ€ ë‰´ìŠ¤ ê°œìˆ˜"),
    force_realtime: bool = Query(False, description="ì‹¤ì‹œê°„ ë¶„ì„ ê°•ì œ ì‹¤í–‰ (Worker ê²°ê³¼ ë¬´ì‹œ)"),
    sasb_keywords: Optional[List[str]] = Query(None, description="SASB í‚¤ì›Œë“œ ëª©ë¡ (ë¯¸ì§€ì •ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©)"),
    dashboard_controller: DashboardController = Depends(get_dashboard_controller),
    sasb_controller: SASBController = Depends(get_sasb_controller)
):
    """SASB ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (Worker ê²°ê³¼ ìš°ì„ , ì²˜ìŒ ëŒ€ì‹œë³´ë“œìš©)"""
    try:
        # ğŸ”„ 1ë‹¨ê³„: Worker ê²°ê³¼ ìš°ì„  í™•ì¸ (force_realtime=Falseì¼ ë•Œ)
        if not force_realtime:
            worker_articles = await dashboard_controller.get_cache_data("latest_sasb_renewable_analysis")
            
            if worker_articles:
                logger.info("âœ… Workerì—ì„œ ì²˜ë¦¬ëœ SASB ë‰´ìŠ¤ ê²°ê³¼ ë°˜í™˜ (ë¹ ë¥¸ ì‘ë‹µ)")
                
                # Worker ê²°ê³¼ëŠ” ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ì´ë¯€ë¡œ NewsAnalysisResult í˜•íƒœë¡œ ë³€í™˜
                if isinstance(worker_articles, list):
                    # ê²°ê³¼ ê°œìˆ˜ ì œí•œ ì ìš©
                    limited_articles = []
                    for i, article in enumerate(worker_articles):
                        if i >= max_results:
                            break
                        limited_articles.append(article)
                    
                    # ğŸ”„ Sentiment ë³€í™˜ ì ìš© (LABEL_X â†’ ê¸ì •/ë¶€ì •/ì¤‘ë¦½)
                    converted_articles = convert_articles_sentiment(limited_articles)
                    logger.info(f"ëŒ€ì‹œë³´ë“œ Worker ê²°ê³¼ {len(converted_articles)}ê°œ ê¸°ì‚¬ì˜ sentiment ë³€í™˜ ì™„ë£Œ")
                    
                    # dictë¥¼ AnalyzedNewsArticle ê°ì²´ë¡œ ë³€í™˜
                    article_objects = []
                    for article_dict in converted_articles:
                        try:
                            article_obj = AnalyzedNewsArticle(**article_dict)
                            article_objects.append(article_obj)
                        except Exception as e:
                            logger.warning(f"ëŒ€ì‹œë³´ë“œ ê¸°ì‚¬ ê°ì²´ ë³€í™˜ ì‹¤íŒ¨: {e}")
                            continue
                    
                    # NewsAnalysisResult í˜•íƒœë¡œ ë˜í•‘
                    result = NewsAnalysisResult(
                        task_id="worker_sasb_dashboard",
                        status="completed",
                        searched_keywords=["SASB í‚¤ì›Œë“œ (Worker ì²˜ë¦¬)"],
                        total_articles_found=len(article_objects),
                        analyzed_articles=article_objects,
                        company_name=None,
                        analysis_type="sasb_only_worker"
                    )
                    
                    return result
        
        # ğŸ” 2ë‹¨ê³„: ì‹¤ì‹œê°„ ë¶„ì„ ìºì‹œ í™•ì¸
        cache_key = f"sasb_only_analysis:{hash(str(sasb_keywords))}"
        cached_result = await dashboard_controller.get_cache_data(cache_key)
        
        if cached_result and not force_realtime:
            logger.info("ğŸ’¾ ìºì‹œëœ ì‹¤ì‹œê°„ SASB ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ ë°˜í™˜")
            result = NewsAnalysisResult(**cached_result)
            
            # ê²°ê³¼ ê°œìˆ˜ ì œí•œ ì ìš©
            if result.analyzed_articles and len(result.analyzed_articles) > max_results:
                result.analyzed_articles = result.analyzed_articles[:max_results]
                result.total_articles_found = len(result.analyzed_articles)
            
            return result
        
        # â±ï¸ 3ë‹¨ê³„: ì‹¤ì‹œê°„ ë¶„ì„ ì‹¤í–‰ (ìµœí›„ ìˆ˜ë‹¨)
        logger.info("âš¡ Worker ê²°ê³¼ ì—†ìŒ, ì‹¤ì‹œê°„ SASB ë‰´ìŠ¤ ë¶„ì„ ì‹¤í–‰ (ëŠë¦¼)")
        result = await sasb_controller.analyze_sasb_only_news(
            sasb_keywords=sasb_keywords,
            max_results=max_results
        )
        
        # ì‹¤ì‹œê°„ ë¶„ì„ ê²°ê³¼ì— ë©”íƒ€ë°ì´í„° ì¶”ê°€
        result_dict = result.dict()
        result_dict["source"] = "realtime_analysis"
        result_dict["analysis_type"] = "sasb_only_realtime"
        
        # ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥ (30ë¶„)
        await dashboard_controller.set_cache_data(
            cache_key,
            result_dict,
            expire_minutes=30
        )
        
        return result
        
    except Exception as e:
        logger.error(f"SASB ë‰´ìŠ¤ ë¶„ì„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"SASB ë‰´ìŠ¤ ë¶„ì„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")

@dashboard_router.get(
    "/companies/{company}/latest",
    summary="íšŒì‚¬ ìµœì‹  SASB ë¶„ì„ ê²°ê³¼",
    description="íŠ¹ì • íšŒì‚¬ì˜ ìµœì‹  SASB ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"
)
async def get_company_latest_analysis(
    company: str = Path(..., description="íšŒì‚¬ëª…"),
    dashboard_controller: DashboardController = Depends(get_dashboard_controller)
):
    """íšŒì‚¬ ìµœì‹  ë¶„ì„ ê²°ê³¼"""
    try:
        # Workerì—ì„œ ì‚¬ìš©í•˜ëŠ” í‚¤ì™€ ë™ì¼í•˜ê²Œ ë³€ê²½
        cache_key = f"latest_company_sasb_analysis:{company}"
        result = await dashboard_controller.get_cache_data(cache_key)
        
        if not result:
            raise HTTPException(status_code=404, detail=f"{company}ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return result
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"íšŒì‚¬ ë¶„ì„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")

# ============================================================================
# ğŸ—„ï¸ ìºì‹œ ê´€ë¦¬ API
# ============================================================================

cache_router = APIRouter(prefix="/api/v1/cache", tags=["ğŸ—„ï¸ SASB Cache"])

@cache_router.get(
    "/info",
    summary="ìºì‹œ ì •ë³´ ì¡°íšŒ",
    description="Redis ìºì‹œ ìƒíƒœ ë° í†µê³„ ì •ë³´"
)
async def get_cache_info(
    dashboard_controller: DashboardController = Depends(get_dashboard_controller)
):
    """ìºì‹œ ì •ë³´ ì¡°íšŒ"""
    try:
        return await dashboard_controller.get_cache_info()
    except Exception as e:
        logger.error(f"ìºì‹œ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ìºì‹œ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")

@cache_router.delete(
    "/company/{company}",
    summary="íšŒì‚¬ ìºì‹œ ì‚­ì œ",
    description="íŠ¹ì • íšŒì‚¬ì˜ SASB ìºì‹œ ë°ì´í„° ì‚­ì œ"
)
async def clear_company_cache(
    company: str = Path(..., description="íšŒì‚¬ëª…"),
    dashboard_controller: DashboardController = Depends(get_dashboard_controller)
):
    """íšŒì‚¬ ìºì‹œ ì‚­ì œ"""
    try:
        # Workerì—ì„œ ì‚¬ìš©í•˜ëŠ” í‚¤ë“¤ê³¼ ì¼ì¹˜í•˜ë„ë¡ ìˆ˜ì •
        cache_keys = [
            f"company_sasb_analysis:{company}",
            f"latest_company_sasb_analysis:{company}",  # Workerì—ì„œ ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” í‚¤
            f"latest_companies_renewable_analysis:{company}"  # ì´ì „ í‚¤ (í˜¹ì‹œ ë‚¨ì•„ìˆì„ ìˆ˜ ìˆëŠ” ìºì‹œ)
        ]
        
        deleted_count = 0
        for key in cache_keys:
            if await dashboard_controller.delete_cache_data(key):
                deleted_count += 1
        
        return {
            "message": f"{company}ì˜ ìºì‹œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "deleted_keys": deleted_count,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"ìºì‹œ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ìºì‹œ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {str(e)}")

# ============================================================================
# ğŸ› ï¸ ì‹œìŠ¤í…œ ê´€ë¦¬ API
# ============================================================================

system_router = APIRouter(prefix="/api/v1/system", tags=["ğŸ› ï¸ SASB System"])

@system_router.get(
    "/health",
    summary="ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬",
    description="ì „ì²´ SASB ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"
)
async def system_health_check():
    """ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬"""
    return {
        "status": "healthy",
        "service": "sasb-service",
        "version": "2.0.0",
        "components": {
            "api": "healthy",
            "redis": "healthy",
            "celery": "healthy",
            "ml_models": "healthy"
        },
        "timestamp": datetime.now().isoformat()
    }

# ============================================================================
# ğŸ”„ Worker ëª¨ë‹ˆí„°ë§ API
# ============================================================================

worker_router = APIRouter(prefix="/api/v1/workers", tags=["ğŸ”„ SASB Workers"])

@worker_router.get(
    "/status",
    summary="Worker ì „ì²´ ìƒíƒœ",
    description="Celery Worker ìƒíƒœ ë° ì‹¤í–‰ ì¤‘ì¸ ì‘ì—… í™•ì¸"
)
async def get_worker_status(
    dashboard_controller: DashboardController = Depends(get_dashboard_controller)
):
    """Worker ì „ì²´ ìƒíƒœ ì¡°íšŒ"""
    try:
        # Worker ì‘ì—… ìƒíƒœ í™•ì¸
        status_keys = [
            "status:combined_keywords_analysis",
            "status:company_combined_keywords_analysis"
        ]
        
        worker_status = {}
        for key in status_keys:
            status = await dashboard_controller.get_cache_data(key)
            task_name = key.replace("status:", "")
            worker_status[task_name] = status or "IDLE"
        
        # ë‹¤ìŒ ì‹¤í–‰ ì˜ˆì • ì‹œê°„ ê³„ì‚°
        now = datetime.now()
        next_runs = {
            "combined_keywords_analysis": _calculate_next_cron(now, "5,35 * * * *"),
            "company_combined_keywords_analysis": _calculate_next_cron(now, "10,40 * * * *")
        }
        
        return {
            "status": "active",
            "timestamp": now.isoformat(),
            "tasks": worker_status,
            "next_scheduled_runs": next_runs,
            "total_active_tasks": sum(1 for status in worker_status.values() if status == "IN_PROGRESS")
        }
        
    except Exception as e:
        logger.error(f"Worker ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Worker ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")

@worker_router.get(
    "/results/sasb-news",
    response_model=NewsAnalysisResult,
    summary="Worker ì²˜ë¦¬ SASB ë‰´ìŠ¤ ê²°ê³¼",
    description="Workerì—ì„œ ë°±ê·¸ë¼ìš´ë“œë¡œ ì²˜ë¦¬í•œ SASB ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"
)
async def get_worker_sasb_results(
    max_results: int = Query(100, description="ë°˜í™˜í•  ìµœëŒ€ ë‰´ìŠ¤ ê°œìˆ˜"),
    dashboard_controller: DashboardController = Depends(get_dashboard_controller)
):
    """Workerì—ì„œ ì²˜ë¦¬í•œ SASB ë‰´ìŠ¤ ê²°ê³¼ ì¡°íšŒ"""
    try:
        # Workerì—ì„œ ì €ì¥í•œ SASB ì „ìš© ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ)
        worker_articles = await dashboard_controller.get_cache_data("latest_sasb_renewable_analysis")
        
        if not worker_articles:
            raise HTTPException(
                status_code=404, 
                detail="Workerì—ì„œ ì²˜ë¦¬í•œ SASB ë‰´ìŠ¤ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. Workerê°€ ì‹¤í–‰ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."
            )
        
        # Worker ê²°ê³¼ëŠ” ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ì´ë¯€ë¡œ NewsAnalysisResult í˜•íƒœë¡œ ë³€í™˜
        if isinstance(worker_articles, list):
            # ê²°ê³¼ ê°œìˆ˜ ì œí•œ ì ìš©
            articles_count = len(worker_articles)
            limited_articles = []
            for i, article in enumerate(worker_articles):
                if i >= max_results:
                    break
                limited_articles.append(article)
            
            # ğŸ”„ Sentiment ë³€í™˜ ì ìš© (LABEL_X â†’ ê¸ì •/ë¶€ì •/ì¤‘ë¦½)
            converted_articles = convert_articles_sentiment(limited_articles)
            logger.info(f"Worker ê²°ê³¼ {len(converted_articles)}ê°œ ê¸°ì‚¬ì˜ sentiment ë³€í™˜ ì™„ë£Œ")
            
            # dictë¥¼ AnalyzedNewsArticle ê°ì²´ë¡œ ë³€í™˜
            article_objects = []
            for article_dict in converted_articles:
                try:
                    article_obj = AnalyzedNewsArticle(**article_dict)
                    article_objects.append(article_obj)
                except Exception as e:
                    logger.warning(f"ê¸°ì‚¬ ê°ì²´ ë³€í™˜ ì‹¤íŒ¨: {e}")
                    continue
            
            # NewsAnalysisResult í˜•íƒœë¡œ ë˜í•‘
            result = NewsAnalysisResult(
                task_id="worker_sasb_analysis",
                status="completed",
                searched_keywords=["SASB í‚¤ì›Œë“œ (Worker ì²˜ë¦¬)"],
                total_articles_found=len(article_objects),
                analyzed_articles=article_objects,
                company_name=None,
                analysis_type="sasb_only_worker"
            )
            
            return result
        else:
            raise HTTPException(
                status_code=500, 
                detail=f"Worker ê²°ê³¼ í˜•íƒœê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. íƒ€ì…: {type(worker_articles)}"
            )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Worker SASB ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Worker SASB ê²°ê³¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")

@worker_router.get(
    "/results/companies",
    summary="Worker ì²˜ë¦¬ íšŒì‚¬ë³„ ë¶„ì„ ê²°ê³¼",
    description="Workerì—ì„œ ë°±ê·¸ë¼ìš´ë“œë¡œ ì²˜ë¦¬í•œ íšŒì‚¬ë³„ ë¶„ì„ ê²°ê³¼ ëª©ë¡"
)
async def get_worker_company_results(
    dashboard_controller: DashboardController = Depends(get_dashboard_controller)
):
    """Workerì—ì„œ ì²˜ë¦¬í•œ íšŒì‚¬ë³„ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
    try:
        # Workerì—ì„œ ì €ì¥í•œ íšŒì‚¬ë³„ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
        worker_result = await dashboard_controller.get_cache_data("latest_companies_renewable_analysis")
        
        if not worker_result:
            raise HTTPException(
                status_code=404,
                detail="Workerì—ì„œ ì²˜ë¦¬í•œ íšŒì‚¬ë³„ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. Workerê°€ ì‹¤í–‰ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."
            )
        
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        result = {
            "source": "worker_background",
            "last_updated": worker_result.get("timestamp", datetime.now().isoformat()),
            "total_companies": len(worker_result.get("companies", [])),
            "companies_data": worker_result
        }
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Worker íšŒì‚¬ë³„ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Worker íšŒì‚¬ë³„ ê²°ê³¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")

@worker_router.get(
    "/results/combined-keywords",
    response_model=NewsAnalysisResult,
    summary="ğŸ¯ ì¡°í•© ê²€ìƒ‰ ê²°ê³¼ ì¡°íšŒ",
    description="(ì‚°ì—… í‚¤ì›Œë“œ) AND (SASB ì´ìŠˆ í‚¤ì›Œë“œ) ì¡°í•© ê²€ìƒ‰ìœ¼ë¡œ ìˆ˜ì§‘ëœ ì •í™•ë„ ë†’ì€ ë‰´ìŠ¤"
)
async def get_combined_keywords_results(
    max_results: int = Query(100, description="ë°˜í™˜í•  ìµœëŒ€ ë‰´ìŠ¤ ê°œìˆ˜"),
    dashboard_controller: DashboardController = Depends(get_dashboard_controller)
):
    """ğŸ¯ ì¡°í•© ê²€ìƒ‰ ê²°ê³¼ ì¡°íšŒ - ê´€ë ¨ì„± ë†’ì€ ì‹ ì¬ìƒì—ë„ˆì§€ ë‰´ìŠ¤ë§Œ"""
    try:
        # Workerì—ì„œ ì €ì¥í•œ ì¡°í•© ê²€ìƒ‰ ê²°ê³¼ ì¡°íšŒ
        worker_articles = await dashboard_controller.get_cache_data("latest_combined_keywords_analysis")
        
        if not worker_articles:
            raise HTTPException(
                status_code=404, 
                detail="ğŸ¯ ì¡°í•© ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. Workerê°€ ì‹¤í–‰ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."
            )
        
        # Worker ê²°ê³¼ëŠ” ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ì´ë¯€ë¡œ NewsAnalysisResult í˜•íƒœë¡œ ë³€í™˜
        if isinstance(worker_articles, list):
            # ê²°ê³¼ ê°œìˆ˜ ì œí•œ ì ìš©
            articles_count = len(worker_articles)
            limited_articles = []
            for i, article in enumerate(worker_articles):
                if i >= max_results:
                    break
                limited_articles.append(article)
            
            # ğŸ”„ Sentiment ë³€í™˜ ì ìš© (LABEL_X â†’ ê¸ì •/ë¶€ì •/ì¤‘ë¦½)
            converted_articles = convert_articles_sentiment(limited_articles)
            logger.info(f"ğŸ¯ ì¡°í•© ê²€ìƒ‰ ê²°ê³¼ {len(converted_articles)}ê°œ ê¸°ì‚¬ì˜ sentiment ë³€í™˜ ì™„ë£Œ")
            
            # dictë¥¼ AnalyzedNewsArticle ê°ì²´ë¡œ ë³€í™˜
            article_objects = []
            for article_dict in converted_articles:
                try:
                    article_obj = AnalyzedNewsArticle(**article_dict)
                    article_objects.append(article_obj)
                except Exception as e:
                    logger.warning(f"ì¡°í•© ê²€ìƒ‰ ê¸°ì‚¬ ê°ì²´ ë³€í™˜ ì‹¤íŒ¨: {e}")
                    continue
            
            # NewsAnalysisResult í˜•íƒœë¡œ ë˜í•‘
            result = NewsAnalysisResult(
                task_id="combined_keywords_analysis",
                status="completed",
                searched_keywords=["ğŸ¯ ì‚°ì—…+ì´ìŠˆ ì¡°í•© í‚¤ì›Œë“œ"],
                total_articles_found=len(article_objects),
                analyzed_articles=article_objects,
                company_name=None,
                analysis_type="combined_keywords"
            )
            
            return result
        else:
            raise HTTPException(
                status_code=500, 
                detail=f"ì¡°í•© ê²€ìƒ‰ ê²°ê³¼ í˜•íƒœê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. íƒ€ì…: {type(worker_articles)}"
            )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ğŸ¯ ì¡°í•© ê²€ìƒ‰ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì¡°í•© ê²€ìƒ‰ ê²°ê³¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")

@worker_router.get(
    "/results/company-combined/{company}",
    response_model=NewsAnalysisResult,
    summary="ğŸ¯ íšŒì‚¬ë³„ ì¡°í•© ê²€ìƒ‰ ê²°ê³¼ ì¡°íšŒ",
    description="íŠ¹ì • íšŒì‚¬ + (ì‚°ì—… í‚¤ì›Œë“œ) AND (SASB ì´ìŠˆ í‚¤ì›Œë“œ) ì¡°í•© ê²€ìƒ‰ ê²°ê³¼"
)
async def get_company_combined_results(
    company: str = Path(..., description="íšŒì‚¬ëª…"),
    max_results: int = Query(100, description="ë°˜í™˜í•  ìµœëŒ€ ë‰´ìŠ¤ ê°œìˆ˜"),
    dashboard_controller: DashboardController = Depends(get_dashboard_controller)
):
    """ğŸ¯ íšŒì‚¬ë³„ ì¡°í•© ê²€ìƒ‰ ê²°ê³¼ ì¡°íšŒ"""
    try:
        # Workerì—ì„œ ì €ì¥í•œ íšŒì‚¬ë³„ ì¡°í•© ê²€ìƒ‰ ê²°ê³¼ ì¡°íšŒ
        cache_key = f"latest_company_combined_analysis:{company}"
        worker_articles = await dashboard_controller.get_cache_data(cache_key)
        
        if not worker_articles:
            raise HTTPException(
                status_code=404, 
                detail=f"ğŸ¯ {company}ì˜ ì¡°í•© ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. Workerê°€ ì‹¤í–‰ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."
            )
        
        # Worker ê²°ê³¼ëŠ” ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ì´ë¯€ë¡œ NewsAnalysisResult í˜•íƒœë¡œ ë³€í™˜
        if isinstance(worker_articles, list):
            # ê²°ê³¼ ê°œìˆ˜ ì œí•œ ì ìš©
            limited_articles = []
            for i, article in enumerate(worker_articles):
                if i >= max_results:
                    break
                limited_articles.append(article)
            
            # ğŸ”„ Sentiment ë³€í™˜ ì ìš©
            converted_articles = convert_articles_sentiment(limited_articles)
            logger.info(f"ğŸ¯ {company} ì¡°í•© ê²€ìƒ‰ ê²°ê³¼ {len(converted_articles)}ê°œ ê¸°ì‚¬ì˜ sentiment ë³€í™˜ ì™„ë£Œ")
            
            # dictë¥¼ AnalyzedNewsArticle ê°ì²´ë¡œ ë³€í™˜
            article_objects = []
            for article_dict in converted_articles:
                try:
                    article_obj = AnalyzedNewsArticle(**article_dict)
                    article_objects.append(article_obj)
                except Exception as e:
                    logger.warning(f"{company} ì¡°í•© ê²€ìƒ‰ ê¸°ì‚¬ ê°ì²´ ë³€í™˜ ì‹¤íŒ¨: {e}")
                    continue
            
            # NewsAnalysisResult í˜•íƒœë¡œ ë˜í•‘
            result = NewsAnalysisResult(
                task_id=f"company_combined_analysis_{company}",
                status="completed",
                searched_keywords=[f"ğŸ¯ {company}+ì‚°ì—…+ì´ìŠˆ ì¡°í•© í‚¤ì›Œë“œ"],
                total_articles_found=len(article_objects),
                analyzed_articles=article_objects,
                company_name=company,
                analysis_type="company_combined_keywords"
            )
            
            return result
        else:
            raise HTTPException(
                status_code=500, 
                detail=f"{company} ì¡°í•© ê²€ìƒ‰ ê²°ê³¼ í˜•íƒœê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. íƒ€ì…: {type(worker_articles)}"
            )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ğŸ¯ {company} ì¡°í•© ê²€ìƒ‰ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"{company} ì¡°í•© ê²€ìƒ‰ ê²°ê³¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")

@worker_router.get(
    "/schedule",
    summary="Worker ìŠ¤ì¼€ì¤„ ì •ë³´",
    description="ì˜ˆì•½ëœ Worker ì‘ì—… ìŠ¤ì¼€ì¤„ ë° ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„"
)
async def get_worker_schedule():
    """Worker ìŠ¤ì¼€ì¤„ ì •ë³´ ì¡°íšŒ"""
    try:
        now = datetime.now()
        
        schedule_info = {
            "current_time": now.isoformat(),
            "scheduled_tasks": [
                {
                    "name": "ğŸ¯ ì¡°í•© í‚¤ì›Œë“œ ë¶„ì„",
                    "task_id": "run_combined_keywords_analysis",
                    "schedule": "ì‹œì‘ í›„ 1ë¶„, ì´í›„ 10ë¶„ë§ˆë‹¤ (1,11,21,31,41,51ë¶„)",
                    "cron": "1,11,21,31,41,51 * * * *",
                    "next_run": _calculate_next_cron(now, "1,11,21,31,41,51 * * * *"),
                    "description": "(ì‚°ì—… í‚¤ì›Œë“œ) AND (SASB ì´ìŠˆ í‚¤ì›Œë“œ) ì¡°í•© ê²€ìƒ‰ìœ¼ë¡œ ì •í™•ë„ ë†’ì€ ë‰´ìŠ¤ ìˆ˜ì§‘"
                },
                {
                    "name": "ğŸ¯ íšŒì‚¬ë³„ ì¡°í•© í‚¤ì›Œë“œ ë¶„ì„", 
                    "task_id": "run_company_combined_keywords_analysis",
                    "schedule": "ì‹œì‘ í›„ 3ë¶„, ì´í›„ 10ë¶„ë§ˆë‹¤ (3,13,23,33,43,53ë¶„)",
                    "cron": "3,13,23,33,43,53 * * * *", 
                    "next_run": _calculate_next_cron(now, "3,13,23,33,43,53 * * * *"),
                    "description": "íšŒì‚¬ + (ì‚°ì—… í‚¤ì›Œë“œ) AND (SASB ì´ìŠˆ í‚¤ì›Œë“œ) ì¡°í•©ìœ¼ë¡œ íšŒì‚¬ë³„ ì •í™•ë„ ë†’ì€ ë‰´ìŠ¤ ìˆ˜ì§‘"
                }
            ]
        }
        
        return schedule_info
        
    except Exception as e:
        logger.error(f"Worker ìŠ¤ì¼€ì¤„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Worker ìŠ¤ì¼€ì¤„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")

def _calculate_next_cron(current_time: datetime, cron_pattern: str) -> str:
    """í¬ë¡  íŒ¨í„´ìœ¼ë¡œ ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ ê³„ì‚° (ê°„ë‹¨í•œ êµ¬í˜„)"""
    if "5,35" in cron_pattern:
        # ë§¤ ì‹œê°„ 5ë¶„, 35ë¶„ì— ì‹¤í–‰
        minutes = current_time.minute
        if minutes < 5:
            next_time = current_time.replace(minute=5, second=0, microsecond=0)
        elif minutes < 35:
            next_time = current_time.replace(minute=35, second=0, microsecond=0)
        else:
            # ë‹¤ìŒ ì‹œê°„ 5ë¶„
            next_time = current_time.replace(hour=current_time.hour + 1, minute=5, second=0, microsecond=0)
    elif "10,40" in cron_pattern:
        # ë§¤ ì‹œê°„ 10ë¶„, 40ë¶„ì— ì‹¤í–‰
        minutes = current_time.minute
        if minutes < 10:
            next_time = current_time.replace(minute=10, second=0, microsecond=0)
        elif minutes < 40:
            next_time = current_time.replace(minute=40, second=0, microsecond=0)
        else:
            # ë‹¤ìŒ ì‹œê°„ 10ë¶„
            next_time = current_time.replace(hour=current_time.hour + 1, minute=10, second=0, microsecond=0)
    else:
        next_time = current_time
    
    return next_time.isoformat()

# ============================================================================
# ğŸ”— ë¼ìš°í„° ë“±ë¡
# ============================================================================

# ë©”ì¸ ë¼ìš°í„° (ê°„ë‹¨í•œ êµ¬ì¡°)
main_router = APIRouter()
main_router.include_router(frontend_router)
main_router.include_router(dashboard_router)
main_router.include_router(cache_router)
main_router.include_router(system_router)
main_router.include_router(worker_router)

 