from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
import logging
import os
import sys
from collections import defaultdict
import math

# âœ… Python Path ì„¤ì • (shared ëª¨ë“ˆ ì ‘ê·¼ìš©)
sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))))))

# âœ… ê³µí†µ ë¶„ì„ í—¬í¼ ì‚¬ìš©
from shared.services.analysis_helper import (
    MaterialityAnalysisHelper, AnalysisErrorHandler, 
    ActionItemGenerator, ConfidenceAssessment
)

from ..model.materiality_dto import MaterialityTopic, MaterialityAssessment
from .news_analysis_engine import NewsAnalysisEngine
from .materiality_update_engine import MaterialityUpdateEngine
from .materiality_mapping_service import MaterialityMappingService
from .materiality_file_service import MaterialityFileService

logger = logging.getLogger(__name__)

class MaterialityAnalysisService:
    """ì¤‘ëŒ€ì„± í‰ê°€ ë³€í™” ë¶„ì„ ì„œë¹„ìŠ¤
    
    ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¤‘ëŒ€ì„± í‰ê°€ ë³€í™” ê°€ëŠ¥ì„±ì„ ë¶„ì„:
    - ìš°ì„ ìˆœìœ„ ë³€í™” ê°€ëŠ¥ì„± ì œì•ˆ
    - ì‹ ê·œ ì´ìŠˆ ë°œêµ´ ë° ê²€í†  ì œì•ˆ
    - ê¸°ì¡´ ì´ìŠˆ ì¤‘ìš”ë„ ë³€í™” ë¶„ì„
    - SASB ë§¤í•‘ ê¸°ë°˜ ê´€ë ¨ì„± ë¶„ì„
    
    ì£¼ì˜: ë‰´ìŠ¤ ë¶„ì„ë§Œìœ¼ë¡œëŠ” í™•ì •ì ì¸ ì¤‘ëŒ€ì„± í‰ê°€ë¥¼ ë‚´ë¦´ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ,
    ëª¨ë“  ê²°ê³¼ëŠ” ì°¸ê³ ìš© ë¶„ì„ ë° ì œì•ˆ ì‚¬í•­ì…ë‹ˆë‹¤.
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.news_engine = NewsAnalysisEngine()
        self.update_engine = MaterialityUpdateEngine()
        self.mapping_service = MaterialityMappingService()
        self.file_service = MaterialityFileService()
        
        # Gateway í´ë¼ì´ì–¸íŠ¸ ì¶”ê°€
        from ...core.gateway_client import GatewayClient
        self.gateway_client = GatewayClient()
        
        # ë¶„ì„ íŒŒë¼ë¯¸í„° ì„¤ì •
        self.analysis_params = {
            'significance_threshold': 0.3,  # ì¤‘ìš”í•œ ë³€í™” ì„ê³„ê°’
            'new_issue_threshold': 0.4,     # ì‹ ê·œ ì´ìŠˆ ê²€í†  ì„ê³„ê°’
            'high_confidence_threshold': 0.7,  # ë†’ì€ ì‹ ë¢°ë„ ì„ê³„ê°’
            'max_recommendations': 10       # ìµœëŒ€ ì¶”ì²œ ê°œìˆ˜
        }
    
    async def check_gateway_connection(self) -> Dict[str, Any]:
        """Gateway ì—°ê²° ìƒíƒœ í™•ì¸"""
        try:
            # Gateway í—¬ìŠ¤ì²´í¬ ìˆ˜í–‰
            health_status = await self.gateway_client.get_sasb_health_check()
            return {
                "status": "connected",
                "gateway_available": True,
                "services": health_status,
                "message": "Gateway ì—°ê²° ì •ìƒ"
            }
        except Exception as e:
            self.logger.warning(f"Gateway ì—°ê²° í™•ì¸ ì‹¤íŒ¨: {str(e)}")
            return {
                "status": "disconnected",
                "gateway_available": False,
                "error": str(e),
                "message": "Gateway ì—°ê²° ì‹¤íŒ¨ - ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
            }
    
    async def analyze_materiality_changes(
        self,
        company_name: str,
        current_year: int,
        base_assessment: Optional[MaterialityAssessment] = None,
        include_news: bool = True,
        max_articles: int = 100
    ) -> Dict[str, Any]:
        """ì¤‘ëŒ€ì„± í‰ê°€ ë³€í™” ë¶„ì„ ë° ì œì•ˆ ìƒì„±
        
        Args:
            company_name: ê¸°ì—…ëª…
            current_year: ë¶„ì„ ëŒ€ìƒ ì—°ë„
            base_assessment: ê¸°ì¤€ í‰ê°€ (ë³´í†µ ì „ë…„ë„)
            include_news: ë‰´ìŠ¤ ë¶„ì„ í¬í•¨ ì—¬ë¶€
            max_articles: ë¶„ì„í•  ìµœëŒ€ ë‰´ìŠ¤ ìˆ˜
            
        Returns:
            Dict[str, Any]: ë¶„ì„ ê²°ê³¼ ë° ì œì•ˆ ì‚¬í•­ (JSON í˜•íƒœ)
        """
        try:
            self.logger.info(f"ğŸ¯ {company_name} {current_year}ë…„ ì¤‘ëŒ€ì„± í‰ê°€ ë³€í™” ë¶„ì„ ì‹œì‘")
            
            # 1. ê¸°ì¤€ í‰ê°€ ë¡œë“œ (2024ë…„ SR ë³´ê³ ì„œ ë°ì´í„°)
            if base_assessment is None:
                base_assessment = self.file_service.load_company_assessment(
                    company_name, 2024
                )
        
            if not base_assessment:
                return await self._analyze_without_base_assessment(company_name, current_year)
            
            # 2. ë³€í™” ë¶„ì„ ìˆ˜í–‰
            try:
                evolution_analysis = await self.update_engine.analyze_materiality_evolution(
                    base_assessment, current_year, company_name
                )
                self.logger.info(f"ğŸ”„ ë³€í™” ë¶„ì„ ì™„ë£Œ: {len(evolution_analysis.get('topic_changes', []))}ê°œ í† í”½")
            except Exception as e:
                self.logger.error(f"âŒ ë³€í™” ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
                raise
            
            # 3. ì œì•ˆ ì‚¬í•­ ìƒì„±
            try:
                recommendations = self._generate_change_recommendations(
                    evolution_analysis, base_assessment
                )
                self.logger.info(f"ğŸ“‹ ì œì•ˆ ì‚¬í•­ ìƒì„± ì™„ë£Œ: {len(recommendations)}ê°œ")
            except Exception as e:
                self.logger.error(f"âŒ ì œì•ˆ ì‚¬í•­ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                raise
            
            # 4. ìš°ì„ ìˆœìœ„ ë³€í™” ì œì•ˆ
            try:
                priority_suggestions = self._generate_priority_suggestions(
                    evolution_analysis, base_assessment
                )
                self.logger.info(f"ğŸ”„ ìš°ì„ ìˆœìœ„ ì œì•ˆ ì™„ë£Œ: {len(priority_suggestions)}ê°œ")
            except Exception as e:
                self.logger.error(f"âŒ ìš°ì„ ìˆœìœ„ ì œì•ˆ ì‹¤íŒ¨: {str(e)}")
                raise
            
            # 5. ì‹ ê·œ ì´ìŠˆ ê²€í†  ì œì•ˆ (ë¹„í™œì„±í™”)
            try:
                # ì‹ ê·œ ì´ìŠˆ ë°œê²¬ ê¸°ëŠ¥ ë¹„í™œì„±í™”ë¡œ ì¸í•´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
                new_issue_suggestions = []
                self.logger.info(f"ğŸš« ì‹ ê·œ ì´ìŠˆ ì œì•ˆ ë¹„í™œì„±í™”: ê¸°ì¡´ í† í”½ ì¤‘ì‹¬ ë¶„ì„ì— ì§‘ì¤‘")
            except Exception as e:
                self.logger.error(f"âŒ ì‹ ê·œ ì´ìŠˆ ì œì•ˆ ì‹¤íŒ¨: {str(e)}")
                new_issue_suggestions = []
        
            # 6. ì¢…í•© ë¶„ì„ ê²°ê³¼ êµ¬ì„± (ê³µí†µ í—¬í¼ ì‚¬ìš©ìœ¼ë¡œ ê°„ì†Œí™”)
            analysis_result = self._build_comprehensive_analysis_result(
                evolution_analysis, recommendations, priority_suggestions, 
                new_issue_suggestions, company_name, current_year
            )
            
            self.logger.info(f"âœ… {company_name} ì¤‘ëŒ€ì„± í‰ê°€ ë³€í™” ë¶„ì„ ì™„ë£Œ")
            return analysis_result

        except Exception as e:
            # ì—ëŸ¬ ì²˜ë¦¬ (ê³µí†µ í—¬í¼ ì‚¬ìš©)
            return AnalysisErrorHandler.create_error_response(
                company_name, current_year, e, "ì¤‘ëŒ€ì„± í‰ê°€ ë³€í™” ë¶„ì„"
            )
    
    def _build_comprehensive_analysis_result(
        self,
        evolution_analysis: Dict[str, Any],
        recommendations: List[Dict[str, Any]],
        priority_suggestions: List[Dict[str, Any]],
        new_issue_suggestions: List[Dict[str, Any]],
        company_name: str,
        current_year: int
    ) -> Dict[str, Any]:
        """ì¢…í•© ë¶„ì„ ê²°ê³¼ êµ¬ì„± (ë¶„ë¦¬ëœ ë©”ì„œë“œ)"""
        try:
            self.logger.info("ğŸ”§ ì¢…í•© ë¶„ì„ ê²°ê³¼ êµ¬ì„± ì‹œì‘")
            
                        # 2. ê³µí†µ í—¬í¼ë¡œ ë©”íƒ€ë°ì´í„° ìƒì„± 
            analysis_metadata = MaterialityAnalysisHelper.create_analysis_metadata(
                company_name, current_year, 2024
            )
            
            # 3. ê³µí†µ í—¬í¼ë¡œ ë‰´ìŠ¤ ë¶„ì„ ìš”ì•½ ìƒì„±
            news_analysis_summary = MaterialityAnalysisHelper.create_news_analysis_summary(evolution_analysis)
            
            # 4. ê³µí†µ í—¬í¼ë¡œ ë³€í™” ë¶„ì„ ìƒì„±
            change_analysis = MaterialityAnalysisHelper.create_change_analysis(
                evolution_analysis, priority_suggestions, self.analysis_params['significance_threshold']
            )
            
            # 5. ê³µí†µ í—¬í¼ë¡œ ì•¡ì…˜ ì•„ì´í…œ ìƒì„±
            action_items = ActionItemGenerator.generate_action_items(evolution_analysis, recommendations)
            
            # 6. ê³µí†µ í—¬í¼ë¡œ ì‹ ë¢°ë„ í‰ê°€
            confidence_assessment = ConfidenceAssessment.assess_overall_confidence(evolution_analysis)
            
            # 7. ìµœì¢… ê²°ê³¼ ì¡°í•©
            return {
                "analysis_metadata": analysis_metadata,
                "news_analysis_summary": news_analysis_summary,
                "change_analysis": change_analysis,
                "recommendations": recommendations,
                "action_items": action_items,
                "confidence_assessment": confidence_assessment
            }
            
        except Exception as e:
            self.logger.error(f"ì¢…í•© ë¶„ì„ ê²°ê³¼ êµ¬ì„± ì‹¤íŒ¨: {str(e)}")
            return AnalysisErrorHandler.create_error_response(
                company_name, current_year, e, "ì¢…í•© ë¶„ì„ ê²°ê³¼ êµ¬ì„±"
            )

    # ===== ì§€ì› ë©”ì„œë“œë“¤ =====
    
    async def _analyze_without_base_assessment(
        self,
        company_name: str,
        current_year: int
    ) -> Dict[str, Any]:
        """ê¸°ì¤€ í‰ê°€ ì—†ì´ ë‰´ìŠ¤ ê¸°ë°˜ ì´ìŠˆ ë¶„ì„"""
        self.logger.info(f"ğŸ†• {company_name} ê¸°ì¤€ í‰ê°€ ì—†ìŒ, ë‰´ìŠ¤ ê¸°ë°˜ ì´ìŠˆ ë¶„ì„ ìˆ˜í–‰")
        
        # ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
        news_data = await self.update_engine._collect_current_news_data(
            company_name, current_year
        )
        
        if not news_data['articles']:
            return {
                "analysis_metadata": {
                    "company_name": company_name,
                    "analysis_year": current_year,
                    "analysis_date": datetime.now().isoformat(),
                    "analysis_type": "insufficient_data",
                    "disclaimer": "ë‰´ìŠ¤ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                },
                "error": "insufficient_news_data",
                "message": "ë¶„ì„ì— í•„ìš”í•œ ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            }
        
        # ë‰´ìŠ¤ì—ì„œ í•µì‹¬ ì´ìŠˆ ì¶”ì¶œ
        core_issues = await self._extract_potential_issues_from_news(
            news_data['articles'], company_name
        )
        
        return {
            "analysis_metadata": {
                "company_name": company_name,
                "analysis_year": current_year,
                "analysis_date": datetime.now().isoformat(),
                "analysis_type": "news_only_analysis",
                "disclaimer": "ê¸°ì¤€ í‰ê°€ê°€ ì—†ì–´ ë‰´ìŠ¤ ë°ì´í„°ë§Œìœ¼ë¡œ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ì‹¤ì œ ì¤‘ëŒ€ì„± í‰ê°€ì—ëŠ” ì¶”ê°€ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            },
            "news_analysis_summary": {
                "total_articles_analyzed": len(news_data['articles']),
                "analysis_period": news_data['metadata']['period'],
                "core_issues_found": len(core_issues)
            },
            "potential_issues": core_issues,
            "recommendations": [
                "ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¤‘ëŒ€ì„± í‰ê°€ ì´ˆì•ˆì„ ê²€í† í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.",
                "ë°œê²¬ëœ ì´ìŠˆë“¤ì— ëŒ€í•´ ì´í•´ê´€ê³„ìì™€ì˜ ì¶”ê°€ ë…¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                "SASB ë§¤í•‘ì„ í†µí•´ ì‚°ì—… í‘œì¤€ê³¼ì˜ ì¼ì¹˜ì„±ì„ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
            ],
            "confidence_assessment": {
                "overall_confidence": 0.5,
                "confidence_level": "medium",
                "limitations": [
                    "ê¸°ì¤€ í‰ê°€ ì—†ìŒìœ¼ë¡œ ë³€í™” ì¶”ì„¸ ë¶„ì„ ë¶ˆê°€",
                    "ë‰´ìŠ¤ ë°ì´í„°ë§Œìœ¼ë¡œëŠ” ì¤‘ëŒ€ì„± í‰ê°€ì˜ ìš°ì„ ìˆœìœ„ ê²°ì • í•œê³„",
                    "ì´í•´ê´€ê³„ì ì˜ê²¬ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ë¶„ì„ í•„ìš”"
                ]
            }
        }
    
    def _generate_change_recommendations(
        self,
        evolution_analysis: Dict[str, Any],
        base_assessment: MaterialityAssessment
    ) -> List[Dict[str, Any]]:
        """ë³€í™” ë¶„ì„ ê¸°ë°˜ ì¶”ì²œ ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # 1. ë†’ì€ ë³€í™” í† í”½ ì¶”ì²œ
        high_change_topics = [
            change for change in evolution_analysis['topic_changes']
            if abs(change['change_magnitude']) > self.analysis_params['significance_threshold']
        ]
        
        for change in high_change_topics[:5]:  # ìƒìœ„ 5ê°œ
            try:
                # ë””ë²„ê¹…: change ë”•ì…”ë„ˆë¦¬ êµ¬ì¡° í™•ì¸
                self.logger.error(f"ğŸ” change êµ¬ì¡°: {change}")
                self.logger.error(f"ğŸ” change keys: {list(change.keys())}")
                
                rec_type = "priority_review"
                change_magnitude = change.get('change_magnitude', 0.0)
                if change_magnitude > 0:
                    action = "ìš°ì„ ìˆœìœ„ ìƒí–¥ ê²€í† "
                    rationale = f"ë‰´ìŠ¤ í™œë™ ì¦ê°€ ({change_magnitude:+.2f})"
                else:
                    action = "ìš°ì„ ìˆœìœ„ í•˜í–¥ ê²€í† "
                    rationale = f"ë‰´ìŠ¤ í™œë™ ê°ì†Œ ({change_magnitude:+.2f})"
                
                # topic_name í‚¤ ì¡´ì¬ í™•ì¸
                topic_name = change.get('topic_name') or change.get('topic') or "unknown_topic"
                
                news_metrics = change.get('news_metrics', {})
                recommendations.append({
                    "type": rec_type,
                    "topic_name": topic_name,
                    "current_priority": change.get('previous_priority', 0),
                    "suggested_action": action,
                    "rationale": rationale,
                    "confidence": change.get('confidence', 0.5),
                    "news_evidence": {
                        "total_articles": news_metrics.get('total_articles', 0),
                        "relevant_articles": news_metrics.get('relevant_articles', 0),
                        "avg_sentiment": news_metrics.get('avg_sentiment', 'neutral')
                    }
                })
            except Exception as e:
                self.logger.error(f"âŒ high_change_topics ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸: {str(e)}")
                self.logger.error(f"âŒ change ë‚´ìš©: {change}")
                continue
        
        # 2. ì‹ ê·œ ì´ìŠˆ ì¶”ì²œ (ë¹„í™œì„±í™”)
        # ì‹ ê·œ ì´ìŠˆ ë°œê²¬ ê¸°ëŠ¥ ë¹„í™œì„±í™”ë¡œ ì´ ë¶€ë¶„ì€ ìƒëµ
        
        # 3. ì „ì²´ íŠ¸ë Œë“œ ê¸°ë°˜ ì¶”ì²œ
        overall_trend = evolution_analysis['overall_trend']
        if overall_trend['update_necessity'] == 'high':
            recommendations.append({
                "type": "overall_review",
                "suggested_action": "ì¤‘ëŒ€ì„± í‰ê°€ ì „ë©´ ì¬ê²€í† ",
                "rationale": f"ì „ì²´ ë³€í™” ê°•ë„ ë†’ìŒ ({overall_trend['avg_change_magnitude']:.2f})",
                "confidence": overall_trend['avg_confidence'],
                "scope": "comprehensive_review"
            })
        
        return recommendations[:self.analysis_params['max_recommendations']]
    
    def _generate_priority_suggestions(
        self,
        evolution_analysis: Dict[str, Any],
        base_assessment: MaterialityAssessment
    ) -> List[Dict[str, Any]]:
        """ìš°ì„ ìˆœìœ„ ë³€í™” ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        for change in evolution_analysis['topic_changes']:
            current_priority = change['previous_priority']
            change_magnitude = change['change_magnitude']
            
            # ì œì•ˆ ìš°ì„ ìˆœìœ„ ê³„ì‚° (ì°¸ê³ ìš©)
            if change_magnitude > 0.3:
                suggested_direction = "ìƒí–¥ ê²€í† "
                suggested_change = min(3, int(change_magnitude * 5))
            elif change_magnitude < -0.3:
                suggested_direction = "í•˜í–¥ ê²€í† "
                suggested_change = max(-3, int(change_magnitude * 5))
            else:
                suggested_direction = "í˜„ì¬ ìˆ˜ì¤€ ìœ ì§€"
                suggested_change = 0
            
            try:
                # topic_name í‚¤ ì¡´ì¬ í™•ì¸
                topic_name = change.get('topic_name') or change.get('topic') or "unknown_topic"
                
                suggestions.append({
                    "topic_name": topic_name,
                    "current_priority": current_priority,
                    "suggested_direction": suggested_direction,
                    "suggested_change": suggested_change,
                    "rationale": f"ë‰´ìŠ¤ ë¶„ì„ ì ìˆ˜ ë³€í™”: {change_magnitude:+.2f}",
                    "confidence": change.get('confidence', 0.5),
                    "change_type": change.get('change_type', 'unknown'),
                    "supporting_evidence": change.get('reasons', [])
                })
            except Exception as e:
                self.logger.error(f"âŒ change ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸: {str(e)}")
                self.logger.error(f"âŒ change ë‚´ìš©: {change}")
                continue
        
        return suggestions
    
    def _generate_new_issue_suggestions(
        self,
        evolution_analysis: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """ì‹ ê·œ ì´ìŠˆ ê²€í†  ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        for new_issue in evolution_analysis['new_issues']:
            if new_issue['issue_score'] > self.analysis_params['new_issue_threshold']:
                # SASB ë§¤í•‘ ì •ë³´
                sasb_mapping = new_issue.get('sasb_mapping', 'unmapped')
                
                suggestions.append({
                    "issue_name": new_issue['keyword'],
                    "discovery_rationale": new_issue['discovery_rationale'],
                    "issue_score": new_issue['issue_score'],
                    "frequency": new_issue['frequency'],
                    "confidence": new_issue['confidence'],
                    "sasb_relevance": sasb_mapping,
                    "suggested_action": "ì¤‘ëŒ€ì„± í‰ê°€ í¬í•¨ ê²€í† ",
                    "review_priority": "high" if new_issue['issue_score'] > 0.6 else "medium",
                    "supporting_evidence": {
                        "related_articles": new_issue['related_articles_count'],
                        "sample_headlines": [
                            article.get('title', 'No title')
                            for article in new_issue.get('sample_articles', [])[:3]
                        ]
                    }
                })
        
        return suggestions
    
    def _generate_action_items(
        self,
        evolution_analysis: Dict[str, Any],
        recommendations: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ ì•„ì´í…œ ìƒì„±"""
        action_items = []
        
        # 1. ì¦‰ì‹œ ê²€í†  í•„ìš” ì‚¬í•­
        high_priority_items = [
            rec for rec in recommendations
            if rec.get('confidence', 0) > self.analysis_params['high_confidence_threshold']
        ]
        
        if high_priority_items:
            action_items.append({
                "priority": "immediate",
                "action": "ë†’ì€ ì‹ ë¢°ë„ ë³€í™” ì‚¬í•­ ê²€í† ",
                "description": f"{len(high_priority_items)}ê°œ í•­ëª©ì— ëŒ€í•œ ì¦‰ì‹œ ê²€í†  í•„ìš”",
                "timeline": "1ì£¼ ì´ë‚´",
                "responsible": "ì¤‘ëŒ€ì„± í‰ê°€ ë‹´ë‹¹íŒ€",
                "items": [item.get('topic_name', 'unknown_topic') for item in high_priority_items]
            })
        
        # 2. ê¸°ì¡´ í† í”½ ë³€í™” ë¶„ì„
        topic_changes_count = len([
            change for change in evolution_analysis.get('topic_changes', [])
            if abs(change.get('change_magnitude', 0)) > self.analysis_params['significance_threshold']
        ])
        
        if topic_changes_count > 0:
            action_items.append({
                "priority": "medium",
                "action": "í† í”½ë³„ ë³€í™” ë¶„ì„ ê²€í† ",
                "description": f"{topic_changes_count}ê°œ í† í”½ì—ì„œ ì¤‘ìš”í•œ ë³€í™” ê°ì§€ë¨",
                "timeline": "2ì£¼ ì´ë‚´", 
                "responsible": "ESG íŒ€, ì‚¬ì—…ë¶€ ë‹´ë‹¹ì",
                "details": "ê° í† í”½ë³„ ë‰´ìŠ¤ ì–¸ê¸‰ë„ ë³€í™”ì™€ ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê²€í† "
            })
        
        # 3. ì „ì²´ ì—…ë°ì´íŠ¸ í•„ìš”ì„±
        if evolution_analysis['overall_trend']['update_necessity'] == 'high':
            action_items.append({
                "priority": "high",
                "action": "ì¤‘ëŒ€ì„± í‰ê°€ ì „ë©´ ì¬ê²€í† ",
                "description": "ì „ì²´ì ì¸ ë³€í™” ê°•ë„ê°€ ë†’ì•„ ì¤‘ëŒ€ì„± í‰ê°€ ì „ë©´ ì¬ê²€í†  í•„ìš”",
                "timeline": "1ê°œì›” ì´ë‚´",
                "responsible": "ì¤‘ëŒ€ì„± í‰ê°€ ìœ„ì›íšŒ",
                "scope": "comprehensive_review"
            })
        
        return action_items
    
    def _assess_overall_confidence(
        self,
        evolution_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì „ì²´ ë¶„ì„ ì‹ ë¢°ë„ í‰ê°€"""
        avg_confidence = evolution_analysis['overall_trend']['avg_confidence']
        news_count = evolution_analysis['news_data_summary']['total_articles']
        
        # ì‹ ë¢°ë„ ë ˆë²¨ ê²°ì •
        if avg_confidence > 0.7 and news_count > 50:
            confidence_level = "high"
            description = "ë¶„ì„ ê²°ê³¼ì— ë†’ì€ ì‹ ë¢°ë„ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        elif avg_confidence > 0.5 and news_count > 20:
            confidence_level = "medium"
            description = "ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ ìš©ìœ¼ë¡œ í™œìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤"
        else:
            confidence_level = "low"
            description = "ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ ë° ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤"
        
        # í•œê³„ì‚¬í•­ ì‹ë³„
        limitations = []
        if news_count < 20:
            limitations.append("ë‰´ìŠ¤ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ë¶„ì„ í•œê³„")
        if avg_confidence < 0.5:
            limitations.append("í‚¤ì›Œë“œ ë§¤ì¹­ ì •í™•ë„ í•œê³„")
        
        limitations.extend([
            "ë‰´ìŠ¤ ë°ì´í„°ë§Œìœ¼ë¡œëŠ” ì´í•´ê´€ê³„ì ê´€ì  ë°˜ì˜ í•œê³„",
            "ì •ëŸ‰ì  ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ë¶„ì„ ë¶€ì¡±",
            "ì‚¬ì—… ì „ëµ ë° ê·œì œ ë³€í™” ê³ ë ¤ í•„ìš”"
        ])
        
        return {
            "overall_confidence": avg_confidence,
            "confidence_level": confidence_level,
            "description": description,
            "limitations": limitations,
            "recommendation": "ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´í•´ê´€ê³„ì ì˜ê²¬ ìˆ˜ë ´ ë° ì „ë¬¸ê°€ ê²€í† ë¥¼ í†µí•´ ìµœì¢… ì¤‘ëŒ€ì„± í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        }
    
    async def _extract_potential_issues_from_news(
        self,
        news_articles: List[Dict[str, Any]],
        company_name: str
    ) -> List[Dict[str, Any]]:
        """ë‰´ìŠ¤ì—ì„œ ì ì¬ì  ì¤‘ëŒ€ì„± ì´ìŠˆ ì¶”ì¶œ"""
        # í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
        keyword_frequency = defaultdict(int)
        keyword_articles = defaultdict(list)
        
        for article in news_articles:
            title = article.get('title', '')
            content = article.get('content', '') or article.get('summary', '')
            full_text = title + ' ' + content
            
            keywords = self.news_engine._extract_keywords_from_text(full_text)
            for keyword in keywords:
                if len(keyword) > 2:
                    keyword_frequency[keyword] += 1
                    keyword_articles[keyword].append(article)
        
        # ìƒìœ„ í‚¤ì›Œë“œ ë¶„ì„
        top_keywords = sorted(keyword_frequency.items(), key=lambda x: x[1], reverse=True)[:20]
        
        potential_issues = []
        for keyword, frequency in top_keywords:
            if frequency >= 2:
                related_articles = keyword_articles[keyword]
                issue_score = self.update_engine._calculate_new_issue_score(
                    related_articles, keyword, frequency
                )
                
                if issue_score > 0.2:
                    potential_issues.append({
                        "issue_name": keyword,
                        "frequency": frequency,
                        "relevance_score": issue_score,
                        "confidence": min(issue_score / 1.0, 1.0),
                        "related_articles_count": len(related_articles),
                        "review_suggestion": "ì¤‘ëŒ€ì„± í‰ê°€ í¬í•¨ ê²€í†  í•„ìš”",
                        "sasb_mapping": self.mapping_service.get_sasb_code_by_topic(keyword)
                    })
        
        return sorted(potential_issues, key=lambda x: x['relevance_score'], reverse=True)[:10] 