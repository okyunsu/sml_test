from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
import logging
from collections import defaultdict
import math

from ..model.materiality_dto import MaterialityTopic, MaterialityAssessment
from .news_analysis_engine import NewsAnalysisEngine
from .materiality_update_engine import MaterialityUpdateEngine
from .materiality_mapping_service import MaterialityMappingService
from .materiality_file_service import MaterialityFileService

logger = logging.getLogger(__name__)

class MaterialityAnalysisService:
    """ì¤‘ëŒ€ì„± í‰ê°€ ë³€í™” ë¶„ì„ ì„œë¹„ìŠ¤
    
    ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¤‘ëŒ€ì„± í‰ê°€ ë³€í™” ê°€ëŠ¥ì„±ì„ ë¶„ì„:
    - ìš°ì„ ìˆœìœ„ ë³€í™” ê°€ëŠ¥ì„± ì œì•ˆ
    - ì‹ ê·œ ì´ìŠˆ ë°œêµ´ ë° ê²€í†  ì œì•ˆ
    - ê¸°ì¡´ ì´ìŠˆ ì¤‘ìš”ë„ ë³€í™” ë¶„ì„
    - SASB ë§¤í•‘ ê¸°ë°˜ ê´€ë ¨ì„± ë¶„ì„
    
    ì£¼ì˜: ë‰´ìŠ¤ ë¶„ì„ë§Œìœ¼ë¡œëŠ” í™•ì •ì ì¸ ì¤‘ëŒ€ì„± í‰ê°€ë¥¼ ë‚´ë¦´ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ,
    ëª¨ë“  ê²°ê³¼ëŠ” ì°¸ê³ ìš© ë¶„ì„ ë° ì œì•ˆ ì‚¬í•­ì…ë‹ˆë‹¤.
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.news_engine = NewsAnalysisEngine()
        self.update_engine = MaterialityUpdateEngine()
        self.mapping_service = MaterialityMappingService()
        self.file_service = MaterialityFileService()
        
        # Gateway í´ë¼ì´ì–¸íŠ¸ ì¶”ê°€
        from ...core.gateway_client import GatewayClient
        self.gateway_client = GatewayClient()
        
        # ë¶„ì„ íŒŒë¼ë¯¸í„° ì„¤ì •
        self.analysis_params = {
            'significance_threshold': 0.3,  # ì¤‘ìš”í•œ ë³€í™” ì„ê³„ê°’
            'new_issue_threshold': 0.4,     # ì‹ ê·œ ì´ìŠˆ ê²€í†  ì„ê³„ê°’
            'high_confidence_threshold': 0.7,  # ë†’ì€ ì‹ ë¢°ë„ ì„ê³„ê°’
            'max_recommendations': 10       # ìµœëŒ€ ì¶”ì²œ ê°œìˆ˜
        }
    
    async def check_gateway_connection(self) -> Dict[str, Any]:
        """Gateway ì—°ê²° ìƒíƒœ í™•ì¸"""
        try:
            # Gateway í—¬ìŠ¤ì²´í¬ ìˆ˜í–‰
            health_status = await self.gateway_client.get_sasb_health_check()
            return {
                "status": "connected",
                "gateway_available": True,
                "services": health_status,
                "message": "Gateway ì—°ê²° ì •ìƒ"
            }
        except Exception as e:
            self.logger.warning(f"Gateway ì—°ê²° í™•ì¸ ì‹¤íŒ¨: {str(e)}")
            return {
                "status": "disconnected",
                "gateway_available": False,
                "error": str(e),
                "message": "Gateway ì—°ê²° ì‹¤íŒ¨ - ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
            }
    
    async def analyze_materiality_changes(
        self,
        company_name: str,
        current_year: int,
        base_assessment: Optional[MaterialityAssessment] = None,
        include_news: bool = True,
        max_articles: int = 100
    ) -> Dict[str, Any]:
        """ì¤‘ëŒ€ì„± í‰ê°€ ë³€í™” ë¶„ì„ ë° ì œì•ˆ ìƒì„±
        
        Args:
            company_name: ê¸°ì—…ëª…
            current_year: ë¶„ì„ ëŒ€ìƒ ì—°ë„
            base_assessment: ê¸°ì¤€ í‰ê°€ (ë³´í†µ ì „ë…„ë„)
            include_news: ë‰´ìŠ¤ ë¶„ì„ í¬í•¨ ì—¬ë¶€
            max_articles: ë¶„ì„í•  ìµœëŒ€ ë‰´ìŠ¤ ìˆ˜
            
        Returns:
            Dict[str, Any]: ë¶„ì„ ê²°ê³¼ ë° ì œì•ˆ ì‚¬í•­ (JSON í˜•íƒœ)
        """
        try:
            self.logger.info(f"ğŸ¯ {company_name} {current_year}ë…„ ì¤‘ëŒ€ì„± í‰ê°€ ë³€í™” ë¶„ì„ ì‹œì‘")
        
        # 1. ê¸°ì¤€ í‰ê°€ ë¡œë“œ
        if base_assessment is None:
            base_assessment = self.file_service.load_company_assessment(
                company_name, current_year - 1
            )
        
        if not base_assessment:
            return await self._analyze_without_base_assessment(company_name, current_year)
        
        # 2. ë³€í™” ë¶„ì„ ìˆ˜í–‰
        try:
            evolution_analysis = await self.update_engine.analyze_materiality_evolution(
                base_assessment, current_year, company_name
            )
            self.logger.info(f"ğŸ”„ ë³€í™” ë¶„ì„ ì™„ë£Œ: {len(evolution_analysis.get('topic_changes', []))}ê°œ í† í”½")
        except Exception as e:
            self.logger.error(f"âŒ ë³€í™” ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            raise
        
        # 3. ì œì•ˆ ì‚¬í•­ ìƒì„±
        try:
            recommendations = self._generate_change_recommendations(
                evolution_analysis, base_assessment
            )
            self.logger.info(f"ğŸ“‹ ì œì•ˆ ì‚¬í•­ ìƒì„± ì™„ë£Œ: {len(recommendations)}ê°œ")
        except Exception as e:
            self.logger.error(f"âŒ ì œì•ˆ ì‚¬í•­ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
        
        # 4. ìš°ì„ ìˆœìœ„ ë³€í™” ì œì•ˆ
        try:
            priority_suggestions = self._generate_priority_suggestions(
                evolution_analysis, base_assessment
            )
            self.logger.info(f"ğŸ”„ ìš°ì„ ìˆœìœ„ ì œì•ˆ ì™„ë£Œ: {len(priority_suggestions)}ê°œ")
        except Exception as e:
            self.logger.error(f"âŒ ìš°ì„ ìˆœìœ„ ì œì•ˆ ì‹¤íŒ¨: {str(e)}")
            raise
        
        # 5. ì‹ ê·œ ì´ìŠˆ ê²€í†  ì œì•ˆ
        try:
            new_issue_suggestions = self._generate_new_issue_suggestions(
                evolution_analysis
            )
            self.logger.info(f"ğŸ†• ì‹ ê·œ ì´ìŠˆ ì œì•ˆ ì™„ë£Œ: {len(new_issue_suggestions)}ê°œ")
        except Exception as e:
            self.logger.error(f"âŒ ì‹ ê·œ ì´ìŠˆ ì œì•ˆ ì‹¤íŒ¨: {str(e)}")
            raise
        
        # 6. ì¢…í•© ë¶„ì„ ê²°ê³¼ êµ¬ì„±
        try:
            self.logger.info("ğŸ”§ ì¢…í•© ë¶„ì„ ê²°ê³¼ êµ¬ì„± ì‹œì‘")
            
            # 6-1. ê¸°ë³¸ ë©”íƒ€ë°ì´í„°
            analysis_metadata = {
                "company_name": company_name,
                "analysis_year": current_year,
                "base_year": base_assessment.year,
                "analysis_date": datetime.now().isoformat(),
                "analysis_type": "news_based_change_analysis",
                "disclaimer": "ì´ ë¶„ì„ì€ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì°¸ê³ ìš© ì œì•ˆ ì‚¬í•­ì…ë‹ˆë‹¤. ì‹¤ì œ ì¤‘ëŒ€ì„± í‰ê°€ì—ëŠ” ì¶”ê°€ì ì¸ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            }
            self.logger.info("âœ… 6-1. ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ì™„ë£Œ")
            
            # 6-2. ë‰´ìŠ¤ ë¶„ì„ ìš”ì•½
            news_analysis_summary = {
                "total_articles_analyzed": evolution_analysis['news_data_summary']['total_articles'],
                "analysis_period": evolution_analysis['news_data_summary']['analysis_period'],
                "overall_trend": evolution_analysis['overall_trend']['overall_direction'],
                "update_necessity": evolution_analysis['overall_trend']['update_necessity'],
                "confidence_level": evolution_analysis['overall_trend']['avg_confidence']
            }
            self.logger.info("âœ… 6-2. ë‰´ìŠ¤ ë¶„ì„ ìš”ì•½ ì™„ë£Œ")
            
            # 6-3. ë³€í™” ë¶„ì„ (ì—¬ê¸°ì„œ ì—ëŸ¬ ê°€ëŠ¥ì„± ë†’ìŒ)
            try:
                significant_changes = len([
                    change for change in evolution_analysis['topic_changes']
                    if abs(change['change_magnitude']) > self.analysis_params['significance_threshold']
                ])
                self.logger.info(f"âœ… 6-3-a. ì¤‘ìš” ë³€í™” ê³„ì‚° ì™„ë£Œ: {significant_changes}ê°œ")
            except Exception as e:
                self.logger.error(f"âŒ 6-3-a. ì¤‘ìš” ë³€í™” ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
                raise
            
            change_analysis = {
                "existing_topics": priority_suggestions,
                "new_issues_discovered": new_issue_suggestions,
                "change_distribution": evolution_analysis['overall_trend']['change_distribution'],
                "significant_changes": significant_changes
            }
            self.logger.info("âœ… 6-3. ë³€í™” ë¶„ì„ ì™„ë£Œ")
            
            # 6-4. ì•¡ì…˜ ì•„ì´í…œ ìƒì„±
            try:
                action_items = self._generate_action_items(evolution_analysis, recommendations)
                self.logger.info("âœ… 6-4. ì•¡ì…˜ ì•„ì´í…œ ìƒì„± ì™„ë£Œ")
            except Exception as e:
                self.logger.error(f"âŒ 6-4. ì•¡ì…˜ ì•„ì´í…œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                raise
            
            # 6-5. ì‹ ë¢°ë„ í‰ê°€
            try:
                confidence_assessment = self._assess_overall_confidence(evolution_analysis)
                self.logger.info("âœ… 6-5. ì‹ ë¢°ë„ í‰ê°€ ì™„ë£Œ")
            except Exception as e:
                self.logger.error(f"âŒ 6-5. ì‹ ë¢°ë„ í‰ê°€ ì‹¤íŒ¨: {str(e)}")
                raise
            
            # 6-6. ìµœì¢… ê²°ê³¼ ì¡°í•©
            analysis_result = {
                "analysis_metadata": analysis_metadata,
                "news_analysis_summary": news_analysis_summary,
                "change_analysis": change_analysis,
                "recommendations": recommendations,
                "action_items": action_items,
                "confidence_assessment": confidence_assessment
            }
            
            self.logger.info("âœ… 6. ì¢…í•© ë¶„ì„ ê²°ê³¼ êµ¬ì„± ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ 6. ì¢…í•© ë¶„ì„ ê²°ê³¼ êµ¬ì„± ì‹¤íŒ¨: {str(e)}")
            # ë””ë²„ê¹…ì„ ìœ„í•œ ìƒì„¸ ì •ë³´
            self.logger.error(f"ğŸ” evolution_analysis keys: {list(evolution_analysis.keys())}")
            if 'topic_changes' in evolution_analysis:
                self.logger.error(f"ğŸ” topic_changes ìƒ˜í”Œ: {evolution_analysis['topic_changes'][:1] if evolution_analysis['topic_changes'] else 'ë¹ˆ ë¦¬ìŠ¤íŠ¸'}")
            raise
        
            self.logger.info(f"âœ… {company_name} ì¤‘ëŒ€ì„± í‰ê°€ ë³€í™” ë¶„ì„ ì™„ë£Œ")
            return analysis_result
        
        except Exception as e:
            self.logger.error(f"ğŸ’¥ ì „ì²´ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {str(e)}")
            self.logger.error(f"ğŸ’¥ ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
            import traceback
            self.logger.error(f"ğŸ’¥ ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
            raise
    
    async def _analyze_without_base_assessment(
        self,
        company_name: str,
        current_year: int
    ) -> Dict[str, Any]:
        """ê¸°ì¤€ í‰ê°€ ì—†ì´ ë‰´ìŠ¤ ê¸°ë°˜ ì´ìŠˆ ë¶„ì„"""
        self.logger.info(f"ğŸ†• {company_name} ê¸°ì¤€ í‰ê°€ ì—†ìŒ, ë‰´ìŠ¤ ê¸°ë°˜ ì´ìŠˆ ë¶„ì„ ìˆ˜í–‰")
        
        # ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
        news_data = await self.update_engine._collect_current_news_data(
            company_name, current_year
        )
        
        if not news_data['articles']:
            return {
                "analysis_metadata": {
                    "company_name": company_name,
                    "analysis_year": current_year,
                    "analysis_date": datetime.now().isoformat(),
                    "analysis_type": "insufficient_data",
                    "disclaimer": "ë‰´ìŠ¤ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                },
                "error": "insufficient_news_data",
                "message": "ë¶„ì„ì— í•„ìš”í•œ ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            }
        
        # ë‰´ìŠ¤ì—ì„œ í•µì‹¬ ì´ìŠˆ ì¶”ì¶œ
        core_issues = await self._extract_potential_issues_from_news(
            news_data['articles'], company_name
        )
        
        return {
            "analysis_metadata": {
                "company_name": company_name,
                "analysis_year": current_year,
                "analysis_date": datetime.now().isoformat(),
                "analysis_type": "news_only_analysis",
                "disclaimer": "ê¸°ì¤€ í‰ê°€ê°€ ì—†ì–´ ë‰´ìŠ¤ ë°ì´í„°ë§Œìœ¼ë¡œ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ì‹¤ì œ ì¤‘ëŒ€ì„± í‰ê°€ì—ëŠ” ì¶”ê°€ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            },
            "news_analysis_summary": {
                "total_articles_analyzed": len(news_data['articles']),
                "analysis_period": news_data['metadata']['period'],
                "core_issues_found": len(core_issues)
            },
            "potential_issues": core_issues,
            "recommendations": [
                "ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¤‘ëŒ€ì„± í‰ê°€ ì´ˆì•ˆì„ ê²€í† í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.",
                "ë°œê²¬ëœ ì´ìŠˆë“¤ì— ëŒ€í•´ ì´í•´ê´€ê³„ìì™€ì˜ ì¶”ê°€ ë…¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                "SASB ë§¤í•‘ì„ í†µí•´ ì‚°ì—… í‘œì¤€ê³¼ì˜ ì¼ì¹˜ì„±ì„ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
            ],
            "confidence_assessment": {
                "overall_confidence": 0.5,
                "confidence_level": "medium",
                "limitations": [
                    "ê¸°ì¤€ í‰ê°€ ì—†ìŒìœ¼ë¡œ ë³€í™” ì¶”ì„¸ ë¶„ì„ ë¶ˆê°€",
                    "ë‰´ìŠ¤ ë°ì´í„°ë§Œìœ¼ë¡œëŠ” ì¤‘ëŒ€ì„± í‰ê°€ì˜ ìš°ì„ ìˆœìœ„ ê²°ì • í•œê³„",
                    "ì´í•´ê´€ê³„ì ì˜ê²¬ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ë¶„ì„ í•„ìš”"
                ]
            }
        }
    
    def _generate_change_recommendations(
        self,
        evolution_analysis: Dict[str, Any],
        base_assessment: MaterialityAssessment
    ) -> List[Dict[str, Any]]:
        """ë³€í™” ë¶„ì„ ê¸°ë°˜ ì¶”ì²œ ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # 1. ë†’ì€ ë³€í™” í† í”½ ì¶”ì²œ
        high_change_topics = [
            change for change in evolution_analysis['topic_changes']
            if abs(change['change_magnitude']) > self.analysis_params['significance_threshold']
        ]
        
        for change in high_change_topics[:5]:  # ìƒìœ„ 5ê°œ
            rec_type = "priority_review"
            if change['change_magnitude'] > 0:
                action = "ìš°ì„ ìˆœìœ„ ìƒí–¥ ê²€í† "
                rationale = f"ë‰´ìŠ¤ í™œë™ ì¦ê°€ ({change['change_magnitude']:+.2f})"
            else:
                action = "ìš°ì„ ìˆœìœ„ í•˜í–¥ ê²€í† "
                rationale = f"ë‰´ìŠ¤ í™œë™ ê°ì†Œ ({change['change_magnitude']:+.2f})"
            
            recommendations.append({
                "type": rec_type,
                "topic_name": change['topic_name'],
                "current_priority": change['previous_priority'],
                "suggested_action": action,
                "rationale": rationale,
                "confidence": change['confidence'],
                "news_evidence": {
                    "total_articles": change['news_metrics']['total_articles'],
                    "relevant_articles": change['news_metrics']['relevant_articles'],
                    "avg_sentiment": change['news_metrics']['avg_sentiment']
                }
            })
        
        # 2. ì‹ ê·œ ì´ìŠˆ ì¶”ì²œ
        for new_issue in evolution_analysis['new_issues'][:3]:  # ìƒìœ„ 3ê°œ
            if new_issue['issue_score'] > self.analysis_params['new_issue_threshold']:
                recommendations.append({
                    "type": "new_issue_review",
                    "topic_name": new_issue['keyword'],
                    "suggested_action": "ì‹ ê·œ ì¤‘ëŒ€ì„± ì´ìŠˆ ê²€í† ",
                    "rationale": f"ë‰´ìŠ¤ì—ì„œ {new_issue['frequency']}íšŒ ì–¸ê¸‰, ì´ìŠˆ ì ìˆ˜ {new_issue['issue_score']:.2f}",
                    "confidence": new_issue['confidence'],
                    "news_evidence": {
                        "frequency": new_issue['frequency'],
                        "related_articles": new_issue['related_articles_count'],
                        "sample_articles": new_issue.get('sample_articles', [])[:2]
                    }
                })
        
        # 3. ì „ì²´ íŠ¸ë Œë“œ ê¸°ë°˜ ì¶”ì²œ
        overall_trend = evolution_analysis['overall_trend']
        if overall_trend['update_necessity'] == 'high':
            recommendations.append({
                "type": "overall_review",
                "suggested_action": "ì¤‘ëŒ€ì„± í‰ê°€ ì „ë©´ ì¬ê²€í† ",
                "rationale": f"ì „ì²´ ë³€í™” ê°•ë„ ë†’ìŒ ({overall_trend['avg_change_magnitude']:.2f})",
                "confidence": overall_trend['avg_confidence'],
                "scope": "comprehensive_review"
            })
        
        return recommendations[:self.analysis_params['max_recommendations']]
    
    def _generate_priority_suggestions(
        self,
        evolution_analysis: Dict[str, Any],
        base_assessment: MaterialityAssessment
    ) -> List[Dict[str, Any]]:
        """ìš°ì„ ìˆœìœ„ ë³€í™” ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        for change in evolution_analysis['topic_changes']:
            current_priority = change['previous_priority']
            change_magnitude = change['change_magnitude']
            
            # ì œì•ˆ ìš°ì„ ìˆœìœ„ ê³„ì‚° (ì°¸ê³ ìš©)
            if change_magnitude > 0.3:
                suggested_direction = "ìƒí–¥ ê²€í† "
                suggested_change = min(3, int(change_magnitude * 5))
            elif change_magnitude < -0.3:
                suggested_direction = "í•˜í–¥ ê²€í† "
                suggested_change = max(-3, int(change_magnitude * 5))
            else:
                suggested_direction = "í˜„ì¬ ìˆ˜ì¤€ ìœ ì§€"
                suggested_change = 0
            
            suggestions.append({
                "topic_name": change['topic_name'],
                "current_priority": current_priority,
                "suggested_direction": suggested_direction,
                "suggested_change": suggested_change,
                "rationale": f"ë‰´ìŠ¤ ë¶„ì„ ì ìˆ˜ ë³€í™”: {change_magnitude:+.2f}",
                "confidence": change['confidence'],
                "change_type": change['change_type'],
                "supporting_evidence": change['reasons']
            })
        
        return suggestions
    
    def _generate_new_issue_suggestions(
        self,
        evolution_analysis: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """ì‹ ê·œ ì´ìŠˆ ê²€í†  ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        for new_issue in evolution_analysis['new_issues']:
            if new_issue['issue_score'] > self.analysis_params['new_issue_threshold']:
                # SASB ë§¤í•‘ ì •ë³´
                sasb_mapping = new_issue.get('sasb_mapping', 'unmapped')
                
                suggestions.append({
                    "issue_name": new_issue['keyword'],
                    "discovery_rationale": new_issue['discovery_rationale'],
                    "issue_score": new_issue['issue_score'],
                    "frequency": new_issue['frequency'],
                    "confidence": new_issue['confidence'],
                    "sasb_relevance": sasb_mapping,
                    "suggested_action": "ì¤‘ëŒ€ì„± í‰ê°€ í¬í•¨ ê²€í† ",
                    "review_priority": "high" if new_issue['issue_score'] > 0.6 else "medium",
                    "supporting_evidence": {
                        "related_articles": new_issue['related_articles_count'],
                        "sample_headlines": [
                            article.get('title', 'No title')
                            for article in new_issue.get('sample_articles', [])[:3]
                        ]
                    }
                })
        
        return suggestions
    
    def _generate_action_items(
        self,
        evolution_analysis: Dict[str, Any],
        recommendations: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ ì•„ì´í…œ ìƒì„±"""
        action_items = []
        
        # 1. ì¦‰ì‹œ ê²€í†  í•„ìš” ì‚¬í•­
        high_priority_items = [
            rec for rec in recommendations
            if rec.get('confidence', 0) > self.analysis_params['high_confidence_threshold']
        ]
        
        if high_priority_items:
            action_items.append({
                "priority": "immediate",
                "action": "ë†’ì€ ì‹ ë¢°ë„ ë³€í™” ì‚¬í•­ ê²€í† ",
                "description": f"{len(high_priority_items)}ê°œ í•­ëª©ì— ëŒ€í•œ ì¦‰ì‹œ ê²€í†  í•„ìš”",
                "timeline": "1ì£¼ ì´ë‚´",
                "responsible": "ì¤‘ëŒ€ì„± í‰ê°€ ë‹´ë‹¹íŒ€",
                "items": [item['topic_name'] for item in high_priority_items]
            })
        
        # 2. ì‹ ê·œ ì´ìŠˆ ê²€í† 
        new_issues_count = len(evolution_analysis['new_issues'])
        if new_issues_count > 0:
            action_items.append({
                "priority": "medium",
                "action": "ì‹ ê·œ ì´ìŠˆ ê²€í†  ë° í‰ê°€",
                "description": f"{new_issues_count}ê°œ ì‹ ê·œ ì´ìŠˆì— ëŒ€í•œ ì¤‘ëŒ€ì„± í‰ê°€ í•„ìš”ì„± ê²€í† ",
                "timeline": "2ì£¼ ì´ë‚´",
                "responsible": "ESG íŒ€, ì‚¬ì—…ë¶€ ë‹´ë‹¹ì",
                "items": [issue['keyword'] for issue in evolution_analysis['new_issues']]
            })
        
        # 3. ì „ì²´ ì—…ë°ì´íŠ¸ í•„ìš”ì„±
        if evolution_analysis['overall_trend']['update_necessity'] == 'high':
            action_items.append({
                "priority": "high",
                "action": "ì¤‘ëŒ€ì„± í‰ê°€ ì „ë©´ ì¬ê²€í† ",
                "description": "ì „ì²´ì ì¸ ë³€í™” ê°•ë„ê°€ ë†’ì•„ ì¤‘ëŒ€ì„± í‰ê°€ ì „ë©´ ì¬ê²€í†  í•„ìš”",
                "timeline": "1ê°œì›” ì´ë‚´",
                "responsible": "ì¤‘ëŒ€ì„± í‰ê°€ ìœ„ì›íšŒ",
                "scope": "comprehensive_review"
            })
        
        return action_items
    
    def _assess_overall_confidence(
        self,
        evolution_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì „ì²´ ë¶„ì„ ì‹ ë¢°ë„ í‰ê°€"""
        avg_confidence = evolution_analysis['overall_trend']['avg_confidence']
        news_count = evolution_analysis['news_data_summary']['total_articles']
        
        # ì‹ ë¢°ë„ ë ˆë²¨ ê²°ì •
        if avg_confidence > 0.7 and news_count > 50:
            confidence_level = "high"
            description = "ë¶„ì„ ê²°ê³¼ì— ë†’ì€ ì‹ ë¢°ë„ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        elif avg_confidence > 0.5 and news_count > 20:
            confidence_level = "medium"
            description = "ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ ìš©ìœ¼ë¡œ í™œìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤"
        else:
            confidence_level = "low"
            description = "ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ ë° ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤"
        
        # í•œê³„ì‚¬í•­ ì‹ë³„
        limitations = []
        if news_count < 20:
            limitations.append("ë‰´ìŠ¤ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ë¶„ì„ í•œê³„")
        if avg_confidence < 0.5:
            limitations.append("í‚¤ì›Œë“œ ë§¤ì¹­ ì •í™•ë„ í•œê³„")
        
        limitations.extend([
            "ë‰´ìŠ¤ ë°ì´í„°ë§Œìœ¼ë¡œëŠ” ì´í•´ê´€ê³„ì ê´€ì  ë°˜ì˜ í•œê³„",
            "ì •ëŸ‰ì  ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ë¶„ì„ ë¶€ì¡±",
            "ì‚¬ì—… ì „ëµ ë° ê·œì œ ë³€í™” ê³ ë ¤ í•„ìš”"
        ])
        
        return {
            "overall_confidence": avg_confidence,
            "confidence_level": confidence_level,
            "description": description,
            "limitations": limitations,
            "recommendation": "ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´í•´ê´€ê³„ì ì˜ê²¬ ìˆ˜ë ´ ë° ì „ë¬¸ê°€ ê²€í† ë¥¼ í†µí•´ ìµœì¢… ì¤‘ëŒ€ì„± í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        }
    
    async def _extract_potential_issues_from_news(
        self,
        news_articles: List[Dict[str, Any]],
        company_name: str
    ) -> List[Dict[str, Any]]:
        """ë‰´ìŠ¤ì—ì„œ ì ì¬ì  ì¤‘ëŒ€ì„± ì´ìŠˆ ì¶”ì¶œ"""
        # í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
        keyword_frequency = defaultdict(int)
        keyword_articles = defaultdict(list)
        
        for article in news_articles:
            title = article.get('title', '')
            content = article.get('content', '') or article.get('summary', '')
            full_text = title + ' ' + content
            
            keywords = self.news_engine._extract_keywords_from_text(full_text)
            for keyword in keywords:
                if len(keyword) > 2:
                    keyword_frequency[keyword] += 1
                    keyword_articles[keyword].append(article)
        
        # ìƒìœ„ í‚¤ì›Œë“œ ë¶„ì„
        top_keywords = sorted(keyword_frequency.items(), key=lambda x: x[1], reverse=True)[:20]
        
        potential_issues = []
        for keyword, frequency in top_keywords:
            if frequency >= 2:
                related_articles = keyword_articles[keyword]
                issue_score = self.update_engine._calculate_new_issue_score(
                    related_articles, keyword, frequency
                )
                
                if issue_score > 0.2:
                    potential_issues.append({
                        "issue_name": keyword,
                        "frequency": frequency,
                        "relevance_score": issue_score,
                        "confidence": min(issue_score / 1.0, 1.0),
                        "related_articles_count": len(related_articles),
                        "review_suggestion": "ì¤‘ëŒ€ì„± í‰ê°€ í¬í•¨ ê²€í†  í•„ìš”",
                        "sasb_mapping": self.mapping_service.get_sasb_code_by_topic(keyword)
                    })
        
        return sorted(potential_issues, key=lambda x: x['relevance_score'], reverse=True)[:10] 