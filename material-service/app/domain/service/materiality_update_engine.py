from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
import logging
from collections import defaultdict
import math

from ..model.materiality_dto import (
    MaterialityTopic, MaterialityAssessment, MaterialityHistory,
    MaterialityTrendAnalysis, IssueChangeType, MaterialityUpdateRecommendation
)
from .news_analysis_engine import NewsAnalysisEngine
from .materiality_mapping_service import MaterialityMappingService
from ...core.gateway_client import GatewayClient

logger = logging.getLogger(__name__)

class MaterialityUpdateEngine:
    """ì¤‘ëŒ€ì„± í‰ê°€ ì—…ë°ì´íŠ¸ ì—”ì§„
    
    ì „ë…„ë„ ì¤‘ëŒ€ì„± í‰ê°€ì™€ ë‹¹ë…„ ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬:
    - ë³€í™” ì¶”ì„¸ ë¶„ì„
    - ìš°ì„ ìˆœìœ„ ë³€ë™ ê°ì§€
    - ì‹ ê·œ ì´ìŠˆ ë°œêµ´
    - ì—…ë°ì´íŠ¸ í•„ìš”ì„± íŒë‹¨
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.news_engine = NewsAnalysisEngine()
        self.mapping_service = MaterialityMappingService()
        self.gateway_client = GatewayClient()
        
        # ë³€í™” ê°ì§€ ì„ê³„ê°’ ì„¤ì •
        self.thresholds = {
            'significant_change': 0.3,      # ì¤‘ìš”í•œ ë³€í™” ì„ê³„ê°’
            'emerging_issue': 0.5,          # ë¶€ìƒ ì´ìŠˆ ì„ê³„ê°’
            'declining_issue': 0.2,         # ì‡ í‡´ ì´ìŠˆ ì„ê³„ê°’
            'new_issue_score': 0.4,         # ì‹ ê·œ ì´ìŠˆ ì ìˆ˜ ì„ê³„ê°’
            'priority_change': 2            # ìš°ì„ ìˆœìœ„ ë³€í™” ì„ê³„ê°’
        }
    
    async def analyze_materiality_evolution(
        self,
        previous_assessment: MaterialityAssessment,
        current_year: int,
        company_name: str
    ) -> Dict[str, Any]:
        """ì¤‘ëŒ€ì„± í‰ê°€ ë³€í™” ë¶„ì„
        
        Args:
            previous_assessment: ì „ë…„ë„ ì¤‘ëŒ€ì„± í‰ê°€
            current_year: ë‹¹ë…„ë„
            company_name: ê¸°ì—…ëª…
            
        Returns:
            Dict[str, Any]: ë³€í™” ë¶„ì„ ê²°ê³¼
        """
        self.logger.info(f"ğŸ”„ ì¤‘ëŒ€ì„± í‰ê°€ ë³€í™” ë¶„ì„ ì‹œì‘: {company_name} {current_year}")
        
        # 1. í˜„ì¬ ì—°ë„ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
        current_news_data = await self._collect_current_news_data(company_name, current_year)
        
        # 2. ë‰´ìŠ¤ ë°ì´í„° ë¶„ì„
        news_analysis_results = self.news_engine.analyze_news_for_materiality(
            current_news_data['articles'],
            previous_assessment.topics,
            company_name
        )
        
        # 3. í† í”½ë³„ ë³€í™” ë¶„ì„
        topic_changes = self._analyze_topic_changes(
            previous_assessment.topics,
            news_analysis_results
        )
        
        # 4. ì‹ ê·œ ì´ìŠˆ ë°œêµ´
        new_issues = await self._discover_new_issues(
            current_news_data['articles'],
            previous_assessment.topics,
            company_name
        )
        
        # 5. ì „ì²´ ë³€í™” íŠ¸ë Œë“œ ë¶„ì„
        overall_trend = self._analyze_overall_trend(
            topic_changes,
            new_issues,
            current_news_data['metadata']
        )
        
        # 6. ì—…ë°ì´íŠ¸ ìš°ì„ ìˆœìœ„ ê³„ì‚°
        update_priorities = self._calculate_update_priorities(
            topic_changes,
            new_issues,
            overall_trend
        )
        
        evolution_analysis = {
            'analysis_date': datetime.now().isoformat(),
            'company_name': company_name,
            'previous_year': previous_assessment.year,
            'current_year': current_year,
            'news_data_summary': {
                'total_articles': len(current_news_data['articles']),
                'analysis_period': current_news_data['metadata']['period'],
                'data_sources': current_news_data['metadata']['sources']
            },
            'topic_changes': topic_changes,
            'new_issues': new_issues,
            'overall_trend': overall_trend,
            'update_priorities': update_priorities,
            'recommendations': self._generate_update_recommendations(
                topic_changes, new_issues, overall_trend
            )
        }
        
        self.logger.info(f"âœ… ì¤‘ëŒ€ì„± í‰ê°€ ë³€í™” ë¶„ì„ ì™„ë£Œ: {len(topic_changes)}ê°œ í† í”½ ë¶„ì„")
        return evolution_analysis
    
    async def _collect_current_news_data(
        self,
        company_name: str,
        year: int
    ) -> Dict[str, Any]:
        """í˜„ì¬ ì—°ë„ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            # 1. sasb-serviceì—ì„œ ê¸°ì—… ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘
            date_range = {
                'start_date': f"{year}-01-01",
                'end_date': f"{year}-12-31"
            }
            
            # ê¸°ì—…ëª… + SASB í‚¤ì›Œë“œë¡œ ê²€ìƒ‰
            sasb_keywords = self.mapping_service.get_sasb_issue_keywords()
            company_keywords = [company_name] + sasb_keywords[:10]  # ìƒìœ„ 10ê°œ SASB í‚¤ì›Œë“œ
            
            news_result = await self.gateway_client.search_news_by_keywords(
                keywords=company_keywords,
                date_range=date_range,
                limit=500
            )
            
            articles = news_result.get('results', [])
            
            return {
                'articles': articles,
                'metadata': {
                    'period': f"{year}-01-01 ~ {year}-12-31",
                    'sources': ['sasb-service'],
                    'search_keywords': company_keywords,
                    'total_found': len(articles)
                }
            }
            
        except Exception as e:
            self.logger.error(f"ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            return {
                'articles': [],
                'metadata': {
                    'period': f"{year}-01-01 ~ {year}-12-31",
                    'sources': [],
                    'search_keywords': [],
                    'total_found': 0,
                    'error': str(e)
                }
            }
    
    def _analyze_topic_changes(
        self,
        previous_topics: List[MaterialityTopic],
        news_analysis_results: Dict[str, Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """í† í”½ë³„ ë³€í™” ë¶„ì„"""
        topic_changes = []
        
        for topic in previous_topics:
            topic_name = topic.topic_name
            previous_priority = topic.priority
            
            # ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ì—ì„œ í•´ë‹¹ í† í”½ì˜ í˜„ì¬ ìƒíƒœ í™•ì¸
            current_analysis = news_analysis_results.get(topic_name, {})
            
            if not current_analysis:
                # ë‰´ìŠ¤ì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°
                change_analysis = {
                    'topic_name': topic_name,
                    'previous_priority': previous_priority,
                    'current_score': 0.0,
                    'change_type': IssueChangeType.DECLINING.value,
                    'change_magnitude': -1.0,
                    'trend_direction': 'declining',
                    'confidence': 0.3,
                    'reasons': ['ë‰´ìŠ¤ì—ì„œ ê´€ë ¨ ë‚´ìš© ë¶€ì¡±'],
                    'news_metrics': {
                        'total_articles': 0,
                        'relevant_articles': 0,
                        'avg_sentiment': 'neutral'
                    }
                }
            else:
                # ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ë³€í™” ë¶„ì„
                current_score = current_analysis['comprehensive_score']
                change_magnitude = self._calculate_change_magnitude(
                    previous_priority, current_score
                )
                
                change_type = self._determine_change_type(
                    previous_priority, current_score, change_magnitude
                )
                
                confidence = self._calculate_confidence_score(current_analysis)
                
                change_analysis = {
                    'topic_name': topic_name,
                    'previous_priority': previous_priority,
                    'current_score': current_score,
                    'change_type': change_type,
                    'change_magnitude': change_magnitude,
                    'trend_direction': current_analysis['trend_analysis']['trend_direction'],
                    'confidence': confidence,
                    'reasons': self._generate_change_reasons(
                        change_type, current_analysis, change_magnitude
                    ),
                    'news_metrics': {
                        'total_articles': current_analysis['total_news_count'],
                        'relevant_articles': current_analysis['relevant_news_count'],
                        'avg_sentiment': current_analysis['trend_analysis']['avg_sentiment']
                    },
                    'detailed_analysis': current_analysis
                }
            
            topic_changes.append(change_analysis)
        
        return topic_changes
    
    def _calculate_change_magnitude(
        self,
        previous_priority: int,
        current_score: float
    ) -> float:
        """ë³€í™” í¬ê¸° ê³„ì‚°"""
        # ì´ì „ ìš°ì„ ìˆœìœ„ë¥¼ ì ìˆ˜ë¡œ ë³€í™˜ (ë‚®ì€ ìš°ì„ ìˆœìœ„ = ë†’ì€ ì ìˆ˜)
        max_priority = 10  # ê°€ì •: ìµœëŒ€ ìš°ì„ ìˆœìœ„ëŠ” 10
        previous_score = (max_priority - previous_priority + 1) / max_priority
        
        # í˜„ì¬ ì ìˆ˜ì™€ ë¹„êµ
        change_magnitude = current_score - previous_score
        
        return round(change_magnitude, 3)
    
    def _determine_change_type(
        self,
        previous_priority: int,
        current_score: float,
        change_magnitude: float
    ) -> str:
        """ë³€í™” ìœ í˜• ê²°ì •"""
        if change_magnitude > self.thresholds['significant_change']:
            return IssueChangeType.EMERGING.value
        elif change_magnitude < -self.thresholds['significant_change']:
            return IssueChangeType.DECLINING.value
        elif current_score > self.thresholds['emerging_issue']:
            return IssueChangeType.ONGOING.value
        else:
            return IssueChangeType.MATURING.value
    
    def _calculate_confidence_score(
        self,
        analysis_result: Dict[str, Any]
    ) -> float:
        """ë¶„ì„ ê²°ê³¼ ì‹ ë¢°ë„ ê³„ì‚°"""
        news_count = analysis_result.get('total_news_count', 0)
        relevant_count = analysis_result.get('relevant_news_count', 0)
        score = analysis_result.get('comprehensive_score', 0)
        
        # ë‰´ìŠ¤ ê°œìˆ˜ ê¸°ë°˜ ì‹ ë¢°ë„
        news_confidence = min(news_count / 10, 1.0)  # 10ê°œ ì´ìƒì´ë©´ ìµœëŒ€ ì‹ ë¢°ë„
        
        # ê´€ë ¨ì„± ë¹„ìœ¨ ê¸°ë°˜ ì‹ ë¢°ë„
        relevance_confidence = relevant_count / max(news_count, 1)
        
        # ì ìˆ˜ ê¸°ë°˜ ì‹ ë¢°ë„
        score_confidence = min(score / 2.0, 1.0)  # 2.0 ì´ìƒì´ë©´ ìµœëŒ€ ì‹ ë¢°ë„
        
        # ê°€ì¤‘ í‰ê· 
        overall_confidence = (
            news_confidence * 0.3 +
            relevance_confidence * 0.4 +
            score_confidence * 0.3
        )
        
        return round(overall_confidence, 3)
    
    def _generate_change_reasons(
        self,
        change_type: str,
        analysis_result: Dict[str, Any],
        change_magnitude: float
    ) -> List[str]:
        """ë³€í™” ì´ìœ  ìƒì„±"""
        reasons = []
        
        trend = analysis_result.get('trend_analysis', {})
        news_count = analysis_result.get('total_news_count', 0)
        sentiment = trend.get('avg_sentiment', 'neutral')
        
        if change_type == IssueChangeType.EMERGING.value:
            reasons.append(f"ë‰´ìŠ¤ ê´€ë ¨ë„ ì ìˆ˜ ìƒìŠ¹ ({change_magnitude:+.2f})")
            if trend.get('recent_increase'):
                reasons.append("ìµœê·¼ ë‰´ìŠ¤ ì¦ê°€ ì¶”ì„¸")
            if sentiment == 'positive':
                reasons.append("ê¸ì •ì  ë‰´ìŠ¤ ì¦ê°€")
        
        elif change_type == IssueChangeType.DECLINING.value:
            reasons.append(f"ë‰´ìŠ¤ ê´€ë ¨ë„ ì ìˆ˜ í•˜ë½ ({change_magnitude:+.2f})")
            if news_count < 5:
                reasons.append("ê´€ë ¨ ë‰´ìŠ¤ ë¶€ì¡±")
            if sentiment == 'negative':
                reasons.append("ë¶€ì •ì  ë‰´ìŠ¤ ì¦ê°€")
        
        elif change_type == IssueChangeType.ONGOING.value:
            reasons.append("ì§€ì†ì ì¸ ë‰´ìŠ¤ ë…¸ì¶œ")
            if news_count > 10:
                reasons.append("í’ë¶€í•œ ë‰´ìŠ¤ ë°ì´í„°")
        
        else:  # MATURING
            reasons.append("ì•ˆì •ì ì¸ ì´ìŠˆ ìƒíƒœ")
            if trend.get('trend_direction') == 'stable':
                reasons.append("íŠ¸ë Œë“œ ì•ˆì •ì„±")
        
        return reasons
    
    async def _discover_new_issues(
        self,
        news_articles: List[Dict[str, Any]],
        existing_topics: List[MaterialityTopic],
        company_name: str
    ) -> List[Dict[str, Any]]:
        """ì‹ ê·œ ì´ìŠˆ ë°œêµ´"""
        new_issues = []
        
        # ê¸°ì¡´ í† í”½ëª… ë¦¬ìŠ¤íŠ¸
        existing_topic_names = [topic.topic_name for topic in existing_topics]
        
        # 1. ë‰´ìŠ¤ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        all_keywords = defaultdict(int)
        for article in news_articles:
            title = article.get('title', '')
            content = article.get('content', '') or article.get('summary', '')
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ ë° ë¹ˆë„ ê³„ì‚°
            keywords = self.news_engine._extract_keywords_from_text(title + ' ' + content)
            for keyword in keywords:
                if len(keyword) > 2:  # ìµœì†Œ 3ê¸€ì ì´ìƒ
                    all_keywords[keyword] += 1
        
        # 2. ë¹ˆë„ ê¸°ë°˜ ìƒìœ„ í‚¤ì›Œë“œ ì„ ë³„
        top_keywords = sorted(all_keywords.items(), key=lambda x: x[1], reverse=True)[:20]
        
        # 3. ê¸°ì¡´ í† í”½ê³¼ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” í‚¤ì›Œë“œ í•„í„°ë§
        potential_new_issues = []
        for keyword, frequency in top_keywords:
            # ê¸°ì¡´ í† í”½ê³¼ ìœ ì‚¬ì„± ì²´í¬
            is_duplicate = any(
                keyword.lower() in topic_name.lower() or topic_name.lower() in keyword.lower()
                for topic_name in existing_topic_names
            )
            
            if not is_duplicate and frequency >= 3:  # ìµœì†Œ 3ë²ˆ ì´ìƒ ì–¸ê¸‰
                potential_new_issues.append((keyword, frequency))
        
        # 4. ì ì¬ì  ì‹ ê·œ ì´ìŠˆ ë¶„ì„
        for keyword, frequency in potential_new_issues[:10]:  # ìƒìœ„ 10ê°œë§Œ ë¶„ì„
            # í•´ë‹¹ í‚¤ì›Œë“œ ê´€ë ¨ ë‰´ìŠ¤ ë¶„ì„
            related_articles = [
                article for article in news_articles
                if keyword.lower() in (article.get('title', '') + ' ' + 
                                     (article.get('content', '') or article.get('summary', ''))).lower()
            ]
            
            if len(related_articles) >= 3:  # ìµœì†Œ 3ê°œ ì´ìƒ ê´€ë ¨ ê¸°ì‚¬
                # ì‹ ê·œ ì´ìŠˆ ì ìˆ˜ ê³„ì‚°
                issue_score = self._calculate_new_issue_score(related_articles, keyword, frequency)
                
                if issue_score > self.thresholds['new_issue_score']:
                    # SASB ë§¤í•‘ ì‹œë„
                    sasb_mapping = self.mapping_service.get_sasb_code_by_topic(keyword)
                    
                    new_issue = {
                        'keyword': keyword,
                        'frequency': frequency,
                        'issue_score': issue_score,
                        'related_articles_count': len(related_articles),
                        'sasb_mapping': sasb_mapping,
                        'confidence': min(issue_score / 2.0, 1.0),
                        'sample_articles': related_articles[:3],  # ìƒ˜í”Œ ê¸°ì‚¬ 3ê°œ
                        'discovery_rationale': self._generate_discovery_rationale(
                            keyword, frequency, issue_score, related_articles
                        )
                    }
                    
                    new_issues.append(new_issue)
        
        # 5. ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        new_issues.sort(key=lambda x: x['issue_score'], reverse=True)
        
        return new_issues[:5]  # ìµœëŒ€ 5ê°œ ì‹ ê·œ ì´ìŠˆ
    
    def _calculate_new_issue_score(
        self,
        articles: List[Dict[str, Any]],
        keyword: str,
        frequency: int
    ) -> float:
        """ì‹ ê·œ ì´ìŠˆ ì ìˆ˜ ê³„ì‚°"""
        # 1. ë¹ˆë„ ì ìˆ˜ (ë¡œê·¸ ìŠ¤ì¼€ì¼)
        frequency_score = math.log(frequency + 1) / 10
        
        # 2. ê¸°ì‚¬ ê°œìˆ˜ ì ìˆ˜
        article_count_score = min(len(articles) / 10, 1.0)
        
        # 3. ìµœê·¼ì„± ì ìˆ˜
        recent_count = 0
        for article in articles:
            if self.news_engine._is_recent_news(article.get('published_at', '')):
                recent_count += 1
        recency_score = recent_count / max(len(articles), 1)
        
        # 4. sentiment ë‹¤ì–‘ì„± ì ìˆ˜
        sentiments = [article.get('sentiment', 'neutral') for article in articles]
        unique_sentiments = len(set(sentiments))
        sentiment_diversity = unique_sentiments / 3  # ìµœëŒ€ 3ê°œ sentiment
        
        # 5. ì¢…í•© ì ìˆ˜
        total_score = (
            frequency_score * 0.3 +
            article_count_score * 0.3 +
            recency_score * 0.2 +
            sentiment_diversity * 0.2
        )
        
        return round(total_score, 3)
    
    def _generate_discovery_rationale(
        self,
        keyword: str,
        frequency: int,
        score: float,
        articles: List[Dict[str, Any]]
    ) -> str:
        """ì‹ ê·œ ì´ìŠˆ ë°œê²¬ ê·¼ê±° ìƒì„±"""
        recent_articles = [
            article for article in articles
            if self.news_engine._is_recent_news(article.get('published_at', ''))
        ]
        
        rationale = f"'{keyword}' í‚¤ì›Œë“œê°€ {frequency}íšŒ ì–¸ê¸‰ë˜ì–´ ì‹ ê·œ ì´ìŠˆë¡œ ì‹ë³„ë¨. "
        rationale += f"ê´€ë ¨ ê¸°ì‚¬ {len(articles)}ê°œ ì¤‘ ìµœê·¼ ê¸°ì‚¬ {len(recent_articles)}ê°œ. "
        rationale += f"ì´ìŠˆ ì ìˆ˜: {score:.3f}"
        
        return rationale
    
    def _analyze_overall_trend(
        self,
        topic_changes: List[Dict[str, Any]],
        new_issues: List[Dict[str, Any]],
        news_metadata: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì „ì²´ ë³€í™” íŠ¸ë Œë“œ ë¶„ì„"""
        
        # 1. ë³€í™” ìœ í˜•ë³„ ë¶„í¬
        change_distribution = defaultdict(int)
        for change in topic_changes:
            change_distribution[change['change_type']] += 1
        
        # 2. ì „ì²´ ë³€í™” ê°•ë„
        change_magnitudes = [abs(change['change_magnitude']) for change in topic_changes]
        avg_change_magnitude = sum(change_magnitudes) / len(change_magnitudes) if change_magnitudes else 0
        
        # 3. ì‹ ë¢°ë„ í‰ê· 
        confidences = [change['confidence'] for change in topic_changes]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0
        
        # 4. ì „ì²´ íŠ¸ë Œë“œ ë°©í–¥ ê²°ì •
        emerging_count = change_distribution[IssueChangeType.EMERGING.value]
        declining_count = change_distribution[IssueChangeType.DECLINING.value]
        
        if emerging_count > declining_count:
            overall_direction = 'expanding'
        elif declining_count > emerging_count:
            overall_direction = 'contracting'
        else:
            overall_direction = 'stable'
        
        # 5. ì—…ë°ì´íŠ¸ í•„ìš”ì„± í‰ê°€
        update_necessity = self._assess_update_necessity(
            change_distribution, avg_change_magnitude, len(new_issues)
        )
        
        return {
            'overall_direction': overall_direction,
            'change_distribution': dict(change_distribution),
            'avg_change_magnitude': round(avg_change_magnitude, 3),
            'avg_confidence': round(avg_confidence, 3),
            'new_issues_count': len(new_issues),
            'update_necessity': update_necessity,
            'analysis_summary': self._generate_trend_summary(
                overall_direction, change_distribution, len(new_issues)
            )
        }
    
    def _assess_update_necessity(
        self,
        change_distribution: Dict[str, int],
        avg_change_magnitude: float,
        new_issues_count: int
    ) -> str:
        """ì—…ë°ì´íŠ¸ í•„ìš”ì„± í‰ê°€"""
        emerging_count = change_distribution.get(IssueChangeType.EMERGING.value, 0)
        declining_count = change_distribution.get(IssueChangeType.DECLINING.value, 0)
        
        if (emerging_count >= 3 or new_issues_count >= 2 or 
            avg_change_magnitude > 0.5):
            return 'high'
        elif (emerging_count >= 1 or declining_count >= 2 or 
              avg_change_magnitude > 0.3):
            return 'medium'
        else:
            return 'low'
    
    def _generate_trend_summary(
        self,
        overall_direction: str,
        change_distribution: Dict[str, int],
        new_issues_count: int
    ) -> str:
        """íŠ¸ë Œë“œ ìš”ì•½ ìƒì„±"""
        summary = f"ì „ì²´ íŠ¸ë Œë“œ: {overall_direction}. "
        
        if change_distribution:
            summary += f"ë³€í™” ë¶„í¬ - "
            summary += f"ë¶€ìƒ: {change_distribution.get(IssueChangeType.EMERGING.value, 0)}ê°œ, "
            summary += f"ì§€ì†: {change_distribution.get(IssueChangeType.ONGOING.value, 0)}ê°œ, "
            summary += f"ì„±ìˆ™: {change_distribution.get(IssueChangeType.MATURING.value, 0)}ê°œ, "
            summary += f"ì‡ í‡´: {change_distribution.get(IssueChangeType.DECLINING.value, 0)}ê°œ. "
        
        if new_issues_count > 0:
            summary += f"ì‹ ê·œ ì´ìŠˆ {new_issues_count}ê°œ ë°œê²¬."
        
        return summary
    
    def _calculate_update_priorities(
        self,
        topic_changes: List[Dict[str, Any]],
        new_issues: List[Dict[str, Any]],
        overall_trend: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """ì—…ë°ì´íŠ¸ ìš°ì„ ìˆœìœ„ ê³„ì‚°"""
        priorities = []
        
        # 1. ê¸°ì¡´ í† í”½ ë³€í™” ìš°ì„ ìˆœìœ„
        for change in topic_changes:
            if change['change_type'] in [IssueChangeType.EMERGING.value, IssueChangeType.DECLINING.value]:
                priority_score = abs(change['change_magnitude']) * change['confidence']
                priorities.append({
                    'type': 'topic_change',
                    'topic_name': change['topic_name'],
                    'change_type': change['change_type'],
                    'priority_score': priority_score,
                    'rationale': f"ê¸°ì¡´ í† í”½ ë³€í™”: {change['change_type']}"
                })
        
        # 2. ì‹ ê·œ ì´ìŠˆ ìš°ì„ ìˆœìœ„
        for issue in new_issues:
            priority_score = issue['issue_score'] * issue['confidence']
            priorities.append({
                'type': 'new_issue',
                'topic_name': issue['keyword'],
                'change_type': 'new',
                'priority_score': priority_score,
                'rationale': f"ì‹ ê·œ ì´ìŠˆ ë°œê²¬: {issue['discovery_rationale']}"
            })
        
        # 3. ìš°ì„ ìˆœìœ„ ì •ë ¬
        priorities.sort(key=lambda x: x['priority_score'], reverse=True)
        
        return priorities
    
    def _generate_update_recommendations(
        self,
        topic_changes: List[Dict[str, Any]],
        new_issues: List[Dict[str, Any]],
        overall_trend: Dict[str, Any]
    ) -> List[str]:
        """ì—…ë°ì´íŠ¸ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # 1. ì „ì²´ íŠ¸ë Œë“œ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if overall_trend['overall_direction'] == 'expanding':
            recommendations.append("ì¤‘ëŒ€ì„± í‰ê°€ ë²”ìœ„ í™•ëŒ€ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
        elif overall_trend['overall_direction'] == 'contracting':
            recommendations.append("ì¤‘ëŒ€ì„± í‰ê°€ ë²”ìœ„ ì¶•ì†Œ ë° ì§‘ì¤‘í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
        
        # 2. ì‹ ê·œ ì´ìŠˆ ê´€ë ¨ ê¶Œì¥ì‚¬í•­
        if len(new_issues) > 0:
            recommendations.append(f"{len(new_issues)}ê°œì˜ ì‹ ê·œ ì´ìŠˆë¥¼ ì¤‘ëŒ€ì„± í‰ê°€ì— í¬í•¨í•˜ëŠ” ê²ƒì„ ê²€í† í•˜ì„¸ìš”.")
        
        # 3. ë³€í™” ê°•ë„ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if overall_trend['avg_change_magnitude'] > 0.4:
            recommendations.append("ë³€í™” ê°•ë„ê°€ ë†’ì•„ ì¤‘ëŒ€ì„± í‰ê°€ì˜ ì „ë©´ì ì¸ ì¬ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # 4. ì—…ë°ì´íŠ¸ í•„ìš”ì„± ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        necessity = overall_trend['update_necessity']
        if necessity == 'high':
            recommendations.append("ì¦‰ì‹œ ì¤‘ëŒ€ì„± í‰ê°€ ì—…ë°ì´íŠ¸ë¥¼ ì‹¤ì‹œí•˜ì„¸ìš”.")
        elif necessity == 'medium':
            recommendations.append("3ê°œì›” ë‚´ ì¤‘ëŒ€ì„± í‰ê°€ ì—…ë°ì´íŠ¸ë¥¼ ê³„íší•˜ì„¸ìš”.")
        else:
            recommendations.append("í˜„ì¬ ì¤‘ëŒ€ì„± í‰ê°€ë¥¼ ìœ ì§€í•˜ë˜ ì •ê¸°ì ì¸ ëª¨ë‹ˆí„°ë§ì„ ê³„ì†í•˜ì„¸ìš”.")
        
        return recommendations 