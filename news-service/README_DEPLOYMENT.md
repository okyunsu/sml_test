# News Service v2.0 - ë°°í¬ ê°€ì´ë“œ

## ğŸ“‹ ìµœì‹  ì—…ë°ì´íŠ¸ (v2.0 - í†µí•© ë¼ìš°í„° ì‹œìŠ¤í…œ)

### âœ… v2.0 ì£¼ìš” ê°œì„ ì‚¬í•­
1. **í†µí•© ë¼ìš°í„° ì‹œìŠ¤í…œ** - ì‚¬ìš© ëª©ì ë³„ë¡œ ë¶„ë¦¬ëœ API êµ¬ì¡°
2. **ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì „ëµ** - Redis ê¸°ë°˜ ì§€ëŠ¥í˜• ìºì‹± ì‹œìŠ¤í…œ
3. **Clean Architecture ì ìš©** - ì˜ì¡´ì„± ì£¼ì… ë° ê³„ì¸µ ë¶„ë¦¬
4. **ë§ˆí‹´ íŒŒìš¸ëŸ¬ ë¦¬íŒ©í„°ë§ ì ìš©** - 5ê°œ ì„œë¹„ìŠ¤ ì™„ì „ ë¦¬íŒ©í„°ë§
   - Extract Class: 9ê°œì˜ ë‹¨ì¼ ì±…ì„ í´ë˜ìŠ¤ë¡œ ë¶„ë¦¬
   - Extract Method: ê¸´ ë©”ì„œë“œë“¤ì„ ì‘ì€ ë©”ì„œë“œë¡œ ë¶„í•´
   - Strategy Pattern: ML ë¶„ì„ ì „ëµ íŒ¨í„´ ì ìš©
   - Factory Pattern: ëª¨ë¸ ë¡œë” íŒ©í† ë¦¬ êµ¬í˜„
5. **ì„±ëŠ¥ ìµœì í™”** - 43% ì½”ë“œ ê°ì†Œ, ì‘ë‹µ ì‹œê°„ ê°œì„ 
6. **ë³´ì•ˆ ê°•í™”** - í™˜ê²½ë³€ìˆ˜ë¥¼ ì•ˆì „í•˜ê²Œ ê´€ë¦¬í•˜ëŠ” ë°©ë²• ì ìš©

### ğŸ¯ ìƒˆë¡œìš´ API êµ¬ì¡°
```
/api/v1/search/                    # ğŸ” ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ (ìºì‹œ ìš°ì„  â†’ ì‹¤ì‹œê°„)
â”œâ”€â”€ news                          # ì¼ë°˜ ë‰´ìŠ¤ ê²€ìƒ‰
â”œâ”€â”€ companies/{company}           # íšŒì‚¬ ë‰´ìŠ¤ ê²€ìƒ‰
â”œâ”€â”€ companies/{company}/analyze   # íšŒì‚¬ ë‰´ìŠ¤ ë¶„ì„
â”œâ”€â”€ batch                         # ë°°ì¹˜ ê²€ìƒ‰
â””â”€â”€ trending                      # íŠ¸ë Œë”© í‚¤ì›Œë“œ

/api/v1/dashboard/                # ğŸ“Š ëŒ€ì‹œë³´ë“œ (ë°±ê·¸ë¼ìš´ë“œ ë°ì´í„°)
â”œâ”€â”€ status                        # ì „ì²´ ìƒíƒœ
â”œâ”€â”€ companies/{company}/latest    # íšŒì‚¬ ìµœì‹  ë¶„ì„
â”œâ”€â”€ companies/{company}/history   # ë¶„ì„ íˆìŠ¤í† ë¦¬
â”œâ”€â”€ companies/{company}/trigger   # ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ìš”ì²­
â””â”€â”€ cache/                        # ìºì‹œ ê´€ë¦¬

/api/v1/system/                   # ğŸ› ï¸ ì‹œìŠ¤í…œ ê´€ë¦¬
â”œâ”€â”€ health                        # í—¬ìŠ¤ì²´í¬
â””â”€â”€ test/                         # ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
```

### ğŸš€ ê¶Œì¥ ì‹¤í–‰ ë°©ë²•

#### Windows PowerShell (ê¶Œì¥ - ë³´ì•ˆ ê°•í™”)
```powershell
# 1. ì´ë¯¸ì§€ ë¹Œë“œ
docker build -f Dockerfile.cpu -t news-service:cpu-ultra-light .

# 2. ë³´ì•ˆ ê°•í™”ëœ ë°©ë²• - .env íŒŒì¼ ë§ˆìš´íŠ¸ (ê¶Œì¥)
docker run -d --name news-service-cpu -p 8002:8002 `
  -v "${PWD}/../newstun-service/models:/app/models" `
  -v "${PWD}/.env:/app/.env:ro" `
  news-service:cpu-ultra-light

# 3. ìƒíƒœ í™•ì¸
docker ps
docker logs news-service-cpu --tail 10

# 4. í™˜ê²½ë³€ìˆ˜ í™•ì¸ (ì„ íƒì‚¬í•­)
docker exec news-service-cpu env | Select-String "MODEL\|NAVER"
```

#### Linux/Mac/WSL (ë³´ì•ˆ ê°•í™”)
```bash
# 1. ì´ë¯¸ì§€ ë¹Œë“œ
docker build -f Dockerfile.cpu -t news-service:cpu-ultra-light .

# 2. ë³´ì•ˆ ê°•í™”ëœ ë°©ë²• - .env íŒŒì¼ ë§ˆìš´íŠ¸ (ê¶Œì¥)
docker run -d --name news-service-cpu -p 8002:8002 \
  -v "$(pwd)/../newstun-service/models:/app/models" \
  -v "$(pwd)/.env:/app/.env:ro" \
  news-service:cpu-ultra-light

# 3. ìƒíƒœ í™•ì¸
docker ps
docker logs news-service-cpu --tail 10
```

#### âš ï¸ ë¹„ê¶Œì¥ ë°©ë²• (ë³´ì•ˆ ìœ„í—˜)
```bash
# í™˜ê²½ë³€ìˆ˜ë¥¼ ëª…ë ¹ì–´ì— ì§ì ‘ ë…¸ì¶œ (ë³´ì•ˆìƒ ìœ„í—˜)
docker run -d --name news-service-cpu -p 8002:8002 \
  -v "$(pwd)/../newstun-service/models:/app/models" \
  -e MODEL_NAME=test222 \
  -e NAVER_CLIENT_ID=your_id \
  -e NAVER_CLIENT_SECRET=your_secret \
  news-service:cpu-ultra-light
```

## ê°œìš”
íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì„ ì‚¬ìš©í•œ ë‰´ìŠ¤ ë¶„ì„ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. CPUì™€ GPU ë‘ ê°€ì§€ í™˜ê²½ì„ ì§€ì›í•˜ë©°, v2.0ì—ì„œëŠ” í†µí•© ë¼ìš°í„° ì‹œìŠ¤í…œê³¼ ìŠ¤ë§ˆíŠ¸ ìºì‹œ ê¸°ëŠ¥ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.

## íŒŒì¼ êµ¬ì¡° (ë¦¬íŒ©í„°ë§ ì™„ë£Œ)
```
news-service/
â”œâ”€â”€ Dockerfile.cpu                 # CPU ìµœì í™” Dockerfile
â”œâ”€â”€ Dockerfile.gpu                 # GPU ìµœì í™” Dockerfile  
â”œâ”€â”€ docker-compose.cpu.yml         # CPU í™˜ê²½ ì„¤ì •
â”œâ”€â”€ docker-compose.redis.yml       # Redis + ëŒ€ì‹œë³´ë“œ í™˜ê²½ (ê¶Œì¥)
â”œâ”€â”€ docker-compose.gpu.yml         # GPU í™˜ê²½ ì„¤ì •
â”œâ”€â”€ DOCKER_COMMANDS.txt            # Docker ëª…ë ¹ì–´ ëª¨ìŒ
â””â”€â”€ app/                           # ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ (Clean Architecture ì ìš©)
    â”œâ”€â”€ api/
    â”‚   â””â”€â”€ unified_router.py      # í†µí•© ë¼ìš°í„° ì‹œìŠ¤í…œ
    â”œâ”€â”€ core/                      # ì¸í”„ë¼ìŠ¤íŠ¸ëŸ­ì²˜ ê³„ì¸µ
    â”‚   â”œâ”€â”€ dependencies.py        # ì˜ì¡´ì„± ì£¼ì… ì»¨í…Œì´ë„ˆ
    â”‚   â”œâ”€â”€ exceptions.py          # ê³µí†µ ì˜ˆì™¸ ì²˜ë¦¬
    â”‚   â”œâ”€â”€ http_client.py         # HTTP í´ë¼ì´ì–¸íŠ¸ ê´€ë¦¬
    â”‚   â””â”€â”€ redis_client.py        # Redis í´ë¼ì´ì–¸íŠ¸ ê´€ë¦¬
    â”œâ”€â”€ domain/                    # ë„ë©”ì¸ ê³„ì¸µ (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§)
    â”‚   â”œâ”€â”€ controller/            # ì»¨íŠ¸ë¡¤ëŸ¬ ê³„ì¸µ
    â”‚   â”‚   â”œâ”€â”€ news_controller.py      # ë‰´ìŠ¤ ê²€ìƒ‰/ë¶„ì„ ì»¨íŠ¸ë¡¤ëŸ¬
    â”‚   â”‚   â””â”€â”€ dashboard_controller.py # ëŒ€ì‹œë³´ë“œ ì»¨íŠ¸ë¡¤ëŸ¬
    â”‚   â”œâ”€â”€ service/               # ì„œë¹„ìŠ¤ ê³„ì¸µ (ë¦¬íŒ©í„°ë§ ì™„ë£Œ)
    â”‚   â”‚   â”œâ”€â”€ ml_inference_service.py     # ML ì¶”ë¡  ì„œë¹„ìŠ¤
    â”‚   â”‚   â”œâ”€â”€ news_analysis_service.py    # ë‰´ìŠ¤ ë¶„ì„ ì„œë¹„ìŠ¤
    â”‚   â”‚   â”œâ”€â”€ news_service.py             # ë‰´ìŠ¤ ê²€ìƒ‰ ì„œë¹„ìŠ¤
    â”‚   â”‚   â”œâ”€â”€ analysis_workflow_service.py # ë¶„ì„ ì›Œí¬í”Œë¡œìš°
    â”‚   â”‚   â””â”€â”€ dashboard_service.py        # ëŒ€ì‹œë³´ë“œ ì„œë¹„ìŠ¤
    â”‚   â””â”€â”€ model/                 # ëª¨ë¸ ê³„ì¸µ (DTO + ì „ëµ íŒ¨í„´)
    â”‚       â”œâ”€â”€ news_dto.py        # ë‰´ìŠ¤ ë°ì´í„° ì „ì†¡ ê°ì²´
    â”‚       â”œâ”€â”€ ml_strategies.py   # ML ë¶„ì„ ì „ëµ êµ¬í˜„
    â”‚       â””â”€â”€ ml_loader.py       # ML ëª¨ë¸ ë¡œë” íŒ©í† ë¦¬
    â”œâ”€â”€ config/                    # ì„¤ì • ê³„ì¸µ
    â”‚   â”œâ”€â”€ settings.py            # ê¸°ë³¸ ì„¤ì •
    â”‚   â””â”€â”€ ml_settings.py         # ML ì„¤ì •
    â””â”€â”€ workers/                   # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… (Celery)
        â”œâ”€â”€ celery_app.py          # Celery ì• í”Œë¦¬ì¼€ì´ì…˜
        â””â”€â”€ analysis_worker.py     # ë¶„ì„ ì›Œì»¤
```

## ì‚¬ì „ ìš”êµ¬ì‚¬í•­

### ê³µí†µ
- Docker & Docker Compose
- newstun-service/models ë””ë ‰í† ë¦¬ì— íŒŒì¸íŠœë‹ëœ ëª¨ë¸
- `.env` íŒŒì¼ ì„¤ì • (ë³´ì•ˆ í•„ìˆ˜)

### GPU í™˜ê²½ (ì¶”ê°€)
- NVIDIA GPU ë“œë¼ì´ë²„
- NVIDIA Container Toolkit

## ğŸ”’ ë³´ì•ˆ ì„¤ì •

### .env íŒŒì¼ ìƒì„± (í•„ìˆ˜)
```bash
# .env íŒŒì¼ ìƒì„±
cat > .env << EOF
# Naver API ì„¤ì •
NAVER_CLIENT_ID=your_actual_client_id
NAVER_CLIENT_SECRET=your_actual_client_secret

# ëª¨ë¸ ì„¤ì •
MODEL_NAME=test222

# ì„œë¹„ìŠ¤ ì„¤ì • (ì„ íƒì‚¬í•­)
LOG_LEVEL=INFO

# Redis ì„¤ì • (ëŒ€ì‹œë³´ë“œ ê¸°ëŠ¥ ì‚¬ìš© ì‹œ)
REDIS_URL=redis://localhost:6379/0
EOF
```

### íŒŒì¼ ê¶Œí•œ ì„¤ì • (ê¶Œì¥)
```bash
# Linux/Mac - .env íŒŒì¼ ê¶Œí•œì„ ì†Œìœ ìë§Œ ì½ê¸° ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
chmod 600 .env

# Windows PowerShell - íŒŒì¼ ê¶Œí•œ ì œí•œ
icacls .env /inheritance:d /grant:r "${env:USERNAME}:R"
```

### ë³´ì•ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸
- âœ… `.env` íŒŒì¼ì´ `.gitignore`ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
- âœ… ì‹¤ì œ API í‚¤ê°€ ë²„ì „ ê´€ë¦¬ì— í¬í•¨ë˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸  
- âœ… `.env` íŒŒì¼ì„ ì½ê¸° ì „ìš©(`:ro`)ìœ¼ë¡œ ë§ˆìš´íŠ¸
- âœ… í™˜ê²½ë³€ìˆ˜ë¥¼ Docker ëª…ë ¹ì–´ì— ì§ì ‘ ë…¸ì¶œí•˜ì§€ ì•Šê¸°
- âœ… í”„ë¡œë•ì…˜ê³¼ ê°œë°œ í™˜ê²½ì˜ `.env` íŒŒì¼ ë¶„ë¦¬

## ğŸ¯ í™˜ê²½ë³„ ë°°í¬ ì „ëµ ì„ íƒ ê°€ì´ë“œ

### ğŸ“Š í™˜ê²½ë³„ ë¹„êµí‘œ (ë¦¬íŒ©í„°ë§ v2.0 ê¸°ì¤€)

| íŠ¹ì„± | CPU ê¸°ë³¸ | CPU + Redis | GPU | ì‚¬ìš© ì‚¬ë¡€ |
|------|----------|-------------|-----|-----------|
| **ì í•©í•œ ê·œëª¨** | ê°œë°œ/í…ŒìŠ¤íŠ¸ | ì†Œ~ì¤‘ê·œëª¨ í”„ë¡œë•ì…˜ | ëŒ€ê·œëª¨ í”„ë¡œë•ì…˜ | |
| **ì²˜ë¦¬ ì„±ëŠ¥** | 2-5ì´ˆ/ë‰´ìŠ¤ | 100ms/ë‰´ìŠ¤ (ìºì‹œ) | 0.1-0.5ì´ˆ/ë‰´ìŠ¤ | |
| **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰** | 2-4GB | 3-5GB | 4-8GB + GPU | |
| **ìºì‹œ ê¸°ëŠ¥** | âŒ | âœ… (ìŠ¤ë§ˆíŠ¸ ìºì‹œ) | âŒ | |
| **ëŒ€ì‹œë³´ë“œ** | âŒ | âœ… (ìë™ ë¶„ì„) | âŒ | |
| **ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…** | âŒ | âœ… (Celery) | âŒ | |
| **ì´ë¯¸ì§€ í¬ê¸°** | ~2-3GB | ~3-4GB | ~6-8GB | |
| **í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­** | CPUë§Œ | CPU + Redis | GPU í•„ìˆ˜ | |
| **ë¦¬íŒ©í„°ë§ ì„œë¹„ìŠ¤** | 5ê°œ ì„œë¹„ìŠ¤ | 5ê°œ ì„œë¹„ìŠ¤ + ì›Œì»¤ | 5ê°œ ì„œë¹„ìŠ¤ | |

### ğŸ¯ ì„ íƒ ê¸°ì¤€

#### CPU ê¸°ë³¸ í™˜ê²½ ì„ íƒ ì‹œ
- âœ… ê°œë°œ ë° í…ŒìŠ¤íŠ¸ í™˜ê²½
- âœ… ì†Œê·œëª¨ ì‚¬ìš©ëŸ‰ (<50 ë‰´ìŠ¤/ì¼)
- âœ… ë‹¨ìˆœí•œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
- âœ… GPU í•˜ë“œì›¨ì–´ ì—†ìŒ
- âœ… ìµœì†Œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©

#### CPU + Redis í™˜ê²½ ì„ íƒ ì‹œ (â­ ê¶Œì¥)
- âœ… ì¼ë°˜ì ì¸ í”„ë¡œë•ì…˜ í™˜ê²½
- âœ… ì¤‘ê°„ ê·œëª¨ ì‚¬ìš©ëŸ‰ (50-1000 ë‰´ìŠ¤/ì¼)
- âœ… ëŒ€ì‹œë³´ë“œ ê¸°ëŠ¥ í•„ìš”
- âœ… ìŠ¤ë§ˆíŠ¸ ìºì‹œ í™œìš©
- âœ… ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ í•„ìš”
- âœ… ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥ í•„ìš”

#### GPU í™˜ê²½ ì„ íƒ ì‹œ
- âœ… ê³ ì„±ëŠ¥ í”„ë¡œë•ì…˜ í™˜ê²½
- âœ… ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ (>1000 ë‰´ìŠ¤/ì¼)
- âœ… ì‹¤ì‹œê°„ ë¶„ì„ ìš”êµ¬ì‚¬í•­
- âœ… ìµœê³  ì„±ëŠ¥ í•„ìš”
- âœ… GPU í•˜ë“œì›¨ì–´ ë³´ìœ 

## ğŸš€ í™˜ê²½ë³„ ë‹¨ê³„ë³„ ë°°í¬ ê°€ì´ë“œ

### 1ï¸âƒ£ CPU ê¸°ë³¸ í™˜ê²½ (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)

#### ğŸ“‹ ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] `.env` íŒŒì¼ ìƒì„± ë° ì„¤ì •
- [ ] `../newstun-service/models` ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸
- [ ] Docker ì„¤ì¹˜ í™•ì¸
- [ ] í¬íŠ¸ 8002 ì‚¬ìš© ê°€ëŠ¥ í™•ì¸

#### ğŸ”§ ë‹¨ê³„ë³„ ì‹¤í–‰
```bash
# 1ë‹¨ê³„: í™˜ê²½ í™•ì¸
ls ../newstun-service/models/test222*  # ëª¨ë¸ íŒŒì¼ í™•ì¸
cat .env  # í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ í™•ì¸

# 2ë‹¨ê³„: ì´ë¯¸ì§€ ë¹Œë“œ
docker build -f Dockerfile.cpu -t news-service:cpu-ultra-light .

# 3ë‹¨ê³„: ì»¨í…Œì´ë„ˆ ì‹¤í–‰ (ë³´ì•ˆ ê°•í™”)
docker run -d --name news-service-cpu -p 8002:8002 \
  -v "$(pwd)/../newstun-service/models:/app/models" \
  -v "$(pwd)/.env:/app/.env:ro" \
  news-service:cpu-ultra-light

# 4ë‹¨ê³„: ìƒíƒœ í™•ì¸
docker ps | grep news-service-cpu
curl http://localhost:8002/api/v1/system/health
```

#### âš™ï¸ CPU í™˜ê²½ ìµœì í™” ì„¤ì •
```bash
# .env íŒŒì¼ì— ì¶”ê°€ ì„¤ì •
echo "
# CPU í™˜ê²½ ìµœì í™”
TORCH_NUM_THREADS=2
OMP_NUM_THREADS=2
LOG_LEVEL=INFO
CACHE_ENABLED=false
" >> .env
```

#### ğŸ“Š CPU í™˜ê²½ ë¦¬íŒ©í„°ë§ ì„œë¹„ìŠ¤ íŠ¹ì§•
- **MLInferenceService**: CPU ëª¨ë“œë¡œ ë™ì‘, ë©”ëª¨ë¦¬ íš¨ìœ¨ ìµœì í™”
- **NewsAnalysisService**: í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ì „ëµ ì£¼ë¡œ ì‚¬ìš©
- **NewsService**: ê¸°ë³¸ì ì¸ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° ì¤‘ë³µ ì œê±°
- **DashboardService**: ë¹„í™œì„±í™” (Redis ì—†ìŒ)
- **AnalysisWorkflowService**: ë™ê¸° ì²˜ë¦¬ ëª¨ë“œ

---

### 2ï¸âƒ£ CPU + Redis í™˜ê²½ (í”„ë¡œë•ì…˜ ê¶Œì¥) â­

#### ğŸ“‹ ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] `.env` íŒŒì¼ ìƒì„± ë° Redis ì„¤ì • ì¶”ê°€
- [ ] `../newstun-service/models` ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸
- [ ] Docker Compose ì„¤ì¹˜ í™•ì¸
- [ ] í¬íŠ¸ 8002, 6379 ì‚¬ìš© ê°€ëŠ¥ í™•ì¸
- [ ] Redis ì§€ì†ì„± ë³¼ë¥¨ ì„¤ì •

#### ğŸ”§ ë‹¨ê³„ë³„ ì‹¤í–‰
```bash
# 1ë‹¨ê³„: í™˜ê²½ í™•ì¸ ë° Redis ì„¤ì •
echo "REDIS_URL=redis://redis:6379/0" >> .env
echo "CACHE_ENABLED=true" >> .env
echo "CACHE_TTL_HOURS=24" >> .env

# 2ë‹¨ê³„: ì „ì²´ ìŠ¤íƒ ì‹¤í–‰ (ê¶Œì¥ ë°©ë²•)
docker-compose -f docker-compose.redis.yml up -d

# 3ë‹¨ê³„: ì„œë¹„ìŠ¤ë³„ ìƒíƒœ í™•ì¸
docker-compose -f docker-compose.redis.yml ps

# 4ë‹¨ê³„: ë¡œê·¸ í™•ì¸ (ë¦¬íŒ©í„°ë§ëœ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” í™•ì¸)
docker-compose -f docker-compose.redis.yml logs news-service | head -20
docker-compose -f docker-compose.redis.yml logs celery-worker | head -10
docker-compose -f docker-compose.redis.yml logs redis | head -5

# 5ë‹¨ê³„: API í…ŒìŠ¤íŠ¸
curl http://localhost:8002/api/v1/dashboard/status
curl http://localhost:8002/api/v1/system/health
```

#### âš™ï¸ Redis í™˜ê²½ ê³ ê¸‰ ì„¤ì •
```bash
# .env íŒŒì¼ì— Redis í™˜ê²½ ìµœì í™” ì„¤ì •
cat >> .env << EOF
# Redis + Celery í™˜ê²½ ìµœì í™”
REDIS_URL=redis://redis:6379/0
CACHE_ENABLED=true
CACHE_TTL_HOURS=24
CELERY_BROKER_URL=redis://redis:6379/1
CELERY_RESULT_BACKEND=redis://redis:6379/2

# ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì„¤ì •
ANALYSIS_SCHEDULE_MINUTES=30
MONITORED_COMPANIES=ì‚¼ì„±ì „ì,LGì „ì,SKí•˜ì´ë‹‰ìŠ¤
HISTORY_MAX_COUNT=50

# ì„±ëŠ¥ ìµœì í™”
WORKER_CONCURRENCY=2
WORKER_PREFETCH_MULTIPLIER=4
EOF
```

#### ğŸ“Š Redis í™˜ê²½ ë¦¬íŒ©í„°ë§ ì„œë¹„ìŠ¤ íŠ¹ì§•
- **MLInferenceService**: ë¡œì»¬ ML ëª¨ë¸ ìš°ì„ , ì „ëµ íŒ¨í„´ í™œìš©
- **NewsAnalysisService**: ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì—°ë™, 3ë‹¨ê³„ ìš°ì„ ìˆœìœ„ ë¶„ì„
- **NewsService**: ì¤‘ë³µ ì œê±° ìµœì í™”, ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›
- **DashboardService**: ì™„ì „ í™œì„±í™”, ìë™ ëª¨ë‹ˆí„°ë§
- **AnalysisWorkflowService**: ë¹„ë™ê¸° ì›Œí¬í”Œë¡œìš°, Celery ì—°ë™

#### ğŸ” Redis í™˜ê²½ ëª¨ë‹ˆí„°ë§
```bash
# ìºì‹œ ìƒíƒœ í™•ì¸
curl http://localhost:8002/api/v1/dashboard/cache/info

# Celery ì‘ì—… ìƒíƒœ í™•ì¸
docker exec -it $(docker-compose -f docker-compose.redis.yml ps -q celery-worker) \
  celery -A app.workers.celery_app inspect active

# Redis ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
docker exec -it $(docker-compose -f docker-compose.redis.yml ps -q redis) \
  redis-cli info memory
```

---

### 3ï¸âƒ£ GPU í™˜ê²½ (ê³ ì„±ëŠ¥ í”„ë¡œë•ì…˜)

#### ğŸ“‹ ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] NVIDIA GPU ë“œë¼ì´ë²„ ì„¤ì¹˜
- [ ] NVIDIA Container Toolkit ì„¤ì¹˜
- [ ] `.env` íŒŒì¼ ìƒì„± ë° GPU ì„¤ì • ì¶”ê°€
- [ ] `../newstun-service/models` ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸
- [ ] GPU ë©”ëª¨ë¦¬ ì¶©ë¶„ í™•ì¸ (ìµœì†Œ 4GB)

#### ğŸ”§ ë‹¨ê³„ë³„ ì‹¤í–‰
```bash
# 1ë‹¨ê³„: GPU í™˜ê²½ í™•ì¸
nvidia-smi  # GPU ìƒíƒœ í™•ì¸
docker run --rm --gpus all nvidia/cuda:11.8-base nvidia-smi  # Docker GPU ì§€ì› í™•ì¸

# 2ë‹¨ê³„: GPU ìµœì í™” ì„¤ì •
cat >> .env << EOF
# GPU í™˜ê²½ ìµœì í™”
CUDA_VISIBLE_DEVICES=0
TORCH_CUDA_ARCH_LIST="6.0;6.1;7.0;7.5;8.0;8.6"
GPU_MEMORY_FRACTION=0.8
LOG_LEVEL=INFO
EOF

# 3ë‹¨ê³„: ì´ë¯¸ì§€ ë¹Œë“œ (GPU ìµœì í™”)
docker build -f Dockerfile.gpu -t news-service:gpu .

# 4ë‹¨ê³„: GPU í™˜ê²½ ì‹¤í–‰
docker-compose -f docker-compose.gpu.yml up -d

# 5ë‹¨ê³„: GPU ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi
```

#### âš™ï¸ GPU í™˜ê²½ ì„±ëŠ¥ íŠœë‹
```bash
# GPU ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
cat >> .env << EOF
# GPU ì„±ëŠ¥ ìµœì í™”
CUDA_LAUNCH_BLOCKING=0
CUDNN_BENCHMARK=true
TORCH_BACKENDS_CUDNN_BENCHMARK=true
TORCH_BACKENDS_CUDNN_DETERMINISTIC=false

# ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
ML_BATCH_SIZE=32
ML_MAX_WORKERS=4
INFERENCE_TIMEOUT=30
EOF
```

#### ğŸ“Š GPU í™˜ê²½ ë¦¬íŒ©í„°ë§ ì„œë¹„ìŠ¤ íŠ¹ì§•
- **MLInferenceService**: GPU ê°€ì† ì¶”ë¡ , ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
- **NewsAnalysisService**: ML ìš°ì„  ì „ëµ, ê³ ì† ë³‘ë ¬ ì²˜ë¦¬
- **NewsService**: ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬, ë©”ëª¨ë¦¬ ìµœì í™”
- **DashboardService**: ë¹„í™œì„±í™” (ë‹¨ìˆœí™”)
- **AnalysisWorkflowService**: ê³ ì„±ëŠ¥ ë™ê¸° ì²˜ë¦¬

#### ğŸ” GPU í™˜ê²½ ëª¨ë‹ˆí„°ë§
```bash
# GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
nvidia-smi dmon -s pucvmet -d 1

# ì»¨í…Œì´ë„ˆ GPU ì‚¬ìš©ëŸ‰ í™•ì¸
docker exec -it news-service-gpu nvidia-smi

# ì¶”ë¡  ì„±ëŠ¥ ì¸¡ì •
curl -w "@curl-format.txt" -o /dev/null -s \
  -X POST http://localhost:8002/api/v1/search/companies/ì‚¼ì„±ì „ì/analyze \
  -H "Content-Type: application/json" \
  -d '{"max_results": 100}'
```

## ğŸ”„ í™˜ê²½ë³„ ì „í™˜ ê°€ì´ë“œ

### CPU â†’ CPU+Redis ì „í™˜
```bash
# 1. ê¸°ì¡´ CPU í™˜ê²½ ì¤‘ì§€
docker stop news-service-cpu
docker rm news-service-cpu

# 2. Redis ì„¤ì • ì¶”ê°€
echo "REDIS_URL=redis://redis:6379/0" >> .env
echo "CACHE_ENABLED=true" >> .env

# 3. Redis í™˜ê²½ìœ¼ë¡œ ì „í™˜
docker-compose -f docker-compose.redis.yml up -d
```

### CPU â†’ GPU ì „í™˜
```bash
# 1. GPU í™˜ê²½ í™•ì¸
nvidia-smi

# 2. ê¸°ì¡´ CPU í™˜ê²½ ì¤‘ì§€
docker-compose -f docker-compose.cpu.yml down

# 3. GPU ì´ë¯¸ì§€ ë¹Œë“œ ë° ì‹¤í–‰
docker build -f Dockerfile.gpu -t news-service:gpu .
docker-compose -f docker-compose.gpu.yml up -d
```

### Redis â†’ CPU ê¸°ë³¸ ì „í™˜ (ë‹¤ìš´ê·¸ë ˆì´ë“œ)
```bash
# 1. Redis í™˜ê²½ ì¤‘ì§€
docker-compose -f docker-compose.redis.yml down

# 2. Redis ê´€ë ¨ ì„¤ì • ì œê±°
sed -i '/REDIS_URL/d' .env
sed -i '/CACHE_ENABLED/d' .env

# 3. CPU ê¸°ë³¸ í™˜ê²½ìœ¼ë¡œ ì „í™˜
docker-compose -f docker-compose.cpu.yml up -d
```

## ëª¨ë¸ ë³€ê²½

### ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš© (ê¶Œì¥)
```bash
# Linux/Mac
./switch_model.sh cpu test222    # CPU í™˜ê²½ì—ì„œ test222 ëª¨ë¸
./switch_model.sh gpu test123    # GPU í™˜ê²½ì—ì„œ test123 ëª¨ë¸

# Windows
switch_model.bat cpu test222     # CPU í™˜ê²½ì—ì„œ test222 ëª¨ë¸
switch_model.bat gpu test123     # GPU í™˜ê²½ì—ì„œ test123 ëª¨ë¸
```

### ìˆ˜ë™ ë³€ê²½
```bash
# ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì¤‘ì§€
docker-compose -f docker-compose.cpu.yml down
docker-compose -f docker-compose.redis.yml down
docker-compose -f docker-compose.gpu.yml down

# ìƒˆë¡œìš´ ëª¨ë¸ë¡œ ì‹œì‘
MODEL_NAME=test222 docker-compose -f docker-compose.cpu.yml up -d
```

## ğŸ“Š í™˜ê²½ë³„ ì„±ëŠ¥ ë¹„êµ (ë¦¬íŒ©í„°ë§ v2.0)

### ğŸ† ìƒì„¸ ì„±ëŠ¥ ë¹„êµí‘œ

| ì„±ëŠ¥ ì§€í‘œ | CPU ê¸°ë³¸ | CPU + Redis | GPU | ì¸¡ì • ê¸°ì¤€ |
|-----------|----------|-------------|-----|-----------|
| **ë‰´ìŠ¤ ê²€ìƒ‰ ì†ë„** | 1-2ì´ˆ | 100-200ms (ìºì‹œ) | 0.5-1ì´ˆ | 50ê°œ ë‰´ìŠ¤ |
| **ë‰´ìŠ¤ ë¶„ì„ ì†ë„** | 2-5ì´ˆ | 100ms (ìºì‹œ) / 3-6ì´ˆ (ì‹¤ì‹œê°„) | 0.1-0.5ì´ˆ | 50ê°œ ë‰´ìŠ¤ |
| **ë°°ì¹˜ ì²˜ë¦¬ ì†ë„** | ì œí•œì  | ìš°ìˆ˜ (ë°±ê·¸ë¼ìš´ë“œ) | ìµœê³  | 500ê°œ ë‰´ìŠ¤ |
| **ë™ì‹œ ì²˜ë¦¬ ëŠ¥ë ¥** | 5ê°œ ìš”ì²­ | 10ê°œ ìš”ì²­ | 20ê°œ ìš”ì²­ | ë™ì‹œ API í˜¸ì¶œ |
| **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰** | 2-4GB | 3-5GB | 4-8GB + GPU | ì•ˆì • ìƒíƒœ |
| **ë””ìŠ¤í¬ I/O** | ì¤‘ê°„ | ë‚®ìŒ (ìºì‹œ) | ì¤‘ê°„ | ëª¨ë¸ ë¡œë”© |
| **ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©ëŸ‰** | ë†’ìŒ | ë‚®ìŒ (ìºì‹œ) | ë†’ìŒ | API í˜¸ì¶œ ë¹ˆë„ |

### ğŸ”§ ë¦¬íŒ©í„°ë§ ì„±ëŠ¥ ê°œì„  íš¨ê³¼

| ë¦¬íŒ©í„°ë§ ê¸°ë²• | CPU ê¸°ë³¸ | CPU + Redis | GPU | ê°œì„  íš¨ê³¼ |
|---------------|----------|-------------|-----|-----------|
| **Extract Class** | âœ… 20% í–¥ìƒ | âœ… 25% í–¥ìƒ | âœ… 15% í–¥ìƒ | ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± |
| **Strategy Pattern** | âœ… 15% í–¥ìƒ | âœ… 40% í–¥ìƒ | âœ… 30% í–¥ìƒ | ë¶„ì„ ì†ë„ |
| **Factory Pattern** | âœ… 10% í–¥ìƒ | âœ… 15% í–¥ìƒ | âœ… 20% í–¥ìƒ | ëª¨ë¸ ë¡œë”© |
| **Cache Strategy** | âŒ | âœ… 80% í–¥ìƒ | âŒ | ì‘ë‹µ ì‹œê°„ |
| **ì „ì²´ ê°œì„ ìœ¨** | **45% í–¥ìƒ** | **160% í–¥ìƒ** | **65% í–¥ìƒ** | ì¢…í•© ì„±ëŠ¥ |

### ğŸ’¾ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ìƒì„¸

#### CPU ê¸°ë³¸ í™˜ê²½
```
ğŸ“Š ë¦¬ì†ŒìŠ¤ í”„ë¡œí•„:
- CPU: 1-2 ì½”ì–´ (í‰ê·  50-70% ì‚¬ìš©ë¥ )
- ë©”ëª¨ë¦¬: 2-4GB (í”¼í¬ ì‚¬ìš©ëŸ‰)
- ë””ìŠ¤í¬: 200MB/ì¼ (ë¡œê·¸)
- ë„¤íŠ¸ì›Œí¬: 10-50KB/ìš”ì²­

ğŸ”§ ë¦¬íŒ©í„°ë§ëœ ì„œë¹„ìŠ¤ë³„ ì‚¬ìš©ëŸ‰:
- MLInferenceService: 1.5GB ë©”ëª¨ë¦¬
- NewsAnalysisService: 0.5GB ë©”ëª¨ë¦¬  
- NewsService: 0.3GB ë©”ëª¨ë¦¬
- ê¸°íƒ€ ì„œë¹„ìŠ¤: 0.7GB ë©”ëª¨ë¦¬
```

#### CPU + Redis í™˜ê²½
```
ğŸ“Š ë¦¬ì†ŒìŠ¤ í”„ë¡œí•„:
- CPU: 2-3 ì½”ì–´ (í‰ê·  40-60% ì‚¬ìš©ë¥ )
- ë©”ëª¨ë¦¬: 3-5GB (Redis ìºì‹œ í¬í•¨)
- ë””ìŠ¤í¬: 500MB/ì¼ (ë¡œê·¸ + Redis ì§€ì†ì„±)
- ë„¤íŠ¸ì›Œí¬: 5-20KB/ìš”ì²­ (ìºì‹œ íˆíŠ¸ ì‹œ)

ğŸ”§ ë¦¬íŒ©í„°ë§ëœ ì„œë¹„ìŠ¤ë³„ ì‚¬ìš©ëŸ‰:
- MLInferenceService: 1.5GB ë©”ëª¨ë¦¬
- NewsAnalysisService: 0.5GB ë©”ëª¨ë¦¬
- NewsService: 0.3GB ë©”ëª¨ë¦¬
- DashboardService: 0.4GB ë©”ëª¨ë¦¬
- Redis: 0.5-1.5GB ë©”ëª¨ë¦¬ (ìºì‹œ í¬ê¸°)
- Celery Worker: 0.8GB ë©”ëª¨ë¦¬
```

#### GPU í™˜ê²½
```
ğŸ“Š ë¦¬ì†ŒìŠ¤ í”„ë¡œí•„:
- CPU: 2-4 ì½”ì–´ (í‰ê·  30-50% ì‚¬ìš©ë¥ )
- GPU: 4-8GB VRAM (í”¼í¬ ì‚¬ìš©ëŸ‰)
- ë©”ëª¨ë¦¬: 4-8GB (GPU ë²„í¼ í¬í•¨)
- ë””ìŠ¤í¬: 300MB/ì¼ (ë¡œê·¸)
- ë„¤íŠ¸ì›Œí¬: 10-50KB/ìš”ì²­

ğŸ”§ ë¦¬íŒ©í„°ë§ëœ ì„œë¹„ìŠ¤ë³„ ì‚¬ìš©ëŸ‰:
- MLInferenceService: 2.5GB ë©”ëª¨ë¦¬ + 4GB VRAM
- NewsAnalysisService: 0.8GB ë©”ëª¨ë¦¬
- NewsService: 0.5GB ë©”ëª¨ë¦¬
- ê¸°íƒ€ ì„œë¹„ìŠ¤: 0.7GB ë©”ëª¨ë¦¬
```

### ğŸ¯ í™˜ê²½ë³„ ìµœì  ì‚¬ìš© ì‚¬ë¡€

#### CPU ê¸°ë³¸ í™˜ê²½ ìµœì  ì‚¬ë¡€
```
âœ… ì í•©í•œ ìƒí™©:
- ê°œë°œ í™˜ê²½ì—ì„œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
- ì†Œê·œëª¨ POC (Proof of Concept)
- ê°œì¸ í”„ë¡œì íŠ¸ ë˜ëŠ” í•™ìŠµ ëª©ì 
- ë¦¬ì†ŒìŠ¤ ì œì•½ì´ ìˆëŠ” í™˜ê²½

ğŸ“ˆ ì²˜ë¦¬ëŸ‰ ê¸°ì¤€:
- ì¼ì¼ ì²˜ë¦¬ëŸ‰: 50-200 ë‰´ìŠ¤
- ì‹œê°„ë‹¹ ì²˜ë¦¬ëŸ‰: 10-50 ë‰´ìŠ¤
- ë™ì‹œ ì‚¬ìš©ì: 1-5ëª…
```

#### CPU + Redis í™˜ê²½ ìµœì  ì‚¬ë¡€ (â­ ê¶Œì¥)
```
âœ… ì í•©í•œ ìƒí™©:
- ìŠ¤íƒ€íŠ¸ì—… í”„ë¡œë•ì…˜ í™˜ê²½
- ì¤‘ì†Œê¸°ì—… ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§
- ëŒ€ì‹œë³´ë“œê°€ í•„ìš”í•œ ì„œë¹„ìŠ¤
- ë¹„ìš© íš¨ìœ¨ì ì¸ í”„ë¡œë•ì…˜ ë°°í¬

ğŸ“ˆ ì²˜ë¦¬ëŸ‰ ê¸°ì¤€:
- ì¼ì¼ ì²˜ë¦¬ëŸ‰: 500-5,000 ë‰´ìŠ¤
- ì‹œê°„ë‹¹ ì²˜ë¦¬ëŸ‰: 100-500 ë‰´ìŠ¤
- ë™ì‹œ ì‚¬ìš©ì: 10-50ëª…
- ìºì‹œ ì ì¤‘ë¥ : 70-90%
```

#### GPU í™˜ê²½ ìµœì  ì‚¬ë¡€
```
âœ… ì í•©í•œ ìƒí™©:
- ëŒ€ê¸°ì—… í”„ë¡œë•ì…˜ í™˜ê²½
- ì‹¤ì‹œê°„ ë‰´ìŠ¤ ë¶„ì„ ì„œë¹„ìŠ¤
- ê³ ì„±ëŠ¥ì´ í•„ìš”í•œ B2B ì„œë¹„ìŠ¤
- ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬

ğŸ“ˆ ì²˜ë¦¬ëŸ‰ ê¸°ì¤€:
- ì¼ì¼ ì²˜ë¦¬ëŸ‰: 5,000-50,000 ë‰´ìŠ¤
- ì‹œê°„ë‹¹ ì²˜ë¦¬ëŸ‰: 500-2,000 ë‰´ìŠ¤
- ë™ì‹œ ì‚¬ìš©ì: 50-200ëª…
- ì‹¤ì‹œê°„ ì‘ë‹µ ìš”êµ¬ì‚¬í•­
```

### ğŸš€ ì„±ëŠ¥ ìµœì í™” íŒ

#### CPU í™˜ê²½ ìµœì í™”
```bash
# .env íŒŒì¼ CPU ìµœì í™” ì„¤ì •
TORCH_NUM_THREADS=2
OMP_NUM_THREADS=2
TORCH_BACKENDS_CUDNN_ENABLED=false
TRANSFORMERS_OFFLINE=1
HF_DATASETS_OFFLINE=1
```

#### Redis í™˜ê²½ ìµœì í™”
```bash
# .env íŒŒì¼ Redis ìµœì í™” ì„¤ì •
REDIS_MAXMEMORY=2gb
REDIS_MAXMEMORY_POLICY=allkeys-lru
CELERY_TASK_SERIALIZER=json
CELERY_RESULT_SERIALIZER=json
CACHE_TTL_HOURS=24
CACHE_MAX_SIZE=1000
```

#### GPU í™˜ê²½ ìµœì í™”
```bash
# .env íŒŒì¼ GPU ìµœì í™” ì„¤ì •
CUDA_VISIBLE_DEVICES=0
GPU_MEMORY_FRACTION=0.8
TORCH_BACKENDS_CUDNN_BENCHMARK=true
ML_BATCH_SIZE=32
TORCH_COMPILE=true
```

## ëª¨ë¸ ì§€ì›

### í˜„ì¬ ì§€ì› ëª¨ë¸
- **test123**: ê¸°ë³¸ íŒŒì¸íŠœë‹ ëª¨ë¸
- **test222**: ëŒ€ì•ˆ íŒŒì¸íŠœë‹ ëª¨ë¸

### ëª¨ë¸ êµ¬ì¡°
ê° ëª¨ë¸ì€ ë‹¤ìŒ ë‘ ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±:
- `{ëª¨ë¸ëª…}_category`: ESG ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
- `{ëª¨ë¸ëª…}_sentiment`: ê°ì • ë¶„ì„

## ğŸ§ª v2.0 API í…ŒìŠ¤íŠ¸

### í—¬ìŠ¤ì²´í¬
```bash
curl http://localhost:8002/api/v1/system/health
# ì‘ë‹µ: {"status": "healthy", "service": "news-service", "version": "2.0"}
```

### ğŸ” ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ API í…ŒìŠ¤íŠ¸

#### 1. íšŒì‚¬ ë‰´ìŠ¤ ê²€ìƒ‰ (ìŠ¤ë§ˆíŠ¸ ìºì‹œ)
```bash
# PowerShell
Invoke-WebRequest -Uri "http://localhost:8002/api/v1/search/companies/ì‚¼ì„±ì „ì" `
  -Method POST `
  -ContentType "application/json" `
  -Body '{"max_results": 10}' |
  Select-Object -ExpandProperty Content

# Linux/Mac/WSL
curl -X POST http://localhost:8002/api/v1/search/companies/ì‚¼ì„±ì „ì \
  -H "Content-Type: application/json" \
  -d '{"max_results": 10}'
```

#### 2. íšŒì‚¬ ë‰´ìŠ¤ ë¶„ì„ (ìŠ¤ë§ˆíŠ¸ ìºì‹œ)
```bash
# PowerShell
Invoke-WebRequest -Uri "http://localhost:8002/api/v1/search/companies/ì‚¼ì„±ì „ì/analyze" `
  -Method POST `
  -ContentType "application/json" `
  -Body '{"max_results": 50, "force_refresh": false}' |
  Select-Object -ExpandProperty Content

# Linux/Mac/WSL
curl -X POST http://localhost:8002/api/v1/search/companies/ì‚¼ì„±ì „ì/analyze \
  -H "Content-Type: application/json" \
  -d '{"max_results": 50, "force_refresh": false}'
```

#### 3. ì¼ë°˜ ë‰´ìŠ¤ ê²€ìƒ‰
```bash
curl -X POST http://localhost:8002/api/v1/search/news \
  -H "Content-Type: application/json" \
  -d '{"query": "ESG", "max_results": 10}'
```

### ğŸ“Š ëŒ€ì‹œë³´ë“œ API í…ŒìŠ¤íŠ¸ (Redis í™˜ê²½ í•„ìš”)

#### 1. ì „ì²´ ìƒíƒœ ì¡°íšŒ
```bash
curl http://localhost:8002/api/v1/dashboard/status
```

#### 2. íšŒì‚¬ ìµœì‹  ë¶„ì„ ê²°ê³¼
```bash
curl http://localhost:8002/api/v1/dashboard/companies/ì‚¼ì„±ì „ì/latest
```

#### 3. ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ìš”ì²­
```bash
curl -X POST http://localhost:8002/api/v1/dashboard/companies/ì‚¼ì„±ì „ì/trigger
```

### ğŸ› ï¸ ì‹œìŠ¤í…œ ê´€ë¦¬ API í…ŒìŠ¤íŠ¸

#### 1. í†µí•© í…ŒìŠ¤íŠ¸
```bash
curl http://localhost:8002/api/v1/system/test/integration
```

## ìƒíƒœ í™•ì¸

### ë¡œê·¸ í™•ì¸
```bash
# CPU í™˜ê²½
docker-compose -f docker-compose.cpu.yml logs -f

# Redis í™˜ê²½ (ê¶Œì¥)
docker-compose -f docker-compose.redis.yml logs -f

# GPU í™˜ê²½
docker-compose -f docker-compose.gpu.yml logs -f

# ë””ë°”ì´ìŠ¤ í™•ì¸
docker-compose -f docker-compose.cpu.yml logs | grep "ë””ë°”ì´ìŠ¤"
```

### ì˜ˆìƒ ë¡œê·¸ (v2.0 ë¦¬íŒ©í„°ë§ ì™„ë£Œ)
```
# ì •ìƒ ì‹œì‘ ë¡œê·¸
âœ… News Service v2.0 ì‹œì‘ ì™„ë£Œ (ë¦¬íŒ©í„°ë§ ì™„ë£Œ)
ğŸ”§ í†µí•© ë¼ìš°í„° ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ
ğŸ”— ì˜ì¡´ì„± ì£¼ì… ì»¨í…Œì´ë„ˆ ì´ˆê¸°í™” ì™„ë£Œ (Clean Architecture ì ìš©)
âš¡ ìŠ¤ë§ˆíŠ¸ ìºì‹œ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ (Redis ì—°ê²° ì‹œ)

# ë¦¬íŒ©í„°ë§ëœ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
âœ… MLInferenceService ì´ˆê¸°í™” ì™„ë£Œ (Extract Class ì ìš©)
âœ… NewsAnalysisService ì´ˆê¸°í™” ì™„ë£Œ (Strategy Pattern ì ìš©)
âœ… NewsService ì´ˆê¸°í™” ì™„ë£Œ (Extract Method ì ìš©)
âœ… DashboardService ì´ˆê¸°í™” ì™„ë£Œ (Factory Pattern ì ìš©)
âœ… AnalysisWorkflowService ì´ˆê¸°í™” ì™„ë£Œ

# ML ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
âœ… ë¡œì»¬ ML ì¶”ë¡  ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ
ML ì¶”ë¡  ì„œë¹„ìŠ¤ ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: cpu
CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.
ì¹´í…Œê³ ë¦¬ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: test222_category (ModelLoader íŒ©í† ë¦¬ ì‚¬ìš©)
ê°ì • ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: test222_sentiment (ModelLoader íŒ©í† ë¦¬ ì‚¬ìš©)

# ë¶„ì„ ì „ëµ ì´ˆê¸°í™”
âœ… ESG ë¶„ì„ ì „ëµ ë¡œë“œ ì™„ë£Œ (Strategy Pattern)
âœ… ê°ì • ë¶„ì„ ì „ëµ ë¡œë“œ ì™„ë£Œ (Strategy Pattern)
âœ… í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ì „ëµ ì¤€ë¹„ ì™„ë£Œ

# API ìš”ì²­ ì²˜ë¦¬ ë¡œê·¸
ğŸ” ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ ìš”ì²­: company=ì‚¼ì„±ì „ì, cache_hit=true, response_time=120ms
ğŸ“Š ëŒ€ì‹œë³´ë“œ ìƒíƒœ ì¡°íšŒ: redis_connected=true
ğŸ¯ ë¶„ì„ ì „ëµ ì„ íƒ: local_ml_strategy (ìš°ì„ ìˆœìœ„ ê¸°ë°˜)
```

## v2.0 ì‘ë‹µ ì˜ˆì‹œ

### ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ ì‘ë‹µ
```json
{
  "search_metadata": {
    "company": "ì‚¼ì„±ì „ì",
    "total_found": 1247,
    "returned_count": 50,
    "cache_hit": true,
    "response_time_ms": 120,
    "search_time": "2024-01-15T10:30:00Z"
  },
  "items": [
    {
      "title": "ì‚¼ì„±ì „ì, ESG ê²½ì˜ ê°•í™” ë°œí‘œ",
      "url": "https://example.com/news/123",
      "summary": "ì‚¼ì„±ì „ìê°€ í™˜ê²½ ì¹œí™”ì  ê²½ì˜ ë°©ì¹¨ì„ ë°œí‘œí–ˆë‹¤...",
      "published_date": "2024-01-15T10:30:00Z",
      "news_source": "ì¡°ì„ ë¹„ì¦ˆ",
      "relevance_score": 0.95
    }
  ],
  "deduplication": {
    "original_count": 75,
    "duplicates_removed": 25,
    "similarity_threshold": 0.75
  }
}
```

### ë¶„ì„ ì‘ë‹µ
```json
{
  "analysis_metadata": {
    "company": "ì‚¼ì„±ì „ì",
    "analyzed_count": 50,
    "analysis_time": "2024-01-15T10:30:00Z",
    "ml_service_status": "local_model",
    "cache_hit": false,
    "processing_time_ms": 3450
  },
  "analyzed_news": [
    {
      "title": "ì‚¼ì„±ì „ì, ESG ê²½ì˜ ê°•í™” ë°œí‘œ",
      "url": "https://example.com/news/123",
      "esg_classification": {
        "category": "E",
        "confidence": 0.95,
        "reasoning": "í™˜ê²½ ê´€ë ¨ ë‚´ìš© í¬í•¨"
      },
      "sentiment_analysis": {
        "label": "ê¸ì •",
        "confidence": 0.87,
        "scores": {
          "positive": 0.87,
          "neutral": 0.10,
          "negative": 0.03
        }
      }
    }
  ],
  "summary": {
    "total_analyzed": 50,
    "esg_distribution": {"E": 20, "S": 15, "G": 10, "ê¸°íƒ€": 5},
    "sentiment_distribution": {"ê¸ì •": 35, "ì¤‘ë¦½": 12, "ë¶€ì •": 3},
    "top_keywords": ["í™˜ê²½", "ESG", "ì§€ì†ê°€ëŠ¥ê²½ì˜"]
  }
}
```

## ğŸ› ï¸ í™˜ê²½ë³„ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ (ë¦¬íŒ©í„°ë§ v2.0)

### ğŸ¯ ë¬¸ì œ ì§„ë‹¨ ìš°ì„ ìˆœìœ„
1. **í™˜ê²½ í™•ì¸** â†’ ì˜¬ë°”ë¥¸ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
2. **ë¦¬íŒ©í„°ë§ ì„œë¹„ìŠ¤ ìƒíƒœ** â†’ 5ê°œ ì„œë¹„ìŠ¤ ì •ìƒ ì´ˆê¸°í™” í™•ì¸
3. **API ì—”ë“œí¬ì¸íŠ¸** â†’ v2.0 ìƒˆë¡œìš´ API êµ¬ì¡° ì‚¬ìš© í™•ì¸
4. **ì˜ì¡´ì„± ì£¼ì…** â†’ ì»¨í…Œì´ë„ˆ ì •ìƒ ë™ì‘ í™•ì¸

---

### 1ï¸âƒ£ CPU ê¸°ë³¸ í™˜ê²½ ë¬¸ì œ

#### âŒ ë¬¸ì œ: ì„œë¹„ìŠ¤ ì‹œì‘ ì‹¤íŒ¨
**ì¦ìƒ**: ì»¨í…Œì´ë„ˆê°€ ì‹œì‘ë˜ì§€ ì•Šê±°ë‚˜ ì¦‰ì‹œ ì¢…ë£Œ  
**ì§„ë‹¨**:
```bash
# 1. ë¡œê·¸ í™•ì¸ (ë¦¬íŒ©í„°ë§ëœ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ìƒíƒœ)
docker logs news-service-cpu

# 2. ì˜ì¡´ì„± ì£¼ì… ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker logs news-service-cpu | grep "dependencies.py"

# 3. ML ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ìƒíƒœ í™•ì¸
docker logs news-service-cpu | grep "MLInferenceService"
```
**í•´ê²° ë°©ë²•**:
```bash
# A. ëª¨ë¸ íŒŒì¼ í™•ì¸
ls ../newstun-service/models/test222_category/
ls ../newstun-service/models/test222_sentiment/

# B. .env íŒŒì¼ í•„ìˆ˜ ì„¤ì • í™•ì¸
grep -E "NAVER_CLIENT_ID|MODEL_NAME" .env

# C. ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker stop news-service-cpu
docker rm news-service-cpu
docker run -d --name news-service-cpu -p 8002:8002 \
  -v "$(pwd)/../newstun-service/models:/app/models" \
  -v "$(pwd)/.env:/app/.env:ro" \
  news-service:cpu-ultra-light
```

#### âŒ ë¬¸ì œ: í‚¤ì›Œë“œ í´ë°± ëª¨ë“œë¡œë§Œ ë™ì‘
**ì¦ìƒ**: "Strategy Pattern í´ë°±: í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤"  
**ì§„ë‹¨**:
```bash
# MLInferenceService ìƒíƒœ í™•ì¸
docker logs news-service-cpu | grep -E "(ëª¨ë¸|ML|íŒ©í† ë¦¬)"
```
**í•´ê²° ë°©ë²•**:
```bash
# A. ëª¨ë¸ íŒŒì¼ êµ¬ì¡° í™•ì¸
find ../newstun-service/models -name "*test222*" -type d

# B. ëª¨ë¸ ê¶Œí•œ í™•ì¸ ë° ìˆ˜ì •
chmod -R 755 ../newstun-service/models/

# C. MODEL_NAME í™˜ê²½ë³€ìˆ˜ í™•ì¸
docker exec news-service-cpu env | grep MODEL_NAME
```

#### âŒ ë¬¸ì œ: ëŠë¦° ì‘ë‹µ ì†ë„
**ì¦ìƒ**: API ì‘ë‹µ ì‹œê°„ì´ 10ì´ˆ ì´ìƒ  
**ìµœì í™” ë°©ë²•**:
```bash
# A. CPU ìµœì í™” ì„¤ì • ì¶”ê°€
cat >> .env << EOF
TORCH_NUM_THREADS=2
OMP_NUM_THREADS=2
TRANSFORMERS_OFFLINE=1
EOF

# B. ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker restart news-service-cpu

# C. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
docker stats news-service-cpu
```

---

### 2ï¸âƒ£ CPU + Redis í™˜ê²½ ë¬¸ì œ (â­ ê°€ì¥ ë§ì€ ë¬¸ì œ ë°œìƒ)

#### âŒ ë¬¸ì œ: Redis ì—°ê²° ì‹¤íŒ¨
**ì¦ìƒ**: `cache_hit: false` ë˜ëŠ” "Redis ì—°ê²° ì‹¤íŒ¨" ì—ëŸ¬  
**ì§„ë‹¨**:
```bash
# 1. Redis ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
docker-compose -f docker-compose.redis.yml ps

# 2. Redis ë¡œê·¸ í™•ì¸
docker-compose -f docker-compose.redis.yml logs redis

# 3. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
docker-compose -f docker-compose.redis.yml exec news-service ping redis
```
**í•´ê²° ë°©ë²•**:
```bash
# A. Redis ì„œë¹„ìŠ¤ ì¬ì‹œì‘
docker-compose -f docker-compose.redis.yml restart redis

# B. í¬íŠ¸ ì¶©ëŒ í™•ì¸
netstat -an | grep 6379

# C. Redis ì—°ê²° í…ŒìŠ¤íŠ¸
docker-compose -f docker-compose.redis.yml exec redis redis-cli ping
```

#### âŒ ë¬¸ì œ: Celery Worker ì‘ì—… ì‹¤íŒ¨
**ì¦ìƒ**: ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ì´ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ  
**ì§„ë‹¨**:
```bash
# 1. Celery Worker ìƒíƒœ í™•ì¸
docker-compose -f docker-compose.redis.yml logs celery-worker

# 2. Celery Beat ìŠ¤ì¼€ì¤„ í™•ì¸
docker-compose -f docker-compose.redis.yml logs celery-beat

# 3. í™œì„± ì‘ì—… í™•ì¸
docker-compose -f docker-compose.redis.yml exec celery-worker \
  celery -A app.workers.celery_app inspect active
```
**í•´ê²° ë°©ë²•**:
```bash
# A. Celery ë¸Œë¡œì»¤ ì„¤ì • í™•ì¸
grep CELERY .env

# B. ì‘ì—… í ì •ë¦¬
docker-compose -f docker-compose.redis.yml exec redis redis-cli flushdb

# C. Worker ì¬ì‹œì‘
docker-compose -f docker-compose.redis.yml restart celery-worker celery-beat
```

#### âŒ ë¬¸ì œ: ëŒ€ì‹œë³´ë“œ API 404 ì˜¤ë¥˜
**ì¦ìƒ**: `/api/v1/dashboard/*` ì—”ë“œí¬ì¸íŠ¸ ì ‘ê·¼ ë¶ˆê°€  
**í•´ê²° ë°©ë²•**:
```bash
# A. DashboardService ì´ˆê¸°í™” í™•ì¸
docker-compose -f docker-compose.redis.yml logs news-service | grep "DashboardService"

# B. ì˜¬ë°”ë¥¸ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
curl http://localhost:8002/api/v1/dashboard/status

# C. í†µí•© ë¼ìš°í„° ìƒíƒœ í™•ì¸
curl http://localhost:8002/docs  # Swagger UI í™•ì¸
```

#### âŒ ë¬¸ì œ: ìºì‹œ ë©”ëª¨ë¦¬ ë¶€ì¡±
**ì¦ìƒ**: Redis ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 100% ë˜ëŠ” OOM ì—ëŸ¬  
**ìµœì í™” ë°©ë²•**:
```bash
# A. Redis ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
docker-compose -f docker-compose.redis.yml exec redis redis-cli info memory

# B. ìºì‹œ ì •ë¦¬
curl -X DELETE http://localhost:8002/api/v1/dashboard/cache/all

# C. Redis ë©”ëª¨ë¦¬ ì„¤ì • ìµœì í™”
cat >> .env << EOF
REDIS_MAXMEMORY=2gb
REDIS_MAXMEMORY_POLICY=allkeys-lru
CACHE_TTL_HOURS=12
EOF
```

---

### 3ï¸âƒ£ GPU í™˜ê²½ ë¬¸ì œ

#### âŒ ë¬¸ì œ: GPU ì¸ì‹ ì‹¤íŒ¨
**ì¦ìƒ**: "CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤"  
**ì§„ë‹¨**:
```bash
# 1. í˜¸ìŠ¤íŠ¸ GPU ìƒíƒœ í™•ì¸
nvidia-smi

# 2. Docker GPU ì§€ì› í™•ì¸
docker run --rm --gpus all nvidia/cuda:11.8-base nvidia-smi

# 3. ì»¨í…Œì´ë„ˆ ë‚´ GPU í™•ì¸
docker exec news-service-gpu nvidia-smi
```
**í•´ê²° ë°©ë²•**:
```bash
# A. NVIDIA Container Toolkit ì„¤ì¹˜
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
  sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker

# B. GPU í™˜ê²½ë³€ìˆ˜ ì„¤ì •
cat >> .env << EOF
CUDA_VISIBLE_DEVICES=0
GPU_MEMORY_FRACTION=0.8
EOF

# C. GPU ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker-compose -f docker-compose.gpu.yml down
docker-compose -f docker-compose.gpu.yml up -d
```

#### âŒ ë¬¸ì œ: GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
**ì¦ìƒ**: "CUDA out of memory" ì—ëŸ¬  
**ìµœì í™” ë°©ë²•**:
```bash
# A. GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
nvidia-smi

# B. ë°°ì¹˜ í¬ê¸° ê°ì†Œ
cat >> .env << EOF
ML_BATCH_SIZE=16
GPU_MEMORY_FRACTION=0.7
EOF

# C. ë‹¤ë¥¸ GPU í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
sudo kill $(nvidia-smi --query-compute-apps=pid --format=csv,noheader,nounits)
```

#### âŒ ë¬¸ì œ: GPU ì„±ëŠ¥ ì €í•˜
**ì¦ìƒ**: CPU ëª¨ë“œë³´ë‹¤ ëŠë¦° ì¶”ë¡  ì†ë„  
**ìµœì í™” ë°©ë²•**:
```bash
# A. GPU ìµœì í™” ì„¤ì •
cat >> .env << EOF
TORCH_BACKENDS_CUDNN_BENCHMARK=true
TORCH_COMPILE=true
CUDA_LAUNCH_BLOCKING=0
EOF

# B. ëª¨ë¸ ì •ë°€ë„ ìµœì í™” (ì„ íƒì‚¬í•­)
cat >> .env << EOF
TORCH_DTYPE=float16
MIXED_PRECISION=true
EOF

# C. GPU í´ëŸ­ ìµœì í™” (ê¶Œí•œ í•„ìš”)
sudo nvidia-smi -pm 1
sudo nvidia-smi -ac 877,1215  # ë©”ëª¨ë¦¬/GPU í´ëŸ­ ì„¤ì •
```

---

### ğŸ”„ í™˜ê²½ë³„ ê³µí†µ ë¬¸ì œ

#### âŒ ë¬¸ì œ: v2.0 API ì—”ë“œí¬ì¸íŠ¸ 404 ì˜¤ë¥˜
**ì¦ìƒ**: ê¸°ì¡´ API í˜¸ì¶œ ì‹œ 404 ì˜¤ë¥˜  
**í•´ê²°**: ìƒˆë¡œìš´ v2.0 API êµ¬ì¡° ì‚¬ìš©
```bash
# âŒ êµ¬ ë²„ì „ (ë” ì´ìƒ ì‚¬ìš© ë¶ˆê°€)
curl http://localhost:8002/api/v1/news/company/simple/analyze

# âœ… v2.0 ìƒˆ ë²„ì „ (ë¦¬íŒ©í„°ë§ëœ êµ¬ì¡°)
curl -X POST http://localhost:8002/api/v1/search/companies/ì‚¼ì„±ì „ì/analyze \
  -H "Content-Type: application/json" \
  -d '{"max_results": 50}'
```

#### âŒ ë¬¸ì œ: ë¦¬íŒ©í„°ë§ëœ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨
**ì¦ìƒ**: "ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨" ë˜ëŠ” "ì˜ì¡´ì„± ì£¼ì… ì˜¤ë¥˜"  
**ì§„ë‹¨**:
```bash
# 1. ì˜ì¡´ì„± ì£¼ì… ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker logs [ì»¨í…Œì´ë„ˆëª…] | grep "dependencies.py"

# 2. ê° ì„œë¹„ìŠ¤ë³„ ì´ˆê¸°í™” í™•ì¸
docker logs [ì»¨í…Œì´ë„ˆëª…] | grep -E "(MLInferenceService|NewsAnalysisService|NewsService|DashboardService|AnalysisWorkflowService)"

# 3. Strategy Pattern ì´ˆê¸°í™” í™•ì¸
docker logs [ì»¨í…Œì´ë„ˆëª…] | grep "ì „ëµ"
```

#### âŒ ë¬¸ì œ: PowerShell ëª…ë ¹ì–´ ì˜¤ë¥˜
**ì¦ìƒ**: PowerShellì—ì„œ Docker ëª…ë ¹ì–´ ì‹¤í–‰ ì‹¤íŒ¨  
**í•´ê²° ë°©ë²•**:
```powershell
# âŒ ì˜ëª»ëœ ë°©ë²• (Bash ë¬¸ë²•)
docker run -d --name news-service-cpu \
  -v "$(pwd)/../newstun-service/models:/app/models"

# âœ… ì˜¬ë°”ë¥¸ ë°©ë²• (PowerShell ë¬¸ë²•)
docker run -d --name news-service-cpu `
  -v "${PWD}/../newstun-service/models:/app/models" `
  -v "${PWD}/.env:/app/.env:ro" `
  news-service:cpu-ultra-light

# ë˜ëŠ” í•œ ì¤„ë¡œ ì‘ì„±
docker run -d --name news-service-cpu -p 8002:8002 -v "${PWD}/../newstun-service/models:/app/models" -v "${PWD}/.env:/app/.env:ro" news-service:cpu-ultra-light
```

---

### ğŸš¨ ê¸´ê¸‰ ë³µêµ¬ ê°€ì´ë“œ

#### ì™„ì „ ì´ˆê¸°í™” (ëª¨ë“  í™˜ê²½)
```bash
# 1. ëª¨ë“  ì»¨í…Œì´ë„ˆ ì¤‘ì§€ ë° ì œê±°
docker stop $(docker ps -aq --filter "name=news-service")
docker rm $(docker ps -aq --filter "name=news-service")
docker-compose -f docker-compose.redis.yml down -v

# 2. ì´ë¯¸ì§€ ë‹¤ì‹œ ë¹Œë“œ
docker build -f Dockerfile.cpu -t news-service:cpu-ultra-light . --no-cache

# 3. í™˜ê²½ ì„¤ì • ì¬í™•ì¸
cat .env
ls ../newstun-service/models/

# 4. í™˜ê²½ë³„ ì¬ì‹œì‘
# CPU: 
docker run -d --name news-service-cpu -p 8002:8002 -v "${PWD}/../newstun-service/models:/app/models" -v "${PWD}/.env:/app/.env:ro" news-service:cpu-ultra-light

# Redis:
docker-compose -f docker-compose.redis.yml up -d

# GPU:
docker-compose -f docker-compose.gpu.yml up -d
```

#### í—¬ìŠ¤ì²´í¬ ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# health_check.sh - í™˜ê²½ë³„ ìƒíƒœ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸

echo "ğŸ” News Service v2.0 ìƒíƒœ í™•ì¸ (ë¦¬íŒ©í„°ë§ ì™„ë£Œ)"

# 1. ê¸°ë³¸ ì—°ê²° í™•ì¸
curl -s http://localhost:8002/api/v1/system/health | jq '.'

# 2. ë¦¬íŒ©í„°ë§ëœ ì„œë¹„ìŠ¤ í™•ì¸
echo "ğŸ“Š ë¦¬íŒ©í„°ë§ëœ ì„œë¹„ìŠ¤ ìƒíƒœ:"
curl -s http://localhost:8002/api/v1/dashboard/status | jq '.version, .redis_connected'

# 3. API ì‘ë‹µ ì‹œê°„ ì¸¡ì •
echo "â±ï¸ API ì‘ë‹µ ì‹œê°„:"
curl -w "ì‘ë‹µ ì‹œê°„: %{time_total}ì´ˆ\n" -o /dev/null -s http://localhost:8002/api/v1/system/health

# 4. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
echo "ğŸ’¾ ì»¨í…Œì´ë„ˆ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰:"
docker stats --no-stream --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}"
```

## ğŸ¯ í™˜ê²½ë³„ ìš´ì˜ ê¶Œì¥ì‚¬í•­ (ë¦¬íŒ©í„°ë§ v2.0)

### 1. ê°œë°œ í™˜ê²½ ìš´ì˜ ê°€ì´ë“œ

#### CPU ê¸°ë³¸ í™˜ê²½ (ê°œë°œ/í…ŒìŠ¤íŠ¸)
```bash
# ğŸ”§ ë¡œì»¬ ê°œë°œ ì„¤ì •
cat > .env.dev << EOF
# ê°œë°œ í™˜ê²½ ì„¤ì •
MODEL_NAME=test222
NAVER_CLIENT_ID=dev_client_id
NAVER_CLIENT_SECRET=dev_client_secret
LOG_LEVEL=DEBUG
CACHE_ENABLED=false

# ê°œë°œ ìµœì í™”
TORCH_NUM_THREADS=2
TRANSFORMERS_OFFLINE=1
EOF

# ê°œë°œ ì„œë²„ ì‹¤í–‰
docker run -d --name news-service-dev -p 8002:8002 \
  -v "$(pwd)/../newstun-service/models:/app/models" \
  -v "$(pwd)/.env.dev:/app/.env:ro" \
  news-service:cpu-ultra-light

# ë¦¬íŒ©í„°ë§ëœ ì„œë¹„ìŠ¤ ê°œë°œ í™•ì¸
curl http://localhost:8002/docs  # Swagger UIë¡œ API í…ŒìŠ¤íŠ¸
```

#### ê³ ê¸‰ ê°œë°œ í™˜ê²½ (í†µí•© í…ŒìŠ¤íŠ¸)
```bash
# Redis í¬í•¨ ê°œë°œ í™˜ê²½
cp .env.dev .env.integration
echo "REDIS_URL=redis://redis:6379/0" >> .env.integration
echo "CACHE_ENABLED=true" >> .env.integration
echo "CACHE_TTL_HOURS=1" >> .env.integration  # ê°œë°œìš© ì§§ì€ TTL

docker-compose -f docker-compose.redis.yml up -d

# ë¦¬íŒ©í„°ë§ëœ ì„œë¹„ìŠ¤ í†µí•© í…ŒìŠ¤íŠ¸
curl http://localhost:8002/api/v1/system/test/integration
```

### 2. í”„ë¡œë•ì…˜ í™˜ê²½ ìš´ì˜ ê°€ì´ë“œ

#### ì†Œ~ì¤‘ê·œëª¨ í”„ë¡œë•ì…˜ (CPU + Redis) â­ ê¶Œì¥
```bash
# ğŸ­ í”„ë¡œë•ì…˜ ì„¤ì •
cat > .env.prod << EOF
# í”„ë¡œë•ì…˜ í™˜ê²½ ì„¤ì •
MODEL_NAME=test222
NAVER_CLIENT_ID=prod_client_id
NAVER_CLIENT_SECRET=prod_client_secret
LOG_LEVEL=INFO

# Redis + Celery í”„ë¡œë•ì…˜ ì„¤ì •
REDIS_URL=redis://redis:6379/0
CACHE_ENABLED=true
CACHE_TTL_HOURS=24
CELERY_BROKER_URL=redis://redis:6379/1
CELERY_RESULT_BACKEND=redis://redis:6379/2

# í”„ë¡œë•ì…˜ ìµœì í™”
ANALYSIS_SCHEDULE_MINUTES=30
MONITORED_COMPANIES=ì‚¼ì„±ì „ì,LGì „ì,SKí•˜ì´ë‹‰ìŠ¤,ì¹´ì¹´ì˜¤,ë„¤ì´ë²„
HISTORY_MAX_COUNT=100
WORKER_CONCURRENCY=4
WORKER_PREFETCH_MULTIPLIER=4

# ë³´ì•ˆ ì„¤ì •
REDIS_PASSWORD=your_secure_password
JWT_SECRET_KEY=your_jwt_secret
EOF

# í”„ë¡œë•ì…˜ ë°°í¬
docker-compose -f docker-compose.redis.yml up -d

# ëª¨ë‹ˆí„°ë§ ì„¤ì •
echo "ğŸ“Š í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ:"
echo "http://localhost:8002/api/v1/dashboard/status"
```

#### ëŒ€ê·œëª¨ í”„ë¡œë•ì…˜ (GPU í™˜ê²½)
```bash
# ğŸš€ ê³ ì„±ëŠ¥ í”„ë¡œë•ì…˜ ì„¤ì •
cat > .env.gpu.prod << EOF
# GPU í”„ë¡œë•ì…˜ í™˜ê²½
MODEL_NAME=test222
LOG_LEVEL=INFO

# GPU ìµœì í™”
CUDA_VISIBLE_DEVICES=0,1  # ë©€í‹° GPU ì§€ì›
GPU_MEMORY_FRACTION=0.8
TORCH_BACKENDS_CUDNN_BENCHMARK=true
TORCH_COMPILE=true

# ê³ ì„±ëŠ¥ ì²˜ë¦¬ ì„¤ì •
ML_BATCH_SIZE=64
ML_MAX_WORKERS=8
INFERENCE_TIMEOUT=60

# í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§
PROMETHEUS_ENABLED=true
GRAFANA_ENABLED=true
EOF

# GPU í”„ë¡œë•ì…˜ ë°°í¬
docker-compose -f docker-compose.gpu.yml up -d

# GPU ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
nvidia-smi dmon -s pucvmet -d 5 > gpu_monitoring.log &
```

### 3. í™˜ê²½ë³„ ë³´ì•ˆ ì„¤ì • ê°€ì´ë“œ

#### ê°œë°œ í™˜ê²½ ë³´ì•ˆ
```bash
# ğŸ”’ ê°œë°œ í™˜ê²½ ë³´ì•ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸
echo "ê°œë°œ í™˜ê²½ ë³´ì•ˆ ì„¤ì •:"

# A. .env íŒŒì¼ ê¶Œí•œ ì„¤ì •
chmod 600 .env.dev
echo "âœ… .env íŒŒì¼ ê¶Œí•œ ì„¤ì • ì™„ë£Œ"

# B. ê°œë°œìš© API í‚¤ ë¶„ë¦¬
echo "âš ï¸ ì£¼ì˜: ê°œë°œ í™˜ê²½ì—ì„œëŠ” í”„ë¡œë•ì…˜ API í‚¤ ì‚¬ìš© ê¸ˆì§€"
grep -q "dev_client" .env.dev && echo "âœ… ê°œë°œìš© API í‚¤ ì‚¬ìš© ì¤‘" || echo "âŒ í”„ë¡œë•ì…˜ API í‚¤ í™•ì¸ í•„ìš”"

# C. ê°œë°œ ì»¨í…Œì´ë„ˆ ë„¤íŠ¸ì›Œí¬ ê²©ë¦¬
docker network create news-dev-network 2>/dev/null || true
```

#### í”„ë¡œë•ì…˜ í™˜ê²½ ë³´ì•ˆ (ì¤‘ìš”!)
```bash
# ğŸ” í”„ë¡œë•ì…˜ ë³´ì•ˆ ê°•í™” ì„¤ì •
echo "í”„ë¡œë•ì…˜ í™˜ê²½ ë³´ì•ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸:"

# A. í™˜ê²½ë³€ìˆ˜ ì•”í˜¸í™” (ì˜µì…˜)
cat > encrypt_env.sh << 'EOF'
#!/bin/bash
# .env íŒŒì¼ ì•”í˜¸í™” ìŠ¤í¬ë¦½íŠ¸
if [ -f ".env.prod" ]; then
    gpg --symmetric --cipher-algo AES256 .env.prod
    rm .env.prod
    echo "âœ… .env.prod ì•”í˜¸í™” ì™„ë£Œ (.env.prod.gpg)"
fi
EOF
chmod +x encrypt_env.sh

# B. ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ ì„¤ì •
docker network create news-prod-network \
  --driver bridge \
  --subnet=172.20.0.0/16 \
  --ip-range=172.20.240.0/20

# C. ì»¨í…Œì´ë„ˆ ë³´ì•ˆ ì„¤ì •
cat >> docker-compose.prod.yml << 'EOF'
version: '3.8'
services:
  news-service:
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=100m
    user: "1001:1001"  # ë¹„ root ì‚¬ìš©ì
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
EOF

# D. API í‚¤ ë¡œí…Œì´ì…˜ ìŠ¤í¬ë¦½íŠ¸
cat > rotate_api_keys.sh << 'EOF'
#!/bin/bash
echo "ğŸ”„ API í‚¤ ë¡œí…Œì´ì…˜ ì‹œì‘"
# 1. Naver API ì½˜ì†”ì—ì„œ ìƒˆ í‚¤ ìƒì„±
# 2. .env íŒŒì¼ ì—…ë°ì´íŠ¸
sed -i 's/NAVER_CLIENT_ID=.*/NAVER_CLIENT_ID=new_client_id/' .env.prod
sed -i 's/NAVER_CLIENT_SECRET=.*/NAVER_CLIENT_SECRET=new_client_secret/' .env.prod
# 3. ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker-compose -f docker-compose.redis.yml restart
echo "âœ… API í‚¤ ë¡œí…Œì´ì…˜ ì™„ë£Œ"
EOF
chmod +x rotate_api_keys.sh
```

#### GPU í™˜ê²½ ë³´ì•ˆ
```bash
# ğŸ® GPU í™˜ê²½ ë³´ì•ˆ ì„¤ì •
echo "GPU í™˜ê²½ ë³´ì•ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸:"

# A. GPU ë¦¬ì†ŒìŠ¤ ê²©ë¦¬
cat >> .env.gpu.prod << EOF
# GPU ë³´ì•ˆ ì„¤ì •
CUDA_VISIBLE_DEVICES=0  # íŠ¹ì • GPUë§Œ ì‚¬ìš©
NVIDIA_VISIBLE_DEVICES=0
NVIDIA_DRIVER_CAPABILITIES=compute,utility
EOF

# B. GPU ë©”ëª¨ë¦¬ ì œí•œ
echo "GPU_MEMORY_FRACTION=0.7" >> .env.gpu.prod

# C. GPU ëª¨ë‹ˆí„°ë§ ë³´ì•ˆ
nvidia-smi -pm 1  # ì§€ì† ëª¨ë“œ í™œì„±í™”
nvidia-smi -e 0   # ECC ë©”ëª¨ë¦¬ ë¹„í™œì„±í™” (ì„±ëŠ¥ ìš°ì„ ì‹œ)
```

### 4. í™˜ê²½ë³„ ëª¨ë‹ˆí„°ë§ ë° ë©”íŠ¸ë¦­ ìˆ˜ì§‘

#### CPU ê¸°ë³¸ í™˜ê²½ ëª¨ë‹ˆí„°ë§
```bash
# ğŸ“Š CPU í™˜ê²½ ëª¨ë‹ˆí„°ë§ ì„¤ì •
cat > monitoring_cpu.sh << 'EOF'
#!/bin/bash
echo "ğŸ“ˆ CPU í™˜ê²½ ëª¨ë‹ˆí„°ë§ ì‹œì‘"

# A. ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
docker stats news-service-cpu --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.MemPerc}}"

# B. ë¦¬íŒ©í„°ë§ëœ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
echo "ğŸ”§ ë¦¬íŒ©í„°ë§ëœ ì„œë¹„ìŠ¤ ìƒíƒœ:"
curl -s http://localhost:8002/api/v1/system/health | jq '.status, .version'

# C. API ì‘ë‹µ ì‹œê°„ ì¸¡ì •
echo "â±ï¸ API ì„±ëŠ¥ ì¸¡ì •:"
for i in {1..5}; do
  curl -w "%{time_total}s " -o /dev/null -s http://localhost:8002/api/v1/system/health
done
echo ""
EOF
chmod +x monitoring_cpu.sh
```

#### Redis í™˜ê²½ ê³ ê¸‰ ëª¨ë‹ˆí„°ë§
```bash
# ğŸ“Š Redis í™˜ê²½ ëª¨ë‹ˆí„°ë§ ì„¤ì •
cat > monitoring_redis.sh << 'EOF'
#!/bin/bash
echo "ğŸ“ˆ Redis í™˜ê²½ ê³ ê¸‰ ëª¨ë‹ˆí„°ë§ ì‹œì‘"

# A. ìºì‹œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
echo "ğŸ’¾ ìºì‹œ ì„±ëŠ¥:"
curl -s http://localhost:8002/api/v1/dashboard/cache/info | jq '.hit_rate_24h, .cache_size_mb'

# B. Celery ì‘ì—… ëª¨ë‹ˆí„°ë§
echo "âš¡ Celery ì‘ì—… ìƒíƒœ:"
docker-compose -f docker-compose.redis.yml exec celery-worker \
  celery -A app.workers.celery_app inspect stats | grep -E "(pool|rusage-utime)"

# C. Redis ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
echo "ğŸ—„ï¸ Redis ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:"
docker-compose -f docker-compose.redis.yml exec redis \
  redis-cli info memory | grep -E "(used_memory_human|maxmemory_human)"

# D. ë¦¬íŒ©í„°ë§ ì„œë¹„ìŠ¤ë³„ ì„±ëŠ¥
echo "ğŸ—ï¸ ë¦¬íŒ©í„°ë§ëœ ì„œë¹„ìŠ¤ë³„ ì„±ëŠ¥:"
echo "- MLInferenceService: $(docker logs news-service 2>&1 | grep 'MLInferenceService' | tail -1)"
echo "- NewsAnalysisService: $(docker logs news-service 2>&1 | grep 'NewsAnalysisService' | tail -1)"
echo "- DashboardService: $(docker logs news-service 2>&1 | grep 'DashboardService' | tail -1)"
EOF
chmod +x monitoring_redis.sh

# ìë™ ëª¨ë‹ˆí„°ë§ ì„¤ì • (cron)
(crontab -l 2>/dev/null; echo "*/5 * * * * /path/to/monitoring_redis.sh >> /var/log/news-service-monitoring.log") | crontab -
```

#### GPU í™˜ê²½ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
```bash
# ğŸ“Š GPU í™˜ê²½ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
cat > monitoring_gpu.sh << 'EOF'
#!/bin/bash
echo "ğŸ“ˆ GPU í™˜ê²½ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘"

# A. GPU ì‚¬ìš©ëŸ‰ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
echo "ğŸ® GPU ì‚¬ìš©ëŸ‰ (5ì´ˆ ê°„ê²©):"
nvidia-smi dmon -s pucvmet -d 5 -c 12 &
GPU_PID=$!

# B. ì¶”ë¡  ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
echo "ğŸš€ GPU ì¶”ë¡  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸:"
time curl -X POST http://localhost:8002/api/v1/search/companies/ì‚¼ì„±ì „ì/analyze \
  -H "Content-Type: application/json" \
  -d '{"max_results": 100}' > /dev/null

# C. GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
echo "ğŸ’¾ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:"
nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader,nounits

# D. ë¦¬íŒ©í„°ë§ëœ GPU ì„œë¹„ìŠ¤ ìƒíƒœ
echo "ğŸ—ï¸ GPU ê°€ì† ì„œë¹„ìŠ¤ ìƒíƒœ:"
docker logs news-service-gpu 2>&1 | grep -E "(GPU|CUDA|ëª¨ë¸)" | tail -5

# ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ
kill $GPU_PID 2>/dev/null
EOF
chmod +x monitoring_gpu.sh
```

### 5. ë°±ì—… ë° ë³µêµ¬ ê°€ì´ë“œ

#### Redis í™˜ê²½ ë°±ì—…
```bash
# ğŸ’¾ Redis í™˜ê²½ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
cat > backup_redis.sh << 'EOF'
#!/bin/bash
BACKUP_DIR="./backups/$(date +%Y%m%d_%H%M%S)"
mkdir -p $BACKUP_DIR

echo "ğŸ”„ Redis í™˜ê²½ ë°±ì—… ì‹œì‘: $BACKUP_DIR"

# A. Redis ë°ì´í„° ë°±ì—…
docker-compose -f docker-compose.redis.yml exec redis redis-cli BGSAVE
docker cp $(docker-compose -f docker-compose.redis.yml ps -q redis):/data/dump.rdb $BACKUP_DIR/

# B. í™˜ê²½ì„¤ì • ë°±ì—…
cp .env $BACKUP_DIR/
cp docker-compose.redis.yml $BACKUP_DIR/

# C. ë¶„ì„ íˆìŠ¤í† ë¦¬ ë°±ì—… (JSON)
curl -s http://localhost:8002/api/v1/dashboard/latest > $BACKUP_DIR/analysis_history.json

# D. ë¡œê·¸ ë°±ì—…
docker-compose -f docker-compose.redis.yml logs > $BACKUP_DIR/service_logs.txt

echo "âœ… ë°±ì—… ì™„ë£Œ: $BACKUP_DIR"
echo "ğŸ“Š ë°±ì—… í¬ê¸°: $(du -sh $BACKUP_DIR | cut -f1)"
EOF
chmod +x backup_redis.sh

# ìë™ ë°±ì—… ì„¤ì • (ë§¤ì¼ ìƒˆë²½ 2ì‹œ)
(crontab -l 2>/dev/null; echo "0 2 * * * /path/to/backup_redis.sh") | crontab -
```

#### ì¥ì•  ë³µêµ¬ ì‹œë‚˜ë¦¬ì˜¤
```bash
# ğŸš¨ ê¸´ê¸‰ ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸
cat > disaster_recovery.sh << 'EOF'
#!/bin/bash
echo "ğŸš¨ News Service ê¸´ê¸‰ ë³µêµ¬ ì‹œì‘"

# 1. ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
echo "ğŸ“Š í˜„ì¬ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸..."
docker ps | grep news-service
curl -s http://localhost:8002/api/v1/system/health > /dev/null
HEALTH_STATUS=$?

if [ $HEALTH_STATUS -eq 0 ]; then
    echo "âœ… ì„œë¹„ìŠ¤ ì •ìƒ ë™ì‘ ì¤‘"
    exit 0
fi

echo "âŒ ì„œë¹„ìŠ¤ ì¥ì•  ê°ì§€. ë³µêµ¬ ì‹œì‘..."

# 2. ë¡œê·¸ ìˆ˜ì§‘
mkdir -p ./disaster_logs/$(date +%Y%m%d_%H%M%S)
docker logs news-service > ./disaster_logs/$(date +%Y%m%d_%H%M%S)/service.log 2>&1

# 3. ê°•ì œ ì¬ì‹œì‘
echo "ğŸ”„ ì„œë¹„ìŠ¤ ê°•ì œ ì¬ì‹œì‘..."
docker-compose -f docker-compose.redis.yml down
docker-compose -f docker-compose.redis.yml up -d

# 4. í—¬ìŠ¤ì²´í¬ (ìµœëŒ€ 5ë¶„ ëŒ€ê¸°)
echo "ğŸ” ë³µêµ¬ ìƒíƒœ í™•ì¸..."
for i in {1..30}; do
    sleep 10
    if curl -s http://localhost:8002/api/v1/system/health > /dev/null; then
        echo "âœ… ì„œë¹„ìŠ¤ ë³µêµ¬ ì™„ë£Œ! (${i}0ì´ˆ ì†Œìš”)"
        exit 0
    fi
    echo "â³ ë³µêµ¬ ëŒ€ê¸° ì¤‘... (${i}/30)"
done

echo "âŒ ìë™ ë³µêµ¬ ì‹¤íŒ¨. ìˆ˜ë™ ê°œì… í•„ìš”"
echo "ğŸ“ ë‹´ë‹¹ìì—ê²Œ ì—°ë½í•˜ì„¸ìš”"
exit 1
EOF
chmod +x disaster_recovery.sh
```

### 6. ì„±ëŠ¥ íŠœë‹ ë° ìµœì í™”

#### í™˜ê²½ë³„ ì„±ëŠ¥ íŠœë‹ ë§¤íŠ¸ë¦­ìŠ¤

| ìµœì í™” í•­ëª© | CPU ê¸°ë³¸ | CPU + Redis | GPU | íš¨ê³¼ |
|-------------|----------|-------------|-----|------|
| **ëª¨ë¸ ë¡œë”© ìµœì í™”** | âœ… í•„ìˆ˜ | âœ… í•„ìˆ˜ | âœ… í•„ìˆ˜ | ì‹œì‘ ì‹œê°„ 50% ë‹¨ì¶• |
| **ë°°ì¹˜ ì²˜ë¦¬ íŠœë‹** | âœ… ê¶Œì¥ | âœ… í•„ìˆ˜ | âœ… í•„ìˆ˜ | ì²˜ë¦¬ëŸ‰ 200% í–¥ìƒ |
| **ìºì‹œ ì „ëµ ìµœì í™”** | âŒ | âœ… í•„ìˆ˜ | âŒ | ì‘ë‹µì‹œê°„ 80% ë‹¨ì¶• |
| **GPU ë©”ëª¨ë¦¬ ìµœì í™”** | âŒ | âŒ | âœ… í•„ìˆ˜ | ë™ì‹œì²˜ë¦¬ 300% í–¥ìƒ |
| **ë„¤íŠ¸ì›Œí¬ ìµœì í™”** | âœ… ê¶Œì¥ | âœ… ê¶Œì¥ | âœ… ê¶Œì¥ | ëŒ€ì—­í­ 30% ì ˆì•½ |

#### ìë™ ì„±ëŠ¥ íŠœë‹ ìŠ¤í¬ë¦½íŠ¸
```bash
# ğŸš€ ìë™ ì„±ëŠ¥ íŠœë‹ ìŠ¤í¬ë¦½íŠ¸
cat > auto_tuning.sh << 'EOF'
#!/bin/bash
ENVIRONMENT=$1  # cpu, redis, gpu

echo "ğŸ¯ $ENVIRONMENT í™˜ê²½ ìë™ ì„±ëŠ¥ íŠœë‹ ì‹œì‘"

case $ENVIRONMENT in
    "cpu")
        echo "âš™ï¸ CPU í™˜ê²½ ìµœì í™” ì ìš©"
        echo "TORCH_NUM_THREADS=2" >> .env
        echo "OMP_NUM_THREADS=2" >> .env
        echo "TRANSFORMERS_OFFLINE=1" >> .env
        docker restart news-service-cpu
        ;;
    "redis")
        echo "âš™ï¸ Redis í™˜ê²½ ìµœì í™” ì ìš©"
        echo "CACHE_TTL_HOURS=24" >> .env
        echo "WORKER_CONCURRENCY=4" >> .env
        echo "REDIS_MAXMEMORY_POLICY=allkeys-lru" >> .env
        docker-compose -f docker-compose.redis.yml restart
        ;;
    "gpu")
        echo "âš™ï¸ GPU í™˜ê²½ ìµœì í™” ì ìš©"
        echo "TORCH_BACKENDS_CUDNN_BENCHMARK=true" >> .env
        echo "GPU_MEMORY_FRACTION=0.8" >> .env
        echo "ML_BATCH_SIZE=32" >> .env
        docker-compose -f docker-compose.gpu.yml restart
        ;;
    *)
        echo "âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” í™˜ê²½: $ENVIRONMENT"
        echo "ì‚¬ìš©ë²•: ./auto_tuning.sh [cpu|redis|gpu]"
        exit 1
        ;;
esac

echo "âœ… $ENVIRONMENT í™˜ê²½ ìµœì í™” ì™„ë£Œ"
echo "ğŸ“Š ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ê°œì„  íš¨ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”"
EOF
chmod +x auto_tuning.sh

# ì‚¬ìš© ì˜ˆì‹œ:
# ./auto_tuning.sh redis
```

## í™˜ê²½ë³„ ì„ íƒ ê°€ì´ë“œ (v2.0)

### CPU í™˜ê²½ ê¶Œì¥
- ê°œë°œ/í…ŒìŠ¤íŠ¸ í™˜ê²½
- ì†Œê·œëª¨ ì²˜ë¦¬ëŸ‰ (<100 ë‰´ìŠ¤/ì¼)
- GPU ì—†ëŠ” ì„œë²„
- ìºì‹œ ì—†ëŠ” ë‹¨ìˆœ í…ŒìŠ¤íŠ¸

### CPU + Redis í™˜ê²½ ê¶Œì¥ (â­ ì¶”ì²œ)
- ì¼ë°˜ì ì¸ í”„ë¡œë•ì…˜ í™˜ê²½
- ì¤‘ê°„ ê·œëª¨ ì²˜ë¦¬ëŸ‰ (100-1000 ë‰´ìŠ¤/ì¼)
- ëŒ€ì‹œë³´ë“œ ê¸°ëŠ¥ í•„ìš”
- ìŠ¤ë§ˆíŠ¸ ìºì‹œ í™œìš©

### GPU í™˜ê²½ ê¶Œì¥  
- ê³ ì„±ëŠ¥ í”„ë¡œë•ì…˜ í™˜ê²½
- ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ (>1000 ë‰´ìŠ¤/ì¼)
- ì‹¤ì‹œê°„ ë¶„ì„ ìš”êµ¬ì‚¬í•­ 
- ìµœê³  ì„±ëŠ¥ í•„ìš”

# News Service ë°°í¬ ê°€ì´ë“œ (ìš©ëŸ‰ ìµœì í™”)

## ğŸš€ ë°°í¬ ì˜µì…˜

### 1. CPU ë²„ì „ (ê¶Œì¥ - ê²½ëŸ‰)
```bash
docker-compose -f docker-compose.cpu.yml up -d
```
- **ì˜ˆìƒ ìš©ëŸ‰**: ~2-3GB
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: ~1-2GB
- **ì„±ëŠ¥**: ì¤‘ê°„ (CPU ì¶”ë¡ )

### 2. CPU + Redis ë²„ì „ (â­ ê¶Œì¥ - ìŠ¤ë§ˆíŠ¸ ìºì‹œ)
```bash
docker-compose -f docker-compose.redis.yml up -d
```
- **ì˜ˆìƒ ìš©ëŸ‰**: ~3-4GB
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: ~2-3GB
- **ì„±ëŠ¥**: ë¹ ë¦„ (ìºì‹œ ì ì¤‘ ì‹œ), ëŒ€ì‹œë³´ë“œ ê¸°ëŠ¥

### 3. GPU ë²„ì „ (ìµœì í™”ë¨)
```bash
docker-compose -f docker-compose.gpu.yml up -d
```
- **ì˜ˆìƒ ìš©ëŸ‰**: ~6-8GB (ê¸°ì¡´ 26GB â†’ ëŒ€í­ ê°ì†Œ)
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: ~2-4GB
- **ì„±ëŠ¥**: ë¹ ë¦„ (GPU ì¶”ë¡ )

## ğŸ¯ ìš©ëŸ‰ ìµœì í™” ì ìš© ì‚¬í•­

### Docker ì´ë¯¸ì§€ ìµœì í™”
1. **ë² ì´ìŠ¤ ì´ë¯¸ì§€ ë³€ê²½**:
   - `nvidia/cuda:11.8.0-devel` â†’ `nvidia/cuda:11.8.0-runtime`
   - ê°œë°œ ë„êµ¬ ì œê±°ë¡œ **~4GB ì ˆì•½**

2. **PyTorch ë²„ì „ ê³ ì •**:
   - ìµœì‹  ë²„ì „ ëŒ€ì‹  ì•ˆì •ëœ ë²„ì „ ì‚¬ìš©
   - `torch==2.0.1+cu118` ê³ ì •ìœ¼ë¡œ **~2GB ì ˆì•½**

3. **ìºì‹œ ë¹„í™œì„±í™”**:
   - pip, transformers, torch ìºì‹œ ë¹„í™œì„±í™”
   - ì„ì‹œ ë””ë ‰í† ë¦¬ë¥¼ tmpfsë¡œ ë§ˆìš´íŠ¸

4. **ë©€í‹°ìŠ¤í…Œì´ì§€ ë¹Œë“œ**:
   - ë¹Œë“œ ë„êµ¬ì™€ ëŸ°íƒ€ì„ ë¶„ë¦¬
   - ë¶ˆí•„ìš”í•œ íŒŒì¼ ì •ë¦¬

### ë©”ëª¨ë¦¬ ìµœì í™”
1. **ëª¨ë¸ ë¡œë”© ìµœì í™”**:
   - `torch.float16` ì‚¬ìš© (GPU)
   - `local_files_only=True`
   - `low_cpu_mem_usage=True`

2. **GPU ë©”ëª¨ë¦¬ ê´€ë¦¬**:
   - `torch.cuda.empty_cache()` ìë™ í˜¸ì¶œ
   - CUDNN ìµœì í™” ì„¤ì •

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ (v2.0)

| ë²„ì „ | ì´ë¯¸ì§€ í¬ê¸° | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | ë¹Œë“œ ì‹œê°„ | ì¶”ë¡  ì†ë„ | ìºì‹œ ê¸°ëŠ¥ |
|------|-------------|---------------|-----------|-----------|-----------|
| CPU | ~2-3GB | ~1-2GB | ~5ë¶„ | ë³´í†µ | âŒ |
| CPU+Redis | ~3-4GB | ~2-3GB | ~6ë¶„ | ë¹ ë¦„(ìºì‹œ) | âœ… |
| GPU (ìµœì í™” ì „) | ~26GB | ~8GB | ~20ë¶„ | ë¹ ë¦„ | âŒ |
| GPU (ìµœì í™” í›„) | ~6-8GB | ~2-4GB | ~10ë¶„ | ë¹ ë¦„ | âŒ |

## ğŸ› ï¸ ì¶”ê°€ ìµœì í™” ì˜µì…˜

### 1. ëª¨ë¸ ì–‘ìí™” (ì„ íƒì‚¬í•­)
```bash
python optimize_models.py
```
- ëª¨ë¸ í¬ê¸° **50-70% ê°ì†Œ**
- ì„±ëŠ¥ ì†ì‹¤ **<5%**

### 2. ìºì‹œ ì •ë¦¬
```bash
# Docker ìºì‹œ ì •ë¦¬
docker system prune -a

# ì´ë¯¸ì§€ ì •ë¦¬
docker image prune -a
```

### 3. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
```env
# .env íŒŒì¼ì— ì¶”ê°€
HF_HOME=/tmp/huggingface
TRANSFORMERS_CACHE=/tmp/transformers_cache
TORCH_HOME=/tmp/torch_cache
PIP_NO_CACHE_DIR=1
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **GPU ë“œë¼ì´ë²„**: CUDA 11.8 í˜¸í™˜ ë“œë¼ì´ë²„ í•„ìš”
2. **ë©”ëª¨ë¦¬**: ìµœì†Œ 4GB RAM ê¶Œì¥ (Redis í¬í•¨ ì‹œ 6GB)
3. **ë””ìŠ¤í¬**: ìµœì†Œ 10GB ì—¬ìœ  ê³µê°„ í•„ìš”
4. **ëª¨ë¸ íŒŒì¼**: `../newstun-service/models` ë””ë ‰í† ë¦¬ í•„ìš”

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ìš©ëŸ‰ ë¶€ì¡± ì‹œ
1. CPU ë²„ì „ ì‚¬ìš© ê³ ë ¤
2. ëª¨ë¸ ì–‘ìí™” ì ìš©
3. Docker ìºì‹œ ì •ë¦¬

### ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ
1. `docker-compose.gpu.yml`ì—ì„œ ë©”ëª¨ë¦¬ ì œí•œ ì¡°ì •
2. ë‹¤ë¥¸ ì»¨í…Œì´ë„ˆ ì¢…ë£Œ
3. GPU ë©”ëª¨ë¦¬ í™•ì¸

### ë¹Œë“œ ì‹¤íŒ¨ ì‹œ
1. Docker ì¬ì‹œì‘
2. ìºì‹œ ì •ë¦¬ í›„ ì¬ë¹Œë“œ
3. ì¸í„°ë„· ì—°ê²° í™•ì¸ 