"""ë¶„ì„ ì „ëµ íŒ¨í„´ - ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”"""
import asyncio
from abc import ABC, abstractmethod
from typing import Dict, Any, List
from app.config.ml_settings import ml_processing_settings

class ESGAnalysisStrategy(ABC):
    """ESG ë¶„ì„ ì „ëµ ì¶”ìƒ í´ë˜ìŠ¤"""
    
    @abstractmethod
    async def analyze(self, text: str) -> Dict[str, Any]:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ESG ë¶„ì„"""
        pass
    
    @abstractmethod
    async def analyze_batch(self, texts: List[str]) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ í…ìŠ¤íŠ¸ ESG ë¶„ì„"""
        pass

class SentimentAnalysisStrategy(ABC):
    """ê°ì • ë¶„ì„ ì „ëµ ì¶”ìƒ í´ë˜ìŠ¤"""
    
    @abstractmethod
    async def analyze(self, text: str) -> Dict[str, Any]:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„"""
        pass
    
    @abstractmethod
    async def analyze_batch(self, texts: List[str]) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„"""
        pass

class KeywordBasedESGStrategy(ESGAnalysisStrategy):
    """í‚¤ì›Œë“œ ê¸°ë°˜ ESG ë¶„ì„"""
    
    def __init__(self):
        self.esg_keywords = {
            "í™˜ê²½(E)": ["í™˜ê²½", "íƒ„ì†Œ", "ì¹œí™˜ê²½", "ì¬ìƒì—ë„ˆì§€", "ì˜¨ì‹¤ê°€ìŠ¤", "ê¸°í›„ë³€í™”"],
            "ì‚¬íšŒ(S)": ["ì‚¬íšŒ", "ì¸ê¶Œ", "ë‹¤ì–‘ì„±", "ì•ˆì „", "ì§ì›", "ê³ ìš©"],
            "ì§€ë°°êµ¬ì¡°(G)": ["ê±°ë²„ë„ŒìŠ¤", "ìœ¤ë¦¬", "íˆ¬ëª…", "ì»´í”Œë¼ì´ì–¸ìŠ¤", "ì´ì‚¬íšŒ"],
            "í†µí•©ESG": ["esg", "ì§€ì†ê°€ëŠ¥", "ì§€ì†ê°€ëŠ¥ì„±"]
        }
    
    async def analyze(self, text: str) -> Dict[str, Any]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ESG ë¶„ì„"""
        await asyncio.sleep(0)  # ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•œ ì–‘ë³´
        
        text = text.lower()
        best_category = "ê¸°íƒ€"
        best_score = 0.0
        matched_keywords = []
        
        for category, keywords in self.esg_keywords.items():
            matches = [keyword for keyword in keywords if keyword in text]
            if matches:
                score = len(matches) / len(keywords)
                if score > best_score:
                    best_score = score
                    best_category = category
                    matched_keywords = matches
        
        return {
            "category": best_category,
            "confidence": min(best_score + 0.4, 1.0),
            "keywords": matched_keywords,
            "method": "keyword_fallback"
        }
    
    async def analyze_batch(self, texts: List[str]) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ í‚¤ì›Œë“œ ê¸°ë°˜ ESG ë¶„ì„"""
        await asyncio.sleep(0)
        
        results = []
        for text in texts:
            result = await self.analyze(text)
            results.append(result)
        
        return results

class KeywordBasedSentimentStrategy(SentimentAnalysisStrategy):
    """í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ë¶„ì„"""
    
    def __init__(self):
        self.positive_keywords = ["ì„±ì¥", "ì¦ê°€", "ê°œì„ ", "ì„±ê³µ", "ë°œì „", "ìƒìŠ¹", "í˜¸ì¡°"]
        self.negative_keywords = ["ê°ì†Œ", "í•˜ë½", "ë¬¸ì œ", "ìœ„í—˜", "ì†ì‹¤", "ì•…í™”", "ìš°ë ¤"]
    
    async def analyze(self, text: str) -> Dict[str, Any]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ë¶„ì„"""
        await asyncio.sleep(0)  # ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•œ ì–‘ë³´
        
        text = text.lower()
        positive_count = sum(1 for keyword in self.positive_keywords if keyword in text)
        negative_count = sum(1 for keyword in self.negative_keywords if keyword in text)
        
        if positive_count > negative_count:
            sentiment = "ê¸ì •"
            positive_score = 0.7
            negative_score = 0.2
            neutral_score = 0.1
        elif negative_count > positive_count:
            sentiment = "ë¶€ì •"
            positive_score = 0.2
            negative_score = 0.7
            neutral_score = 0.1
        else:
            sentiment = "ì¤‘ë¦½"
            positive_score = 0.3
            negative_score = 0.3
            neutral_score = 0.4
        
        confidence = min((abs(positive_count - negative_count) + 1) * 0.2, 1.0)
        
        return {
            "sentiment": sentiment,
            "confidence": confidence,
            "positive": positive_score,
            "negative": negative_score,
            "neutral": neutral_score,
            "method": "keyword_fallback"
        }
    
    async def analyze_batch(self, texts: List[str]) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ë¶„ì„"""
        await asyncio.sleep(0)
        
        results = []
        for text in texts:
            result = await self.analyze(text)
            results.append(result)
        
        return results

class MLBasedESGStrategy(ESGAnalysisStrategy):
    """ML ëª¨ë¸ ê¸°ë°˜ ESG ë¶„ì„ - ë°°ì¹˜ ìµœì í™”"""
    
    def __init__(self, model, tokenizer, label_mapping, device, max_length=512):
        self.model = model
        self.tokenizer = tokenizer
        self.label_mapping = label_mapping
        self.device = device
        self.max_length = max_length
    
    async def analyze(self, text: str) -> Dict[str, Any]:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ML ê¸°ë°˜ ESG ë¶„ì„"""
        batch_results = await self.analyze_batch([text])
        return batch_results[0] if batch_results else self._get_default_result()
    
    async def analyze_batch(self, texts: List[str]) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ ML ê¸°ë°˜ ESG ë¶„ì„ - í•µì‹¬ ìµœì í™”"""
        await asyncio.sleep(0)  # ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•œ ì–‘ë³´
        
        if not texts:
            return []
        
        try:
            import torch  # type: ignore
            
            # ğŸš€ ë°°ì¹˜ í† í¬ë‚˜ì´ì§• (í•œ ë²ˆì— ëª¨ë“  í…ìŠ¤íŠ¸ ì²˜ë¦¬)
            inputs = self.tokenizer(
                texts,
                truncation=True,
                padding=True,
                max_length=self.max_length,
                return_tensors="pt"
            )
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # ğŸš€ ë°°ì¹˜ ì˜ˆì¸¡ (í•œ ë²ˆì— ëª¨ë“  ì˜ˆì¸¡ ìˆ˜í–‰)
            with torch.no_grad():  # type: ignore
                outputs = self.model(**inputs)
                logits = outputs.logits
                probabilities = torch.nn.functional.softmax(logits, dim=-1)  # type: ignore
                predicted_classes = torch.argmax(probabilities, dim=-1)  # type: ignore
                confidences = torch.max(probabilities, dim=-1)[0]  # type: ignore
            
            # ê²°ê³¼ ë³€í™˜
            results = []
            for i in range(len(texts)):
                predicted_class = predicted_classes[i].item()
                confidence = confidences[i].item()
                predicted_label = self.label_mapping.get(str(predicted_class), "ê¸°íƒ€")
                
                # ëª¨ë“  í´ë˜ìŠ¤ì˜ í™•ë¥  ê³„ì‚°
                class_probabilities = {}
                for j, prob in enumerate(probabilities[i].tolist()):
                    label = self.label_mapping.get(str(j), f"class_{j}")
                    class_probabilities[label] = prob
                
                results.append({
                    "category": predicted_label,
                    "confidence": confidence,
                    "probabilities": class_probabilities,
                    "method": "fine_tuned_model_batch"
                })
            
            return results
            
        except Exception as e:
            print(f"âŒ ML ESG ë°°ì¹˜ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê²°ê³¼ ë°˜í™˜
            return [self._get_default_result() for _ in texts]
    
    def _get_default_result(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ê²°ê³¼"""
        return {
            "category": "ê¸°íƒ€",
            "confidence": 0.0,
            "probabilities": {},
            "method": "error_fallback"
        }

class MLBasedSentimentStrategy(SentimentAnalysisStrategy):
    """ML ëª¨ë¸ ê¸°ë°˜ ê°ì • ë¶„ì„ - ë°°ì¹˜ ìµœì í™”"""
    
    def __init__(self, model, tokenizer, label_mapping, device, max_length=512):
        self.model = model
        self.tokenizer = tokenizer
        self.label_mapping = label_mapping
        self.device = device
        self.max_length = max_length
    
    async def analyze(self, text: str) -> Dict[str, Any]:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ML ê¸°ë°˜ ê°ì • ë¶„ì„"""
        batch_results = await self.analyze_batch([text])
        return batch_results[0] if batch_results else self._get_default_result()
    
    async def analyze_batch(self, texts: List[str]) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ ML ê¸°ë°˜ ê°ì • ë¶„ì„ - í•µì‹¬ ìµœì í™”"""
        await asyncio.sleep(0)  # ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•œ ì–‘ë³´
        
        if not texts:
            return []
        
        try:
            import torch  # type: ignore
            
            # ğŸš€ ë°°ì¹˜ í† í¬ë‚˜ì´ì§• (í•œ ë²ˆì— ëª¨ë“  í…ìŠ¤íŠ¸ ì²˜ë¦¬)
            inputs = self.tokenizer(
                texts,
                truncation=True,
                padding=True,
                max_length=self.max_length,
                return_tensors="pt"
            )
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # ğŸš€ ë°°ì¹˜ ì˜ˆì¸¡ (í•œ ë²ˆì— ëª¨ë“  ì˜ˆì¸¡ ìˆ˜í–‰)
            with torch.no_grad():  # type: ignore
                outputs = self.model(**inputs)
                logits = outputs.logits
                probabilities = torch.nn.functional.softmax(logits, dim=-1)  # type: ignore
                predicted_classes = torch.argmax(probabilities, dim=-1)  # type: ignore
                confidences = torch.max(probabilities, dim=-1)[0]  # type: ignore
            
            # ê²°ê³¼ ë³€í™˜
            results = []
            for i in range(len(texts)):
                predicted_class = predicted_classes[i].item()
                confidence = confidences[i].item()
                predicted_label = self.label_mapping.get(str(predicted_class), "ì¤‘ë¦½")
                
                # ëª¨ë“  í´ë˜ìŠ¤ì˜ í™•ë¥  ê³„ì‚°
                class_probabilities = {}
                for j, prob in enumerate(probabilities[i].tolist()):
                    label = self.label_mapping.get(str(j), f"class_{j}")
                    class_probabilities[label] = prob
                
                results.append({
                    "sentiment": predicted_label,
                    "confidence": confidence,
                    "probabilities": class_probabilities,
                    "method": "fine_tuned_model_batch"
                })
            
            return results
            
        except Exception as e:
            print(f"âŒ ML ê°ì • ë°°ì¹˜ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê²°ê³¼ ë°˜í™˜
            return [self._get_default_result() for _ in texts]
    
    def _get_default_result(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ê²°ê³¼"""
        return {
            "sentiment": "ì¤‘ë¦½",
            "confidence": 0.0,
            "probabilities": {},
            "method": "error_fallback"
        }

class AnalysisContext:
    """ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ - ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”"""
    
    def __init__(self, esg_strategy: ESGAnalysisStrategy, sentiment_strategy: SentimentAnalysisStrategy):
        self.esg_strategy = esg_strategy
        self.sentiment_strategy = sentiment_strategy
    
    async def analyze_text(self, text: str) -> Dict[str, Any]:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¶„ì„"""
        batch_results = await self.analyze_batch([text])
        return batch_results[0] if batch_results else self._get_default_result()
    
    async def analyze_batch(self, texts: List[str]) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ í…ìŠ¤íŠ¸ ë¶„ì„ - ğŸš€ í•µì‹¬ ìµœì í™”"""
        if not texts:
            return []
        
        print(f"ğŸš€ ë°°ì¹˜ ë¶„ì„ ì‹œì‘: {len(texts)}ê°œ í…ìŠ¤íŠ¸")
        
        # ESGì™€ ê°ì • ë¶„ì„ì„ ë³‘ë ¬ë¡œ ë°°ì¹˜ ì²˜ë¦¬
        esg_task = asyncio.create_task(self.esg_strategy.analyze_batch(texts))
        sentiment_task = asyncio.create_task(self.sentiment_strategy.analyze_batch(texts))
        
        esg_results, sentiment_results = await asyncio.gather(esg_task, sentiment_task)
        
        # ê²°ê³¼ ê²°í•©
        combined_results = []
        for i in range(len(texts)):
            esg_result = esg_results[i] if i < len(esg_results) else self._get_default_esg()
            sentiment_result = sentiment_results[i] if i < len(sentiment_results) else self._get_default_sentiment()
            
            combined_results.append({
                "esg": esg_result,
                "sentiment": sentiment_result
            })
        
        print(f"âœ… ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ: {len(combined_results)}ê°œ ê²°ê³¼")
        return combined_results
    
    def _get_default_result(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ê²°ê³¼"""
        return {
            "esg": self._get_default_esg(),
            "sentiment": self._get_default_sentiment()
        }
    
    def _get_default_esg(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ESG ê²°ê³¼"""
        return {
            "category": "ê¸°íƒ€",
            "confidence": 0.0,
            "probabilities": {},
            "method": "default"
        }
    
    def _get_default_sentiment(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ê°ì • ê²°ê³¼"""
        return {
            "sentiment": "ì¤‘ë¦½",
            "confidence": 0.0,
            "probabilities": {},
            "method": "default"
        } 