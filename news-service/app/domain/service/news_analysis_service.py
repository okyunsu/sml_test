"""ë¦¬íŒ©í† ë§ëœ ë‰´ìŠ¤ ë¶„ì„ ì„œë¹„ìŠ¤"""
import asyncio
from typing import Dict, Any, List, Optional
from contextlib import asynccontextmanager

from app.config.settings import settings
from app.domain.model.news_dto import (
    NewsSearchResponse, NewsAnalysisRequest, NewsAnalysisResponse,
    AnalyzedNewsItem, AnalysisSummary, ESGClassification, SentimentAnalysis, NewsItem
)
from app.core.http_client import HttpClientManager, MLHttpClientConfig
from app.config.ml_settings import ml_processing_settings
from app.domain.model.ml_strategies import (
    KeywordBasedESGStrategy, KeywordBasedSentimentStrategy, AnalysisContext
)

# ML ì¶”ë¡  ì„œë¹„ìŠ¤ import ì‹œë„
try:
    from app.domain.service.ml_inference_service import MLInferenceService
    ML_INFERENCE_AVAILABLE = True
except ImportError:
    MLInferenceService = None  # type: ignore
    ML_INFERENCE_AVAILABLE = False

class NewsAnalysisService:
    """ë‰´ìŠ¤ ë¶„ì„ ì„œë¹„ìŠ¤ - ë¦¬íŒ©í† ë§ ì™„ë£Œ"""
    
    def __init__(self):
        self.ml_service_url = settings.ml_service_url
        
        # HTTP í´ë¼ì´ì–¸íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.http_manager = HttpClientManager(MLHttpClientConfig())
        
        # ë¡œì»¬ ML ì¶”ë¡  ì„œë¹„ìŠ¤ - ì˜ì¡´ì„± ì£¼ì… ì‚¬ìš©
        self.local_ml_service = self._get_ml_service_from_container()
        
        # í´ë°± ë¶„ì„ ì „ëµ ì´ˆê¸°í™”
        self.fallback_analysis = AnalysisContext(
            KeywordBasedESGStrategy(),
            KeywordBasedSentimentStrategy()
        )
    
    def _get_ml_service_from_container(self) -> Optional[Any]:
        """ì˜ì¡´ì„± ì£¼ì… ì»¨í…Œì´ë„ˆì—ì„œ ML ì¶”ë¡  ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
        if not ML_INFERENCE_AVAILABLE:
            return None
            
        try:
            from app.core.dependencies import get_dependency
            container = get_dependency()
            service = container.get("ml_inference_service")
            print(f"âœ… ì˜ì¡´ì„± ì£¼ì…ì—ì„œ ML ì¶”ë¡  ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ")
            return service
        except Exception as e:
            print(f"âš ï¸ ML ì¶”ë¡  ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
            return None
    
    async def analyze_company_news(
        self, 
        company: str, 
        news_response: NewsSearchResponse
    ) -> NewsAnalysisResponse:
        """íšŒì‚¬ ë‰´ìŠ¤ ë¶„ì„ ì‹¤í–‰"""
        
        if not news_response.items:
            return self._create_empty_analysis_response(company, news_response)
        
        # ë¶„ì„ ì‹¤í–‰
        analysis_results = await self._execute_analysis_with_fallback(news_response)
        
        # ê²€ìƒ‰ ì •ë³´ ìƒì„±
        search_info = self._create_search_info(company, news_response)
        
        return NewsAnalysisResponse(
            search_info=search_info,
            analyzed_news=analysis_results["analyzed_news"],
            analysis_summary=analysis_results["analysis_summary"],
            ml_service_status=analysis_results["service_status"]
        )
    
    async def _execute_analysis_with_fallback(self, news_response: NewsSearchResponse) -> Dict[str, Any]:
        """ë¶„ì„ ì‹¤í–‰ ë° í´ë°± ì²˜ë¦¬"""
        # ìš°ì„ ìˆœìœ„: ë¡œì»¬ ML ì„œë¹„ìŠ¤ > ì™¸ë¶€ ML ì„œë¹„ìŠ¤ > í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°±
        
        # 1. ë¡œì»¬ ML ì„œë¹„ìŠ¤ ì‹œë„
        if self.local_ml_service and self.local_ml_service.is_available():
            try:
                return await self._analyze_with_local_ml_service(news_response)
            except Exception as e:
                print(f"âš ï¸ ë¡œì»¬ ML ì„œë¹„ìŠ¤ ì‹¤íŒ¨, ì™¸ë¶€ ì„œë¹„ìŠ¤ ì‹œë„: {str(e)}")
        
        # 2. ì™¸ë¶€ ML ì„œë¹„ìŠ¤ì™€ í´ë°± ê²½ìŸ
        return await self._race_external_ml_vs_fallback(news_response)
    
    async def _analyze_with_local_ml_service(self, news_response: NewsSearchResponse) -> Dict[str, Any]:
        """ë¡œì»¬ ML ì„œë¹„ìŠ¤ë¡œ ë¶„ì„"""
        print(f"ğŸ“Š ë¡œì»¬ ML ì„œë¹„ìŠ¤ë¡œ ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘: {len(news_response.items)}ê°œ ì•„ì´í…œ")
        
        try:
            analyzed_news = await self._analyze_news_batch_local(news_response.items)
            print(f"âœ… ë¡œì»¬ ML ì„œë¹„ìŠ¤ ë¶„ì„ ì™„ë£Œ: {len(analyzed_news)}ê°œ ê²°ê³¼")
            
            analysis_summary = await self._create_analysis_summary_async(analyzed_news)
            
            return {
                "analyzed_news": [item.dict() for item in analyzed_news],
                "analysis_summary": analysis_summary.dict(),
                "service_status": "local_ml"
            }
        except Exception as e:
            print(f"âŒ ë¡œì»¬ ML ì„œë¹„ìŠ¤ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            raise
    
    async def _race_external_ml_vs_fallback(self, news_response: NewsSearchResponse) -> Dict[str, Any]:
        """ì™¸ë¶€ ML ì„œë¹„ìŠ¤ì™€ í´ë°± ë¶„ì„ ê²½ìŸ"""
        print(f"ğŸ ì™¸ë¶€ ML vs í´ë°± ë¶„ì„ ê²½ìŸ ì‹œì‘: {len(news_response.items)}ê°œ ì•„ì´í…œ")
        
        analysis_request = self._create_analysis_request(news_response)
        
        # ì™¸ë¶€ ML ì„œë¹„ìŠ¤ì™€ í´ë°± ë¶„ì„ì„ ë™ì‹œì— ì‹œì‘
        ml_task = asyncio.create_task(self._call_external_ml_service_safe(analysis_request))
        fallback_task = asyncio.create_task(self._create_fallback_analysis_async(news_response.items))
        
        try:
            # ì™¸ë¶€ ML ì„œë¹„ìŠ¤ë¥¼ ë¨¼ì € ì‹œë„ (60ì´ˆ íƒ€ì„ì•„ì›ƒ)
            print("ğŸŒ ì™¸ë¶€ ML ì„œë¹„ìŠ¤ ì‹œë„ ì¤‘...")
            ml_results = await asyncio.wait_for(ml_task, timeout=60.0)
            fallback_task.cancel()
            print("âœ… ì™¸ë¶€ ML ì„œë¹„ìŠ¤ ì„±ê³µ")
            return {**ml_results, "service_status": "external_ml"}
        except (asyncio.TimeoutError, Exception) as e:
            print(f"âš ï¸ ì™¸ë¶€ ML ì„œë¹„ìŠ¤ ì‹¤íŒ¨ ({str(e)}), í´ë°± ë¶„ì„ ì‚¬ìš©")
            ml_task.cancel()
            fallback_results = await fallback_task
            print("âœ… í´ë°± ë¶„ì„ ì™„ë£Œ")
            return {**fallback_results, "service_status": "fallback"}
    
    async def _analyze_news_batch_local(self, news_items: List[NewsItem]) -> List[AnalyzedNewsItem]:
        """ë¡œì»¬ ML ì„œë¹„ìŠ¤ë¡œ ë‰´ìŠ¤ ë°°ì¹˜ ë¶„ì„ (ì„±ëŠ¥ ìµœì í™”)"""
        if not self.local_ml_service:
            print("âŒ ë¡œì»¬ ML ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ")
            return []
        
        # ìµœì  ë°°ì¹˜ í¬ê¸° (ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•´ ë” í° ë°°ì¹˜ ì‚¬ìš©)
        optimal_batch_size = 32  # 10 â†’ 32ë¡œ ì¦ê°€ (GPU í™œìš©ë„ ê·¹ëŒ€í™”)
        
        if len(news_items) > optimal_batch_size:
            print(f"ğŸ“¦ ê³ ì„±ëŠ¥ ë°°ì¹˜ ì²˜ë¦¬: {len(news_items)}ê°œë¥¼ {optimal_batch_size}ê°œì”© ë‚˜ëˆ„ì–´ ì²˜ë¦¬")
            
            analyzed_items = []
            for i in range(0, len(news_items), optimal_batch_size):
                batch = news_items[i:i + optimal_batch_size]
                batch_num = i // optimal_batch_size + 1
                total_batches = (len(news_items) + optimal_batch_size - 1) // optimal_batch_size
                
                print(f"  ğŸš€ ë°°ì¹˜ {batch_num}/{total_batches} ê³ ì† ì²˜ë¦¬: {len(batch)}ê°œ ì•„ì´í…œ")
                
                batch_results = await self._process_single_batch_local(batch)
                analyzed_items.extend(batch_results)
                
                print(f"  âš¡ ë°°ì¹˜ {batch_num}/{total_batches} ì™„ë£Œ: {len(batch_results)}ê°œ ê²°ê³¼")
            
            return analyzed_items
        else:
            print(f"ğŸš€ ë‹¨ì¼ ë°°ì¹˜ ê³ ì† ì²˜ë¦¬: {len(news_items)}ê°œ ì•„ì´í…œ")
            return await self._process_single_batch_local(news_items)
    
    async def _process_single_batch_local(self, news_items: List[NewsItem]) -> List[AnalyzedNewsItem]:
        """ë‹¨ì¼ ë°°ì¹˜ ì²˜ë¦¬"""
        # ML ì„œë¹„ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ì„± ì¬í™•ì¸
        if not self.local_ml_service or not self.local_ml_service.is_available():
            print("âŒ ML ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ")
            return []
        
        # íƒ€ì… ì²´ì»¤ë¥¼ ìœ„í•œ í™•ì‹¤í•œ íƒ€ì… ê°€ë“œ
        assert self.local_ml_service is not None
        
        # ë‰´ìŠ¤ ì•„ì´í…œì„ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜
        news_data = [self._news_item_to_dict(item) for item in news_items]
        
        # ë¡œì»¬ ML ì„œë¹„ìŠ¤ë¡œ ë¶„ì„
        try:
            print(f"ğŸ”„ ML ì¶”ë¡  ì„œë¹„ìŠ¤ í˜¸ì¶œ: {len(news_data)}ê°œ ì•„ì´í…œ")
            results = await self.local_ml_service.analyze_news_batch(news_data)
            print(f"âœ… ML ì¶”ë¡  ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
        except Exception as e:
            print(f"âŒ ML ì¶”ë¡  ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {str(e)}")
            raise
        
        # ê²°ê³¼ë¥¼ AnalyzedNewsItemìœ¼ë¡œ ë³€í™˜
        analyzed_items = []
        for i, result in enumerate(results):
            try:
                analyzed_item = self._convert_ml_result_to_analyzed_item(result, news_items)
                if analyzed_item:
                    analyzed_items.append(analyzed_item)
            except Exception as e:
                print(f"âš ï¸ ê²°ê³¼ ë³€í™˜ ì‹¤íŒ¨ (ì•„ì´í…œ {i+1}): {str(e)}")
        
        return analyzed_items
    
    def _news_item_to_dict(self, item: NewsItem) -> Dict[str, Any]:
        """NewsItemì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "title": item.title,
            "description": item.description,
            "link": item.link,
            "pub_date": item.pub_date,
            "mention_count": item.mention_count
        }
    
    def _convert_ml_result_to_analyzed_item(
        self, 
        result: Dict[str, Any], 
        original_items: List[NewsItem]
    ) -> Optional[AnalyzedNewsItem]:
        """ML ê²°ê³¼ë¥¼ AnalyzedNewsItemìœ¼ë¡œ ë³€í™˜"""
        try:
            # ì›ë³¸ ë‰´ìŠ¤ ì•„ì´í…œ ì°¾ê¸°
            original_item = self._find_original_news_item(result, original_items)
            if not original_item:
                return None
            
            # ESG ë¶„ë¥˜ ì •ë³´ ë³€í™˜
            esg_info = result.get("esg_classification", {})
            esg_classification = ESGClassification(
                esg_category=esg_info.get("category", "ê¸°íƒ€"),
                confidence_score=esg_info.get("confidence", 0.0),
                keywords=[],
                classification_method=esg_info.get("classification_method", "unknown")
            )
            
            # ê°ì • ë¶„ì„ ì •ë³´ ë³€í™˜
            sentiment_info = result.get("sentiment_analysis", {})
            probabilities = sentiment_info.get("probabilities", {})
            sentiment_analysis = SentimentAnalysis(
                sentiment=sentiment_info.get("sentiment", "ì¤‘ë¦½"),
                confidence_score=sentiment_info.get("confidence", 0.0),
                positive=probabilities.get("ê¸ì •", 0.0),
                negative=probabilities.get("ë¶€ì •", 0.0),
                neutral=probabilities.get("ì¤‘ë¦½", 0.0),
                analysis_method=sentiment_info.get("classification_method", "unknown")
            )
            
            return AnalyzedNewsItem(
                news_item=original_item,
                esg_classification=esg_classification,
                sentiment_analysis=sentiment_analysis
            )
            
        except Exception as e:
            print(f"ML ê²°ê³¼ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _find_original_news_item(
        self, 
        result: Dict[str, Any], 
        original_items: List[NewsItem]
    ) -> Optional[NewsItem]:
        """ML ê²°ê³¼ì— í•´ë‹¹í•˜ëŠ” ì›ë³¸ ë‰´ìŠ¤ ì•„ì´í…œ ì°¾ê¸°"""
        result_title = result.get("title", "")
        result_link = result.get("link", "")
        
        for item in original_items:
            if item.title == result_title or item.link == result_link:
                return item
        
        return None
    
    async def _call_external_ml_service_safe(self, analysis_request: NewsAnalysisRequest) -> Dict[str, Any]:
        """ì•ˆì „í•œ ì™¸ë¶€ ML ì„œë¹„ìŠ¤ í˜¸ì¶œ"""
        try:
            return await self._call_external_ml_service(analysis_request)
        except Exception as e:
            raise Exception(f"External ML service call failed: {str(e)}")
    
    async def _call_external_ml_service(self, analysis_request: NewsAnalysisRequest) -> Dict[str, Any]:
        """ì™¸ë¶€ ML ì„œë¹„ìŠ¤ í˜¸ì¶œ"""
        headers = {"Content-Type": "application/json"}
        
        async with self.http_manager.get_client(headers) as client:
            response = await client.post(
                f"{self.ml_service_url}/api/v1/ml/analyze-news",
                json=analysis_request.dict()
            )
            response.raise_for_status()
            return response.json()
    
    async def _create_fallback_analysis_async(self, news_items: List[NewsItem]) -> Dict[str, Any]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ë¶„ì„"""
        if not news_items:
            return self._create_empty_analysis_result()
        
        # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ìµœì í™”
        analyzed_news = await self._analyze_news_batch_fallback(news_items)
        analysis_summary = await self._create_analysis_summary_async(analyzed_news)
        
        return {
            "analyzed_news": [item.dict() for item in analyzed_news],
            "analysis_summary": analysis_summary.dict()
        }
    
    async def _analyze_news_batch_fallback(self, news_items: List[NewsItem]) -> List[AnalyzedNewsItem]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ë°°ì¹˜ ë¶„ì„"""
        # ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ë³‘ë ¬ ì²˜ë¦¬
        batches = self._create_batches(news_items, ml_processing_settings.batch_size)
        
        # ê° ë°°ì¹˜ë¥¼ ë³‘ë ¬ë¡œ ë¶„ì„
        tasks = [
            asyncio.create_task(self._analyze_batch_with_fallback(batch))
            for batch in batches
        ]
        
        batch_results = await asyncio.gather(*tasks)
        
        # ê²°ê³¼ ë³‘í•©
        analyzed_news = []
        for batch_result in batch_results:
            analyzed_news.extend(batch_result)
        
        return analyzed_news
    
    def _create_batches(self, items: List[NewsItem], batch_size: int) -> List[List[NewsItem]]:
        """ì•„ì´í…œì„ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ê¸°"""
        return [items[i:i + batch_size] for i in range(0, len(items), batch_size)]
    
    async def _analyze_batch_with_fallback(self, news_batch: List[NewsItem]) -> List[AnalyzedNewsItem]:
        """í´ë°± ì „ëµìœ¼ë¡œ ë°°ì¹˜ ë¶„ì„"""
        await asyncio.sleep(0)  # I/O ë¸”ë¡œí‚¹ ë°©ì§€
        
        analyzed_items = []
        for item in news_batch:
            text = f"{item.title} {item.description}".lower()
            
            # ë¶„ì„ ìˆ˜í–‰
            analysis_result = await self.fallback_analysis.analyze_text(text)
            
            # ESG ë¶„ë¥˜
            esg_data = analysis_result["esg"]
            esg_classification = ESGClassification(
                esg_category=esg_data["category"],
                confidence_score=esg_data["confidence"],
                keywords=esg_data.get("keywords", []),
                classification_method=esg_data["method"]
            )
            
            # ê°ì • ë¶„ì„
            sentiment_data = analysis_result["sentiment"]
            sentiment_analysis = SentimentAnalysis(
                sentiment=sentiment_data["sentiment"],
                confidence_score=sentiment_data["confidence"],
                positive=sentiment_data["positive"],
                negative=sentiment_data["negative"],
                neutral=sentiment_data["neutral"],
                analysis_method=sentiment_data["method"]
            )
            
            analyzed_items.append(AnalyzedNewsItem(
                news_item=item,
                esg_classification=esg_classification,
                sentiment_analysis=sentiment_analysis
            ))
        
        return analyzed_items
    
    def _create_empty_analysis_response(self, company: str, news_response: NewsSearchResponse) -> NewsAnalysisResponse:
        """ë¹ˆ ë¶„ì„ ì‘ë‹µ ìƒì„±"""
        search_info = self._create_search_info(company, news_response)
        empty_summary = AnalysisSummary(
            total_analyzed=0,
            esg_distribution={},
            sentiment_distribution={"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0}
        )
        
        return NewsAnalysisResponse(
            search_info=search_info,
            analyzed_news=[],
            analysis_summary=empty_summary,
            ml_service_status="no_data"
        )
    
    def _create_empty_analysis_result(self) -> Dict[str, Any]:
        """ë¹ˆ ë¶„ì„ ê²°ê³¼ ìƒì„±"""
        empty_summary = AnalysisSummary(
            total_analyzed=0,
            esg_distribution={},
            sentiment_distribution={"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0}
        )
        
        return {
            "analyzed_news": [],
            "analysis_summary": empty_summary.dict()
        }
    
    def _create_search_info(self, company: str, news_response: NewsSearchResponse) -> Dict[str, Any]:
        """ê²€ìƒ‰ ì •ë³´ ìƒì„±"""
        return {
            "company": company,
            "total": news_response.total,
            "start": news_response.start,
            "display": news_response.display,
            "last_build_date": news_response.last_build_date,
            "original_count": news_response.original_count,
            "duplicates_removed": news_response.duplicates_removed,
            "deduplication_enabled": news_response.deduplication_enabled
        }
    
    def _create_analysis_request(self, news_response: NewsSearchResponse) -> NewsAnalysisRequest:
        """ML ë¶„ì„ì„ ìœ„í•œ ìš”ì²­ ë°ì´í„° ìƒì„±"""
        news_data = [self._news_item_to_dict(item) for item in news_response.items]
        return NewsAnalysisRequest(news_items=news_data)
    
    async def _create_analysis_summary_async(self, analyzed_news: List[AnalyzedNewsItem]) -> AnalysisSummary:
        """ë¹„ë™ê¸° ë¶„ì„ ìš”ì•½ ìƒì„±"""
        await asyncio.sleep(0)  # ë‹¤ë¥¸ ì½”ë£¨í‹´ì—ê²Œ ì œì–´ê¶Œ ì–‘ë³´
        
        esg_distribution = {}
        sentiment_distribution = {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0}
        
        for item in analyzed_news:
            # ESG ë¶„í¬
            category = item.esg_classification.esg_category
            esg_distribution[category] = esg_distribution.get(category, 0) + 1
            
            # ê°ì • ë¶„í¬
            sentiment = item.sentiment_analysis.sentiment
            if sentiment in sentiment_distribution:
                sentiment_distribution[sentiment] += 1
        
        return AnalysisSummary(
            total_analyzed=len(analyzed_news),
            esg_distribution=esg_distribution,
            sentiment_distribution=sentiment_distribution
        ) 