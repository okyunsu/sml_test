import os
import json
import logging
import asyncio
from typing import Dict, Any, List, Optional, Tuple
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import numpy as np
from datetime import datetime

# HuggingFace ì™„ì „ ì˜¤í”„ë¼ì¸ ëª¨ë“œ ê°•ì œ ì„¤ì •
os.environ["HF_HUB_OFFLINE"] = "1"
os.environ["TRANSFORMERS_OFFLINE"] = "1"
os.environ["HF_DATASETS_OFFLINE"] = "1"

from app.config.ml_settings import ModelType, ml_model_settings
from app.domain.model.ml_loader import ModelManager
from app.domain.model.ml_strategies import (
    AnalysisContext, MLBasedESGStrategy, MLBasedSentimentStrategy,
    KeywordBasedESGStrategy, KeywordBasedSentimentStrategy
)

logger = logging.getLogger(__name__)

class MLInferenceService:
    """íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì„ ì‚¬ìš©í•œ ML ì¶”ë¡  ì„œë¹„ìŠ¤ (ë¦¬íŒ©í† ë§ ì™„ë£Œ)"""
    
    def __init__(self):
        logger.info("=== ML ì¶”ë¡  ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹œì‘ ===")
        
        # ì„¤ì • ë° ëª¨ë¸ ê´€ë¦¬ì ì´ˆê¸°í™”
        self.config = ml_model_settings
        self.model_manager = ModelManager(self.config)
        
        # ëª¨ë¸ ë° ë¶„ì„ ì „ëµ
        self.category_model = None
        self.category_tokenizer = None
        self.category_label_mapping = None
        self.sentiment_model = None
        self.sentiment_tokenizer = None
        self.sentiment_label_mapping = None
        self.analysis_context = None
        
        # íƒ€ì„ì•„ì›ƒ ì„¤ì • (ì´ˆ)
        self.analysis_timeout = 30  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
        self.model_load_timeout = 60  # ëª¨ë¸ ë¡œë”© 60ì´ˆ íƒ€ì„ì•„ì›ƒ
        
        self._log_initialization_info()
        self._validate_models_directory()
        self._load_models()
        self._setup_analysis_strategies()
        
        logger.info("=== ML ì¶”ë¡  ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ ===")
    
    def _log_initialization_info(self):
        """ì´ˆê¸°í™” ì •ë³´ ë¡œê¹…"""
        logger.info(f"ëª¨ë¸ ë””ë ‰í† ë¦¬: {self.config.models_dir}")
        logger.info(f"ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„: {self.config.model_name}")
        logger.info(f"ë¶„ì„ íƒ€ì„ì•„ì›ƒ: {self.analysis_timeout}ì´ˆ")
        logger.info(f"ML ì¶”ë¡  ì„œë¹„ìŠ¤ ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {self.model_manager.device}")
        
        # GPU ì •ë³´ ì¶œë ¥
        self._log_device_info()
    
    def _log_device_info(self):
        """ë””ë°”ì´ìŠ¤ ì •ë³´ ë¡œê¹…"""
        try:
            import torch
            cuda_module = getattr(torch, 'cuda', None)
            if cuda_module and cuda_module.is_available():
                logger.info(f"GPU: {cuda_module.get_device_name(0)}")
                total_memory = cuda_module.get_device_properties(0).total_memory / 1024**3
                logger.info(f"GPU ë©”ëª¨ë¦¬: {total_memory:.1f} GB")
            else:
                logger.warning("CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        except (ImportError, AttributeError):
            logger.info("PyTorch CUDAê°€ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def _validate_models_directory(self):
        """ëª¨ë¸ ë””ë ‰í† ë¦¬ ìœ íš¨ì„± ê²€ì‚¬"""
        if not os.path.exists(self.config.models_dir):
            logger.error(f"ëª¨ë¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.config.models_dir}")
            raise FileNotFoundError(f"ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.config.models_dir}")
        
        try:
            model_dirs = os.listdir(self.config.models_dir)
            logger.info(f"ëª¨ë¸ ë””ë ‰í† ë¦¬ ë‚´ìš©: {model_dirs}")
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë””ë ‰í† ë¦¬ ì½ê¸° ì‹¤íŒ¨: {str(e)}")
            raise
    
    def _load_models(self):
        """ëª¨ë¸ë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤"""
        logger.info("=== ëª¨ë¸ ë¡œë“œ ì‹œì‘ ===")
        
        try:
            # ì¹´í…Œê³ ë¦¬ ëª¨ë¸ ë¡œë“œ
            self._load_model_safely(ModelType.CATEGORY)
            
            # ê°ì • ëª¨ë¸ ë¡œë“œ  
            self._load_model_safely(ModelType.SENTIMENT)
            
            self._log_model_load_results()
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            logger.error(f"ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
            import traceback
            logger.error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
            raise
    
    def _load_model_safely(self, model_type: ModelType):
        """ì•ˆì „í•œ ëª¨ë¸ ë¡œë“œ (Windows í˜¸í™˜)"""
        try:
            model_path = self.config.get_model_path(model_type)
            logger.info(f"{model_type.value} ëª¨ë¸ ê²½ë¡œ: {model_path}")
            
            if os.path.exists(model_path):
                logger.info(f"{model_type.value} ëª¨ë¸ ë””ë ‰í† ë¦¬ ë°œê²¬, ë¡œë“œ ì‹œì‘")
                
                # ëª¨ë¸ ë¡œë“œ ì‹œë„
                try:
                    model, tokenizer, label_mapping = self.model_manager.load_model(model_type)
                    
                    if model_type == ModelType.CATEGORY:
                        self.category_model = model
                        self.category_tokenizer = tokenizer
                        self.category_label_mapping = label_mapping
                    else:
                        self.sentiment_model = model
                        self.sentiment_tokenizer = tokenizer
                        self.sentiment_label_mapping = label_mapping
                    
                    logger.info(f"{model_type.value} ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
                    
                except Exception as e:
                    logger.error(f"{model_type.value} ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜ˆì™¸: {str(e)}")
                    
            else:
                logger.warning(f"{model_type.value} ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
                
        except Exception as e:
            logger.error(f"{model_type.value} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            # ê°œë³„ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ëŠ” ì „ì²´ ì„œë¹„ìŠ¤ë¥¼ ì¤‘ë‹¨ì‹œí‚¤ì§€ ì•ŠìŒ
    
    def _log_model_load_results(self):
        """ëª¨ë¸ ë¡œë“œ ê²°ê³¼ ë¡œê¹…"""
        category_loaded = self.category_model is not None
        sentiment_loaded = self.sentiment_model is not None
        
        logger.info(f"ëª¨ë¸ ë¡œë“œ ê²°ê³¼ - ì¹´í…Œê³ ë¦¬: {'ì„±ê³µ' if category_loaded else 'ì‹¤íŒ¨'}, ê°ì •: {'ì„±ê³µ' if sentiment_loaded else 'ì‹¤íŒ¨'}")
        
        if not category_loaded and not sentiment_loaded:
            logger.error("ëª¨ë“  ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.")
        elif not category_loaded:
            logger.warning("ì¹´í…Œê³ ë¦¬ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. í•´ë‹¹ ê¸°ëŠ¥ì€ í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.")
        elif not sentiment_loaded:
            logger.warning("ê°ì • ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. í•´ë‹¹ ê¸°ëŠ¥ì€ í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.")
        else:
            logger.info("ëª¨ë“  ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    def _setup_analysis_strategies(self):
        """ë¶„ì„ ì „ëµ ì„¤ì •"""
        logger.info("=== ë¶„ì„ ì „ëµ ì„¤ì • ì‹œì‘ ===")
        
        try:
            # ESG ë¶„ì„ ì „ëµ
            if self.category_model and self.category_tokenizer:
                logger.info("ML ê¸°ë°˜ ESG ë¶„ì„ ì „ëµ ì‚¬ìš©")
                esg_strategy = MLBasedESGStrategy(
                    self.category_model,
                    self.category_tokenizer,
                    self.category_label_mapping,
                    self.model_manager.device,
                    self.config.max_length
                )
            else:
                logger.info("í‚¤ì›Œë“œ ê¸°ë°˜ ESG ë¶„ì„ ì „ëµ ì‚¬ìš©")
                esg_strategy = KeywordBasedESGStrategy()
            
            # ê°ì • ë¶„ì„ ì „ëµ
            if self.sentiment_model and self.sentiment_tokenizer:
                logger.info("ML ê¸°ë°˜ ê°ì • ë¶„ì„ ì „ëµ ì‚¬ìš©")
                sentiment_strategy = MLBasedSentimentStrategy(
                    self.sentiment_model,
                    self.sentiment_tokenizer,
                    self.sentiment_label_mapping,
                    self.model_manager.device,
                    self.config.max_length
                )
            else:
                logger.info("í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ë¶„ì„ ì „ëµ ì‚¬ìš©")
                sentiment_strategy = KeywordBasedSentimentStrategy()
            
            self.analysis_context = AnalysisContext(esg_strategy, sentiment_strategy)
            logger.info("âœ… ë¶„ì„ ì „ëµ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ë¶„ì„ ì „ëµ ì„¤ì • ì‹¤íŒ¨: {str(e)}")
            # í´ë°±ìœ¼ë¡œ í‚¤ì›Œë“œ ê¸°ë°˜ ì „ëµë§Œ ì‚¬ìš©
            try:
                logger.info("ğŸ”„ í´ë°±ìœ¼ë¡œ í‚¤ì›Œë“œ ê¸°ë°˜ ì „ëµ ì„¤ì •")
                esg_strategy = KeywordBasedESGStrategy()
                sentiment_strategy = KeywordBasedSentimentStrategy()
                self.analysis_context = AnalysisContext(esg_strategy, sentiment_strategy)
                logger.info("âœ… í´ë°± ì „ëµ ì„¤ì • ì™„ë£Œ")
            except Exception as fallback_error:
                logger.error(f"âŒ í´ë°± ì „ëµ ì„¤ì •ë„ ì‹¤íŒ¨: {str(fallback_error)}")
                self.analysis_context = None
    
    async def predict_category(self, text: str) -> Dict[str, Any]:
        """ESG ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡"""
        if not self.analysis_context:
            raise ValueError("ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        try:
            result = await self.analysis_context.esg_strategy.analyze(text)
            return {
                "predicted_class": 0,  # í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
                "predicted_label": result["category"],
                "confidence": result["confidence"],
                "probabilities": result.get("probabilities", {}),
                "classification_method": result["method"]
            }
        except Exception as e:
            logger.error(f"ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            raise
    
    async def predict_sentiment(self, text: str) -> Dict[str, Any]:
        """ê°ì • ë¶„ì„ ì˜ˆì¸¡"""
        if not self.analysis_context:
            raise ValueError("ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        try:
            result = await self.analysis_context.sentiment_strategy.analyze(text)
            return {
                "predicted_class": 0,  # í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
                "predicted_label": result["sentiment"],
                "confidence": result["confidence"],
                "probabilities": result.get("probabilities", {}),
                "classification_method": result["method"]
            }
        except Exception as e:
            logger.error(f"ê°ì • ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            raise
    
    async def analyze_news_batch(self, news_items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ë‰´ìŠ¤ ë°°ì¹˜ ë¶„ì„ (ì§„ì§œ ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”)"""
        logger.info(f"ğŸš€ ê³ ì„±ëŠ¥ ë°°ì¹˜ ë¶„ì„ ì‹œì‘: {len(news_items)}ê°œ ì•„ì´í…œ")
        
        if not news_items:
            return []
        
        # ìµœì  ë°°ì¹˜ í¬ê¸° ê³„ì‚° (GPU ë©”ëª¨ë¦¬ ê³ ë ¤)
        optimal_batch_size = min(32, len(news_items))  # 32ê°œì”© ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
        
        if len(news_items) <= optimal_batch_size:
            # ì†ŒëŸ‰ ë°ì´í„°ëŠ” í•œ ë²ˆì— ì²˜ë¦¬
            return await self._process_batch_optimized(news_items)
        else:
            # ëŒ€ëŸ‰ ë°ì´í„°ëŠ” ìµœì  ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
            logger.info(f"ğŸ“¦ ëŒ€ìš©ëŸ‰ ìµœì í™”: {len(news_items)}ê°œë¥¼ {optimal_batch_size}ê°œì”© ë‚˜ëˆ„ì–´ ì²˜ë¦¬")
            
            all_results = []
            for i in range(0, len(news_items), optimal_batch_size):
                batch = news_items[i:i + optimal_batch_size]
                batch_num = i // optimal_batch_size + 1
                total_batches = (len(news_items) + optimal_batch_size - 1) // optimal_batch_size
                
                logger.info(f"  ğŸ”„ ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘: {len(batch)}ê°œ ì•„ì´í…œ")
                
                try:
                    batch_results = await asyncio.wait_for(
                        self._process_batch_optimized(batch),
                        timeout=self.analysis_timeout * 2  # ë°°ì¹˜ëŠ” ë” ê¸´ íƒ€ì„ì•„ì›ƒ
                    )
                    all_results.extend(batch_results)
                    logger.info(f"  âœ… ë°°ì¹˜ {batch_num}/{total_batches} ì™„ë£Œ: {len(batch_results)}ê°œ ê²°ê³¼")
                    
                except asyncio.TimeoutError:
                    logger.error(f"  â° ë°°ì¹˜ {batch_num}/{total_batches} íƒ€ì„ì•„ì›ƒ")
                    # íƒ€ì„ì•„ì›ƒëœ ë°°ì¹˜ëŠ” ê°œë³„ ì²˜ë¦¬ë¡œ í´ë°±
                    for item in batch:
                        all_results.append(self._create_timeout_fallback_result(item))
                except Exception as e:
                    logger.error(f"  âŒ ë°°ì¹˜ {batch_num}/{total_batches} ì˜¤ë¥˜: {str(e)}")
                    # ì˜¤ë¥˜ ë°œìƒí•œ ë°°ì¹˜ëŠ” ê°œë³„ ì²˜ë¦¬ë¡œ í´ë°±
                    for item in batch:
                        all_results.append(self._create_error_fallback_result(item))
            
            logger.info(f"ğŸ‰ ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ: {len(all_results)}ê°œ ê²°ê³¼")
            return all_results
    
    async def _process_batch_optimized(self, batch_items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ìµœì í™”ëœ ë°°ì¹˜ ì²˜ë¦¬ - í•µì‹¬ ì„±ëŠ¥ ê°œì„ """
        if not batch_items or not self.analysis_context:
            logger.warning("ë°°ì¹˜ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ìŒ")
            return [self._create_default_result(item) for item in batch_items]
        
        # íƒ€ì… ì²´ì»¤ë¥¼ ìœ„í•œ í™•ì‹¤í•œ íƒ€ì… ê°€ë“œ
        assert self.analysis_context is not None
        
        try:
            # ğŸš€ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ì¶”ì¶œ
            texts = [self._combine_news_text(item) for item in batch_items]
            
            # ğŸš€ ë°°ì¹˜ ë¶„ì„ (ESG + ê°ì • ë™ì‹œ ì²˜ë¦¬)
            logger.info(f"ğŸ”„ ë°°ì¹˜ ML ë¶„ì„ ì‹œì‘: {len(texts)}ê°œ í…ìŠ¤íŠ¸")
            analysis_results = await self.analysis_context.analyze_batch(texts)
            logger.info(f"âœ… ë°°ì¹˜ ML ë¶„ì„ ì™„ë£Œ: {len(analysis_results)}ê°œ ê²°ê³¼")
            
            # ê²°ê³¼ ê²°í•©
            final_results = []
            for i, item in enumerate(batch_items):
                if i < len(analysis_results):
                    analysis_result = analysis_results[i]
                    final_results.append({
                        **item,
                        "esg_classification": {
                            "category": analysis_result["esg"]["category"],
                            "confidence": analysis_result["esg"]["confidence"],
                            "probabilities": analysis_result["esg"].get("probabilities", {}),
                            "classification_method": analysis_result["esg"]["method"]
                        },
                        "sentiment_analysis": {
                            "sentiment": analysis_result["sentiment"]["sentiment"],
                            "confidence": analysis_result["sentiment"]["confidence"],
                            "probabilities": analysis_result["sentiment"].get("probabilities", {}),
                            "classification_method": analysis_result["sentiment"]["method"]
                        }
                    })
                else:
                    final_results.append(self._create_default_result(item))
            
            return final_results
            
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ê°œë³„ ì²˜ë¦¬ë¡œ í´ë°±
            return await self._fallback_individual_processing(batch_items)
    
    async def _fallback_individual_processing(self, batch_items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """í´ë°±: ê°œë³„ ì²˜ë¦¬"""
        logger.warning("ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨, ê°œë³„ ì²˜ë¦¬ë¡œ í´ë°±")
        
        results = []
        for i, item in enumerate(batch_items):
            try:
                logger.info(f"  ê°œë³„ ì²˜ë¦¬ {i+1}/{len(batch_items)}")
                result = await asyncio.wait_for(
                    self._analyze_single_news_item(item),
                    timeout=self.analysis_timeout
                )
                results.append(result)
            except Exception as e:
                logger.error(f"  ê°œë³„ ì²˜ë¦¬ {i+1} ì‹¤íŒ¨: {str(e)}")
                results.append(self._create_error_fallback_result(item))
        
        return results
    
    async def _analyze_single_news_item(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¨ì¼ ë‰´ìŠ¤ ì•„ì´í…œ ë¶„ì„ (íƒ€ì„ì•„ì›ƒ ë° ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”)"""
        text = self._combine_news_text(item)
        
        if not text or not self.analysis_context:
            logger.warning("í…ìŠ¤íŠ¸ê°€ ì—†ê±°ë‚˜ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ìŒ, ê¸°ë³¸ ê²°ê³¼ ë°˜í™˜")
            return self._create_default_result(item)
        
        try:
            # ë¶„ì„ ìˆ˜í–‰ (íƒ€ì„ì•„ì›ƒ ì ìš©)
            analysis_result = await asyncio.wait_for(
                self.analysis_context.analyze_text(text),
                timeout=self.analysis_timeout
            )
            
            return {
                **item,
                "esg_classification": {
                    "category": analysis_result["esg"]["category"],
                    "confidence": analysis_result["esg"]["confidence"],
                    "probabilities": analysis_result["esg"].get("probabilities", {}),
                    "classification_method": analysis_result["esg"]["method"]
                },
                "sentiment_analysis": {
                    "sentiment": analysis_result["sentiment"]["sentiment"],
                    "confidence": analysis_result["sentiment"]["confidence"],
                    "probabilities": analysis_result["sentiment"].get("probabilities", {}),
                    "classification_method": analysis_result["sentiment"]["method"]
                }
            }
            
        except asyncio.TimeoutError:
            logger.error("ë¶„ì„ íƒ€ì„ì•„ì›ƒ, ê¸°ë³¸ ê²°ê³¼ ë°˜í™˜")
            return self._create_timeout_fallback_result(item)
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}")
            return self._create_error_fallback_result(item)
    
    def _combine_news_text(self, item: Dict[str, Any]) -> str:
        """ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ê²°í•©"""
        title = item.get('title', '')
        description = item.get('description', '')
        return f"{title} {description}".strip()
    
    def _create_default_result(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """ê¸°ë³¸ ê²°ê³¼ ìƒì„±"""
        return {
            **item,
            "esg_classification": {
                "category": "ê¸°íƒ€",
                "confidence": 0.0,
                "probabilities": {},
                "classification_method": "default"
            },
            "sentiment_analysis": {
                "sentiment": "ì¤‘ë¦½",
                "confidence": 0.0,
                "probabilities": {},
                "classification_method": "default"
            }
        }
    
    def _create_error_fallback_result(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ì‹œ í´ë°± ê²°ê³¼ ìƒì„±"""
        return {
            **item,
            "esg_classification": {
                "category": "ê¸°íƒ€",
                "confidence": 0.0,
                "probabilities": {},
                "classification_method": "error_fallback"
            },
            "sentiment_analysis": {
                "sentiment": "ì¤‘ë¦½",
                "confidence": 0.0,
                "probabilities": {},
                "classification_method": "error_fallback"
            }
        }
    
    def _create_timeout_fallback_result(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """íƒ€ì„ì•„ì›ƒ ì‹œ í´ë°± ê²°ê³¼ ìƒì„±"""
        return {
            **item,
            "esg_classification": {
                "category": "ê¸°íƒ€",
                "confidence": 0.0,
                "probabilities": {},
                "classification_method": "timeout_fallback"
            },
            "sentiment_analysis": {
                "sentiment": "ì¤‘ë¦½",
                "confidence": 0.0,
                "probabilities": {},
                "classification_method": "timeout_fallback"
            }
        }
    
    def is_available(self) -> bool:
        """ML ì¶”ë¡  ì„œë¹„ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
        return (
            self.analysis_context is not None and
            hasattr(self.analysis_context, 'esg_strategy') and
            hasattr(self.analysis_context, 'sentiment_strategy')
        )
    
    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
        return {
            "category_model_available": self.category_model is not None,
            "sentiment_model_available": self.sentiment_model is not None,
            "device": str(self.model_manager.device),
            "category_labels": self.category_label_mapping,
            "sentiment_labels": self.sentiment_label_mapping,
            "config": {
                "models_dir": self.config.models_dir,
                "model_name": self.config.model_name,
                "max_length": self.config.max_length
            }
        } 