import os
import json
import logging
import asyncio
from typing import Dict, Any, List, Optional, Tuple
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import numpy as np
from datetime import datetime

# HuggingFace ÏôÑÏ†Ñ Ïò§ÌîÑÎùºÏù∏ Î™®Îìú Í∞ïÏ†ú ÏÑ§Ï†ï
os.environ["HF_HUB_OFFLINE"] = "1"
os.environ["TRANSFORMERS_OFFLINE"] = "1"
os.environ["HF_DATASETS_OFFLINE"] = "1"

from app.config.ml_settings import ModelType, ml_model_settings
from app.domain.model.ml_loader import ModelManager
from app.domain.model.ml_strategies import (
    AnalysisContext, MLBasedESGStrategy, MLBasedSentimentStrategy,
    KeywordBasedESGStrategy, KeywordBasedSentimentStrategy
)

logger = logging.getLogger(__name__)

class MLInferenceService:
    """ÌååÏù∏ÌäúÎãùÎêú Î™®Îç∏ÏùÑ ÏÇ¨Ïö©Ìïú ML Ï∂îÎ°† ÏÑúÎπÑÏä§ (Î¶¨Ìå©ÌÜ†ÎßÅ ÏôÑÎ£å)"""
    
    def __init__(self):
        logger.info("=== ML Ï∂îÎ°† ÏÑúÎπÑÏä§ Ï¥àÍ∏∞Ìôî ÏãúÏûë ===")
        
        # ÏÑ§Ï†ï Î∞è Î™®Îç∏ Í¥ÄÎ¶¨Ïûê Ï¥àÍ∏∞Ìôî
        self.config = ml_model_settings
        self.model_manager = ModelManager(self.config)
        
        # Î™®Îç∏ Î∞è Î∂ÑÏÑù Ï†ÑÎûµ
        self.category_model = None
        self.category_tokenizer = None
        self.category_label_mapping = None
        self.sentiment_model = None
        self.sentiment_tokenizer = None
        self.sentiment_label_mapping = None
        self.analysis_context = None
        
        # ÌÉÄÏûÑÏïÑÏõÉ ÏÑ§Ï†ï (Ï¥à)
        self.analysis_timeout = 30  # 30Ï¥à ÌÉÄÏûÑÏïÑÏõÉ
        self.model_load_timeout = 60  # Î™®Îç∏ Î°úÎî© 60Ï¥à ÌÉÄÏûÑÏïÑÏõÉ
        
        self._log_initialization_info()
        self._validate_models_directory()
        self._load_models()
        self._setup_analysis_strategies()
        
        logger.info("=== ML Ï∂îÎ°† ÏÑúÎπÑÏä§ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å ===")
    
    def _log_initialization_info(self):
        """Ï¥àÍ∏∞Ìôî Ï†ïÎ≥¥ Î°úÍπÖ"""
        logger.info(f"Î™®Îç∏ ÎîîÎ†âÌÜ†Î¶¨: {self.config.models_dir}")
        logger.info(f"ÏÇ¨Ïö©Ìï† Î™®Îç∏ Ïù¥Î¶Ñ: {self.config.model_name}")
        logger.info(f"Î∂ÑÏÑù ÌÉÄÏûÑÏïÑÏõÉ: {self.analysis_timeout}Ï¥à")
        logger.info(f"ML Ï∂îÎ°† ÏÑúÎπÑÏä§ Ï¥àÍ∏∞Ìôî - ÎîîÎ∞îÏù¥Ïä§: {self.model_manager.device}")
        
        # GPU Ï†ïÎ≥¥ Ï∂úÎ†•
        self._log_device_info()
    
    def _log_device_info(self):
        """ÎîîÎ∞îÏù¥Ïä§ Ï†ïÎ≥¥ Î°úÍπÖ"""
        try:
            import torch
            cuda_module = getattr(torch, 'cuda', None)
            if cuda_module and cuda_module.is_available():
                logger.info(f"GPU: {cuda_module.get_device_name(0)}")
                total_memory = cuda_module.get_device_properties(0).total_memory / 1024**3
                logger.info(f"GPU Î©îÎ™®Î¶¨: {total_memory:.1f} GB")
            else:
                logger.warning("CUDAÎ•º ÏÇ¨Ïö©Ìï† Ïàò ÏóÜÏäµÎãàÎã§. CPU Î™®ÎìúÎ°ú Ïã§ÌñâÎê©ÎãàÎã§.")
        except (ImportError, AttributeError):
            logger.info("PyTorch CUDAÍ∞Ä ÏÇ¨Ïö©Ìï† Ïàò ÏóÜÏäµÎãàÎã§.")
    
    def _validate_models_directory(self):
        """Î™®Îç∏ ÎîîÎ†âÌÜ†Î¶¨ Ïú†Ìö®ÏÑ± Í≤ÄÏÇ¨"""
        if not os.path.exists(self.config.models_dir):
            logger.error(f"Î™®Îç∏ ÎîîÎ†âÌÜ†Î¶¨Í∞Ä Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§: {self.config.models_dir}")
            raise FileNotFoundError(f"Î™®Îç∏ ÎîîÎ†âÌÜ†Î¶¨Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {self.config.models_dir}")
        
        try:
            model_dirs = os.listdir(self.config.models_dir)
            logger.info(f"Î™®Îç∏ ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Ïö©: {model_dirs}")
        except Exception as e:
            logger.error(f"Î™®Îç∏ ÎîîÎ†âÌÜ†Î¶¨ ÏùΩÍ∏∞ Ïã§Ìå®: {str(e)}")
            raise
    
    def _load_models(self):
        """Î™®Îç∏Îì§ÏùÑ Î°úÎìúÌï©ÎãàÎã§"""
        logger.info("=== Î™®Îç∏ Î°úÎìú ÏãúÏûë ===")
        
        try:
            # Ïπ¥ÌÖåÍ≥†Î¶¨ Î™®Îç∏ Î°úÎìú
            self._load_model_safely(ModelType.CATEGORY)
            
            # Í∞êÏ†ï Î™®Îç∏ Î°úÎìú  
            self._load_model_safely(ModelType.SENTIMENT)
            
            self._log_model_load_results()
            
        except Exception as e:
            logger.error(f"Î™®Îç∏ Î°úÎìú Ï§ë Ïò§Î•ò: {str(e)}")
            logger.error(f"Ïò§Î•ò ÌÉÄÏûÖ: {type(e).__name__}")
            import traceback
            logger.error(f"Ïä§ÌÉù Ìä∏Î†àÏù¥Ïä§: {traceback.format_exc()}")
            raise
    
    def _load_model_safely(self, model_type: ModelType):
        """ÏïàÏ†ÑÌïú Î™®Îç∏ Î°úÎìú (Windows Ìò∏Ìôò)"""
        try:
            model_path = self.config.get_model_path(model_type)
            logger.info(f"{model_type.value} Î™®Îç∏ Í≤ΩÎ°ú: {model_path}")
            
            if os.path.exists(model_path):
                logger.info(f"{model_type.value} Î™®Îç∏ ÎîîÎ†âÌÜ†Î¶¨ Î∞úÍ≤¨, Î°úÎìú ÏãúÏûë")
                
                # Î™®Îç∏ Î°úÎìú ÏãúÎèÑ
                try:
                    model, tokenizer, label_mapping = self.model_manager.load_model(model_type)
                    
                    if model_type == ModelType.CATEGORY:
                        self.category_model = model
                        self.category_tokenizer = tokenizer
                        self.category_label_mapping = label_mapping
                    else:
                        self.sentiment_model = model
                        self.sentiment_tokenizer = tokenizer
                        self.sentiment_label_mapping = label_mapping
                    
                    logger.info(f"{model_type.value} Î™®Îç∏ Î°úÎìú ÏÑ±Í≥µ")
                    
                except Exception as e:
                    logger.error(f"{model_type.value} Î™®Îç∏ Î°úÎìú Ï§ë ÏòàÏô∏: {str(e)}")
                    
            else:
                logger.warning(f"{model_type.value} Î™®Îç∏ÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {model_path}")
                
        except Exception as e:
            logger.error(f"{model_type.value} Î™®Îç∏ Î°úÎìú Ïã§Ìå®: {str(e)}")
            # Í∞úÎ≥Ñ Î™®Îç∏ Î°úÎìú Ïã§Ìå®Îäî Ï†ÑÏ≤¥ ÏÑúÎπÑÏä§Î•º Ï§ëÎã®ÏãúÌÇ§ÏßÄ ÏïäÏùå
    
    def _log_model_load_results(self):
        """Î™®Îç∏ Î°úÎìú Í≤∞Í≥º Î°úÍπÖ"""
        category_loaded = self.category_model is not None
        sentiment_loaded = self.sentiment_model is not None
        
        logger.info(f"Î™®Îç∏ Î°úÎìú Í≤∞Í≥º - Ïπ¥ÌÖåÍ≥†Î¶¨: {'ÏÑ±Í≥µ' if category_loaded else 'Ïã§Ìå®'}, Í∞êÏ†ï: {'ÏÑ±Í≥µ' if sentiment_loaded else 'Ïã§Ìå®'}")
        
        if not category_loaded and not sentiment_loaded:
            logger.error("Î™®Îì† Î™®Îç∏ Î°úÎìúÏóê Ïã§Ìå®ÌñàÏäµÎãàÎã§. ÌÇ§ÏõåÎìú Í∏∞Î∞ò Î∂ÑÏÑùÏúºÎ°ú ÎåÄÏ≤¥Îê©ÎãàÎã§.")
        elif not category_loaded:
            logger.warning("Ïπ¥ÌÖåÍ≥†Î¶¨ Î™®Îç∏ Î°úÎìú Ïã§Ìå®. Ìï¥Îãπ Í∏∞Îä•ÏùÄ ÌÇ§ÏõåÎìú Í∏∞Î∞òÏúºÎ°ú ÎåÄÏ≤¥Îê©ÎãàÎã§.")
        elif not sentiment_loaded:
            logger.warning("Í∞êÏ†ï Î™®Îç∏ Î°úÎìú Ïã§Ìå®. Ìï¥Îãπ Í∏∞Îä•ÏùÄ ÌÇ§ÏõåÎìú Í∏∞Î∞òÏúºÎ°ú ÎåÄÏ≤¥Îê©ÎãàÎã§.")
        else:
            logger.info("Î™®Îì† Î™®Îç∏Ïù¥ ÏÑ±Í≥µÏ†ÅÏúºÎ°ú Î°úÎìúÎêòÏóàÏäµÎãàÎã§!")
    
    def _setup_analysis_strategies(self):
        """Î∂ÑÏÑù Ï†ÑÎûµ ÏÑ§Ï†ï"""
        logger.info("=== Î∂ÑÏÑù Ï†ÑÎûµ ÏÑ§Ï†ï ÏãúÏûë ===")
        
        try:
            # ESG Î∂ÑÏÑù Ï†ÑÎûµ
            if self.category_model and self.category_tokenizer:
                logger.info("ML Í∏∞Î∞ò ESG Î∂ÑÏÑù Ï†ÑÎûµ ÏÇ¨Ïö©")
                esg_strategy = MLBasedESGStrategy(
                    self.category_model,
                    self.category_tokenizer,
                    self.category_label_mapping,
                    self.model_manager.device,
                    self.config.max_length
                )
            else:
                logger.info("ÌÇ§ÏõåÎìú Í∏∞Î∞ò ESG Î∂ÑÏÑù Ï†ÑÎûµ ÏÇ¨Ïö©")
                esg_strategy = KeywordBasedESGStrategy()
            
            # Í∞êÏ†ï Î∂ÑÏÑù Ï†ÑÎûµ
            if self.sentiment_model and self.sentiment_tokenizer:
                logger.info("ML Í∏∞Î∞ò Í∞êÏ†ï Î∂ÑÏÑù Ï†ÑÎûµ ÏÇ¨Ïö©")
                sentiment_strategy = MLBasedSentimentStrategy(
                    self.sentiment_model,
                    self.sentiment_tokenizer,
                    self.sentiment_label_mapping,
                    self.model_manager.device,
                    self.config.max_length
                )
            else:
                logger.info("ÌÇ§ÏõåÎìú Í∏∞Î∞ò Í∞êÏ†ï Î∂ÑÏÑù Ï†ÑÎûµ ÏÇ¨Ïö©")
                sentiment_strategy = KeywordBasedSentimentStrategy()
            
            self.analysis_context = AnalysisContext(esg_strategy, sentiment_strategy)
            logger.info("‚úÖ Î∂ÑÏÑù Ï†ÑÎûµ ÏÑ§Ï†ï ÏôÑÎ£å")
            
        except Exception as e:
            logger.error(f"‚ùå Î∂ÑÏÑù Ï†ÑÎûµ ÏÑ§Ï†ï Ïã§Ìå®: {str(e)}")
            # Ìè¥Î∞±ÏúºÎ°ú ÌÇ§ÏõåÎìú Í∏∞Î∞ò Ï†ÑÎûµÎßå ÏÇ¨Ïö©
            try:
                logger.info("üîÑ Ìè¥Î∞±ÏúºÎ°ú ÌÇ§ÏõåÎìú Í∏∞Î∞ò Ï†ÑÎûµ ÏÑ§Ï†ï")
                esg_strategy = KeywordBasedESGStrategy()
                sentiment_strategy = KeywordBasedSentimentStrategy()
                self.analysis_context = AnalysisContext(esg_strategy, sentiment_strategy)
                logger.info("‚úÖ Ìè¥Î∞± Ï†ÑÎûµ ÏÑ§Ï†ï ÏôÑÎ£å")
            except Exception as fallback_error:
                logger.error(f"‚ùå Ìè¥Î∞± Ï†ÑÎûµ ÏÑ§Ï†ïÎèÑ Ïã§Ìå®: {str(fallback_error)}")
                self.analysis_context = None
    
    async def predict_category(self, text: str) -> Dict[str, Any]:
        """ESG Ïπ¥ÌÖåÍ≥†Î¶¨ ÏòàÏ∏°"""
        if not self.analysis_context:
            raise ValueError("Î∂ÑÏÑù Ïª®ÌÖçÏä§Ìä∏Í∞Ä Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§")
        
        try:
            result = await self.analysis_context.esg_strategy.analyze(text)
            return {
                "predicted_class": 0,  # Ìò∏ÌôòÏÑ±ÏùÑ ÏúÑÌï¥ Ïú†ÏßÄ
                "predicted_label": result["category"],
                "confidence": result["confidence"],
                "probabilities": result.get("probabilities", {}),
                "classification_method": result["method"]
            }
        except Exception as e:
            logger.error(f"Ïπ¥ÌÖåÍ≥†Î¶¨ ÏòàÏ∏° Ï§ë Ïò§Î•ò: {str(e)}")
            raise
    
    async def predict_sentiment(self, text: str) -> Dict[str, Any]:
        """Í∞êÏ†ï Î∂ÑÏÑù ÏòàÏ∏°"""
        if not self.analysis_context:
            raise ValueError("Î∂ÑÏÑù Ïª®ÌÖçÏä§Ìä∏Í∞Ä Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§")
        
        try:
            result = await self.analysis_context.sentiment_strategy.analyze(text)
            return {
                "predicted_class": 0,  # Ìò∏ÌôòÏÑ±ÏùÑ ÏúÑÌï¥ Ïú†ÏßÄ
                "predicted_label": result["sentiment"],
                "confidence": result["confidence"],
                "probabilities": result.get("probabilities", {}),
                "classification_method": result["method"]
            }
        except Exception as e:
            logger.error(f"Í∞êÏ†ï ÏòàÏ∏° Ï§ë Ïò§Î•ò: {str(e)}")
            raise
    
    async def analyze_news_batch(self, news_items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Îâ¥Ïä§ Î∞∞Ïπò Î∂ÑÏÑù (ÌÉÄÏûÑÏïÑÏõÉ Ï†ÅÏö©)"""
        logger.info(f"Îâ¥Ïä§ Î∞∞Ïπò Î∂ÑÏÑù ÏãúÏûë: {len(news_items)}Í∞ú ÏïÑÏù¥ÌÖú")
        results = []
        
        for i, item in enumerate(news_items):
            try:
                logger.info(f"Îâ¥Ïä§ ÏïÑÏù¥ÌÖú {i+1}/{len(news_items)} Î∂ÑÏÑù ÏãúÏûë")
                
                # ÌÉÄÏûÑÏïÑÏõÉÏùÑ Ï†ÅÏö©ÌïòÏó¨ Î∂ÑÏÑù ÏàòÌñâ
                result = await asyncio.wait_for(
                    self._analyze_single_news_item(item),
                    timeout=self.analysis_timeout
                )
                results.append(result)
                logger.info(f"Îâ¥Ïä§ ÏïÑÏù¥ÌÖú {i+1}/{len(news_items)} Î∂ÑÏÑù ÏôÑÎ£å")
                
            except asyncio.TimeoutError:
                logger.error(f"Îâ¥Ïä§ ÏïÑÏù¥ÌÖú {i+1}/{len(news_items)} Î∂ÑÏÑù ÌÉÄÏûÑÏïÑÏõÉ")
                result = self._create_error_fallback_result(item)
                results.append(result)
                
            except Exception as e:
                logger.error(f"Îâ¥Ïä§ ÏïÑÏù¥ÌÖú {i+1}/{len(news_items)} Î∂ÑÏÑù Ï§ë Ïò§Î•ò: {str(e)}")
                result = self._create_error_fallback_result(item)
                results.append(result)
        
        logger.info(f"Îâ¥Ïä§ Î∞∞Ïπò Î∂ÑÏÑù ÏôÑÎ£å: {len(results)}Í∞ú Í≤∞Í≥º")
        return results
    
    async def _analyze_single_news_item(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """Îã®Ïùº Îâ¥Ïä§ ÏïÑÏù¥ÌÖú Î∂ÑÏÑù (ÌÉÄÏûÑÏïÑÏõÉ Î∞è ÏòàÏô∏ Ï≤òÎ¶¨ Í∞ïÌôî)"""
        text = self._combine_news_text(item)
        
        if not text or not self.analysis_context:
            logger.warning("ÌÖçÏä§Ìä∏Í∞Ä ÏóÜÍ±∞ÎÇò Î∂ÑÏÑù Ïª®ÌÖçÏä§Ìä∏Í∞Ä ÏóÜÏùå, Í∏∞Î≥∏ Í≤∞Í≥º Î∞òÌôò")
            return self._create_default_result(item)
        
        try:
            # Î∂ÑÏÑù ÏàòÌñâ (ÌÉÄÏûÑÏïÑÏõÉ Ï†ÅÏö©)
            analysis_result = await asyncio.wait_for(
                self.analysis_context.analyze_text(text),
                timeout=self.analysis_timeout
            )
            
            return {
                **item,
                "esg_classification": {
                    "category": analysis_result["esg"]["category"],
                    "confidence": analysis_result["esg"]["confidence"],
                    "probabilities": analysis_result["esg"].get("probabilities", {}),
                    "classification_method": analysis_result["esg"]["method"]
                },
                "sentiment_analysis": {
                    "sentiment": analysis_result["sentiment"]["sentiment"],
                    "confidence": analysis_result["sentiment"]["confidence"],
                    "probabilities": analysis_result["sentiment"].get("probabilities", {}),
                    "classification_method": analysis_result["sentiment"]["method"]
                }
            }
            
        except asyncio.TimeoutError:
            logger.error("Î∂ÑÏÑù ÌÉÄÏûÑÏïÑÏõÉ, Í∏∞Î≥∏ Í≤∞Í≥º Î∞òÌôò")
            return self._create_timeout_fallback_result(item)
            
        except Exception as e:
            logger.error(f"Î∂ÑÏÑù Ï§ë ÏòàÏô∏ Î∞úÏÉù: {str(e)}")
            return self._create_error_fallback_result(item)
    
    def _combine_news_text(self, item: Dict[str, Any]) -> str:
        """Îâ¥Ïä§ ÌÖçÏä§Ìä∏ Í≤∞Ìï©"""
        title = item.get('title', '')
        description = item.get('description', '')
        return f"{title} {description}".strip()
    
    def _create_default_result(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """Í∏∞Î≥∏ Í≤∞Í≥º ÏÉùÏÑ±"""
        return {
            **item,
            "esg_classification": {
                "category": "Í∏∞ÌÉÄ",
                "confidence": 0.0,
                "probabilities": {},
                "classification_method": "default"
            },
            "sentiment_analysis": {
                "sentiment": "Ï§ëÎ¶Ω",
                "confidence": 0.0,
                "probabilities": {},
                "classification_method": "default"
            }
        }
    
    def _create_error_fallback_result(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """Ïò§Î•ò Ïãú Ìè¥Î∞± Í≤∞Í≥º ÏÉùÏÑ±"""
        return {
            **item,
            "esg_classification": {
                "category": "Í∏∞ÌÉÄ",
                "confidence": 0.0,
                "probabilities": {},
                "classification_method": "error_fallback"
            },
            "sentiment_analysis": {
                "sentiment": "Ï§ëÎ¶Ω",
                "confidence": 0.0,
                "probabilities": {},
                "classification_method": "error_fallback"
            }
        }
    
    def _create_timeout_fallback_result(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """ÌÉÄÏûÑÏïÑÏõÉ Ïãú Ìè¥Î∞± Í≤∞Í≥º ÏÉùÏÑ±"""
        return {
            **item,
            "esg_classification": {
                "category": "Í∏∞ÌÉÄ",
                "confidence": 0.0,
                "probabilities": {},
                "classification_method": "timeout_fallback"
            },
            "sentiment_analysis": {
                "sentiment": "Ï§ëÎ¶Ω",
                "confidence": 0.0,
                "probabilities": {},
                "classification_method": "timeout_fallback"
            }
        }
    
    def is_available(self) -> bool:
        """ML Ï∂îÎ°† ÏÑúÎπÑÏä§ ÏÇ¨Ïö© Í∞ÄÎä• Ïó¨Î∂Ä"""
        return (
            self.analysis_context is not None and
            hasattr(self.analysis_context, 'esg_strategy') and
            hasattr(self.analysis_context, 'sentiment_strategy')
        )
    
    def get_model_info(self) -> Dict[str, Any]:
        """Î™®Îç∏ Ï†ïÎ≥¥ Ï°∞Ìöå"""
        return {
            "category_model_available": self.category_model is not None,
            "sentiment_model_available": self.sentiment_model is not None,
            "device": str(self.model_manager.device),
            "category_labels": self.category_label_mapping,
            "sentiment_labels": self.sentiment_label_mapping,
            "config": {
                "models_dir": self.config.models_dir,
                "model_name": self.config.model_name,
                "max_length": self.config.max_length
            }
        } 